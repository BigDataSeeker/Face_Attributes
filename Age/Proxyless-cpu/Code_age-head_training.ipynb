{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims to compare a few different model training approaches when it comes to age estimation problem.\n",
    "* Proxyless Indexed tensor\n",
    "  * Frozen backbone, only age head trained\n",
    "  * Model trained entirely on age problem\n",
    "* Proxyless aged tensor, dimension of 10\n",
    "* Proxyless aged tensor, dimension of 30\n",
    "* ResNet18 baseline model\n",
    "  * Frozen backbone\n",
    "  * Entirely trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as Ap\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import PIL\n",
    "import pandas\n",
    "from os.path import join\n",
    "import copy\n",
    "import timm \n",
    "from collections import OrderedDict\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing for age training \n",
    "data_transforms = {\n",
    "    'train': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.RandomResizedCrop(height=112,width=112,scale=(0.5, 1.0)),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.Blur(p=0.5),#Размытие входного изображения с помощью ядра случайного размера. \n",
    "            A.GaussianBlur(p=0.5),#Размытие входного изображения с помощью фильтра Гаусса со случайным размером ядра. \n",
    "            A.GaussNoise(p=0.5),#Примените гауссовский шум к входному изображению. \n",
    "            A.ISONoise(p=0.5),#Примените шум сенсора камеры. \n",
    "            A.MedianBlur(p=0.5),#Размытие входного изображения с помощью медианного фильтра со случайным линейным размером апертуры.\n",
    "            A.MotionBlur(p=0.5),#Примените размытие движения к входному изображению, используя ядро случайного размера. \n",
    "            A.CLAHE(p=0.5),#Примените коррекцию адаптивной гистограммы с ограничением контраста к входному изображению.\n",
    "            A.Equalize(p=0.5),#Выровняйте гистограмму изображения. \n",
    "        ], p = 1),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.ChannelDropout(p=0.5),#Случайно отбросьте каналы во входном изображении.\n",
    "            A.ChannelShuffle(p=0.5),#Произвольно переставьте каналы входного изображения RGB.\n",
    "            A.InvertImg(p=0.5),#Инвертируйте входное изображение, вычитая значения пикселей из 255\n",
    "            A.Solarize(p=0.5),#Инвертировать все значения пикселей выше порога. \n",
    "            A.ToGray(p=0.5),#Преобразуйте входное изображение RGB в оттенки серого.\n",
    "            A.HueSaturationValue(p=0.5),#Произвольно изменяйте оттенок, насыщенность и значение входного изображения. \n",
    "            A.RandomBrightness(p=0.5),#Произвольно изменяйте яркость входного изображения. \n",
    "            A.RandomBrightnessContrast(p=0.5),#Произвольно изменяйте яркость и контраст входного изображения.\n",
    "            A.RandomContrast(p=0.5)#Произвольно изменяйте контраст входного изображения.\n",
    "        ], p = 1),\n",
    "        A.core.composition.OneOf ([ \n",
    "           A.Downscale(scale_min=0.2, scale_max=0.2,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.3, scale_max=0.3,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.4, scale_max=0.4,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.5, scale_max=0.5,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.6, scale_max=0.6,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.7, scale_max=0.7,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.8, scale_max=0.8,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.9, scale_max=0.9,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.99, scale_max=0.99,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "        ], p = 1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "}\n",
    "\n",
    "from Datasets.age_data_pipeline import MyDataset_age,dataloader_age\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,annotations[x],list(range(1,91)),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=4,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize train images to see how strong augmentations are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs,agr_range,classes = next(iter(dataloaders['train']))\n",
    "\n",
    "imgs = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imgs = imgs.numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "imgs = std * imgs + mean\n",
    "imgs = np.clip(imgs, 0, 1)\n",
    "\n",
    "plt.imshow(imgs)\n",
    "if classes is not None:\n",
    "    plt.title(classes)\n",
    "plt.pause(0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we are going to test the approach when age-head has 30 output units representing probability of its own age range(1-3,..,87-90), then the probability vector is dot producted with the vector indexing each age group, then the result is considered to age estimation.\n",
    "\n",
    "**As we have 2 different age representation at the end of the head (class units probs and regression predicts) we should use the loss function composed of crossentropy loss for age class units and L1 loss for regression pred**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop for age training \n",
    "def train_model(model, classification_criterion,regression_criterion, optimizer, scheduler, losses_ratio = None,num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_class_loss = 0.0\n",
    "            running_regress_loss = 0.0\n",
    "            \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, class_labels,regress_labels in dataloaders[phase]:\n",
    "                class_labels = class_labels.type(torch.FloatTensor)\n",
    "                regress_labels = regress_labels.type(torch.FloatTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                class_labels = class_labels.to(device)\n",
    "                regress_labels = regress_labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    age_group,age_digit = model(inputs)[1]\n",
    "                    batch_regression_loss = regression_criterion(age_digit, regress_labels)\n",
    "                    batch_classification_loss = classification_criterion(age_group, class_labels.long())\n",
    "                    \n",
    "                    \n",
    "                    if (losses_ratio == None):\n",
    "                        if (batch_regression_loss > batch_classification_loss):\n",
    "                            alpha = batch_regression_loss / batch_classification_loss\n",
    "                            loss = alpha * batch_classification_loss + batch_regression_loss\n",
    "                        else:\n",
    "                            alpha = batch_classification_loss / batch_regression_loss\n",
    "                            loss = batch_classification_loss +  alpha * batch_regression_loss\n",
    "                    else:\n",
    "                        loss = losses_ratio[0] * batch_regression_loss + losses_ratio[1] * batch_classification_loss\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_class_loss += batch_classification_loss.item() * inputs.size(0)\n",
    "                running_regress_loss += batch_regression_loss.item() * inputs.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_class_loss = running_class_loss / dataset_sizes[phase]\n",
    "            epoch_regress_loss = running_regress_loss/ dataset_sizes[phase]\n",
    "            avrg_epoch_loss = (epoch_class_loss+epoch_regress_loss)/2\n",
    "\n",
    "            \n",
    "            print('{} Classificatoin_Loss: {:.4f} Regression_Loss: {:.4f}'.format(\n",
    "                phase, epoch_class_loss, epoch_regress_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and avrg_epoch_loss < best_loss:\n",
    "                best_loss = avrg_epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_grouped_age_head(\n",
       "  (encoder): MultiTaskModel(\n",
       "    (encoder): ProxylessNASNets(\n",
       "      (first_conv): ConvLayer(\n",
       "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6(inplace=True)\n",
       "        (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "              (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (3): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (4): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (5): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (7): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (8): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (9): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): ZeroLayer()\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (11): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): ZeroLayer()\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (12): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "              (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (13): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "              (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (15): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (16): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (17): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "              (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (19): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (20): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (21): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "              (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (feature_mix_layer): ConvLayer(\n",
       "        (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6(inplace=True)\n",
       "        (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "      (classifier): Sequential()\n",
       "    )\n",
       "    (fc1): Linear(in_features=1432, out_features=2, bias=True)\n",
       "    (fc2): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "    (fc3): Linear(in_features=1432, out_features=7, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (age_group_head): Linear(in_features=1400, out_features=31, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.MultiTaskModel_grouped_age_head_proxyless import MultiTaskModel_grouped_age_head\n",
    "from utils.MultiTaskModel_proxyless import MultiTaskModel\n",
    "\n",
    "model_proxyless_frozen_backbone = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_frozen_backbone.classifier = nn.Sequential(*list(model_proxyless_frozen_backbone.classifier.children())[:-3])\n",
    "model_proxyless_frozen_backbone = MultiTaskModel(model_proxyless_frozen_backbone)\n",
    "model_proxyless_frozen_backbone.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_proxyless_frozen_backbone = MultiTaskModel_grouped_age_head(model_proxyless_frozen_backbone)\n",
    "model_proxyless_frozen_backbone.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_frozen_age_trained_3_heads.pth',map_location=device))\n",
    "model_proxyless_frozen_backbone.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen the model backbone and verify it on 2 test images. Then trained the model and saw regression loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "#freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_proxyless_frozen_backbone.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_proxyless_frozen_backbone.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_proxyless_frozen_backbone.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_proxyless_frozen_backbone.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_proxyless_frozen_backbone.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_proxyless_frozen_backbone.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6496 Regression_Loss: 12.4145\n",
      "val Classificatoin_Loss: 4.7697 Regression_Loss: 10.2179\n",
      "\n",
      "Epoch 1/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.5815 Regression_Loss: 12.5156\n",
      "val Classificatoin_Loss: 4.6287 Regression_Loss: 10.4207\n",
      "\n",
      "Epoch 2/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.5880 Regression_Loss: 12.3987\n",
      "val Classificatoin_Loss: 4.9101 Regression_Loss: 10.9905\n",
      "\n",
      "Epoch 3/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6135 Regression_Loss: 12.5832\n",
      "val Classificatoin_Loss: 4.6372 Regression_Loss: 10.3926\n",
      "\n",
      "Epoch 4/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6660 Regression_Loss: 12.4139\n",
      "val Classificatoin_Loss: 4.9274 Regression_Loss: 10.4378\n",
      "\n",
      "Epoch 5/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6860 Regression_Loss: 12.5347\n",
      "val Classificatoin_Loss: 4.6212 Regression_Loss: 10.1264\n",
      "\n",
      "Epoch 6/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6504 Regression_Loss: 12.2749\n",
      "val Classificatoin_Loss: 4.6967 Regression_Loss: 10.5396\n",
      "\n",
      "Epoch 7/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6897 Regression_Loss: 12.3543\n",
      "val Classificatoin_Loss: 4.6429 Regression_Loss: 10.0529\n",
      "\n",
      "Epoch 8/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6628 Regression_Loss: 12.0909\n",
      "val Classificatoin_Loss: 4.7200 Regression_Loss: 10.2074\n",
      "\n",
      "Epoch 9/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6591 Regression_Loss: 12.1255\n",
      "val Classificatoin_Loss: 4.6915 Regression_Loss: 9.8442\n",
      "\n",
      "Epoch 10/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6786 Regression_Loss: 12.1337\n",
      "val Classificatoin_Loss: 4.6703 Regression_Loss: 10.1394\n",
      "\n",
      "Epoch 11/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7045 Regression_Loss: 12.1084\n",
      "val Classificatoin_Loss: 4.7436 Regression_Loss: 10.0620\n",
      "\n",
      "Epoch 12/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6822 Regression_Loss: 12.1379\n",
      "val Classificatoin_Loss: 4.6889 Regression_Loss: 10.2048\n",
      "\n",
      "Epoch 13/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6749 Regression_Loss: 12.0698\n",
      "val Classificatoin_Loss: 4.7986 Regression_Loss: 10.2118\n",
      "\n",
      "Epoch 14/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7063 Regression_Loss: 12.0793\n",
      "val Classificatoin_Loss: 4.7519 Regression_Loss: 10.3834\n",
      "\n",
      "Epoch 15/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7066 Regression_Loss: 12.1249\n",
      "val Classificatoin_Loss: 4.7978 Regression_Loss: 10.2136\n",
      "\n",
      "Epoch 16/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7062 Regression_Loss: 12.0518\n",
      "val Classificatoin_Loss: 4.7961 Regression_Loss: 10.3530\n",
      "\n",
      "Epoch 17/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7046 Regression_Loss: 12.1492\n",
      "val Classificatoin_Loss: 4.7168 Regression_Loss: 10.1209\n",
      "\n",
      "Epoch 18/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7394 Regression_Loss: 12.0811\n",
      "val Classificatoin_Loss: 4.7574 Regression_Loss: 9.9278\n",
      "\n",
      "Epoch 19/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7200 Regression_Loss: 12.0835\n",
      "val Classificatoin_Loss: 4.7509 Regression_Loss: 10.2434\n",
      "\n",
      "Epoch 20/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6854 Regression_Loss: 12.1098\n",
      "val Classificatoin_Loss: 4.8125 Regression_Loss: 10.0080\n",
      "\n",
      "Epoch 21/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7032 Regression_Loss: 12.0583\n",
      "val Classificatoin_Loss: 4.7249 Regression_Loss: 10.2134\n",
      "\n",
      "Epoch 22/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6878 Regression_Loss: 12.0774\n",
      "val Classificatoin_Loss: 4.7951 Regression_Loss: 10.0661\n",
      "\n",
      "Epoch 23/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7062 Regression_Loss: 12.1188\n",
      "val Classificatoin_Loss: 4.7362 Regression_Loss: 9.9995\n",
      "\n",
      "Epoch 24/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7007 Regression_Loss: 12.1292\n",
      "val Classificatoin_Loss: 4.7661 Regression_Loss: 10.1138\n",
      "\n",
      "Epoch 25/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6814 Regression_Loss: 12.1540\n",
      "val Classificatoin_Loss: 4.6915 Regression_Loss: 10.0773\n",
      "\n",
      "Epoch 26/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6824 Regression_Loss: 12.0578\n",
      "val Classificatoin_Loss: 4.8296 Regression_Loss: 9.9177\n",
      "\n",
      "Epoch 27/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7067 Regression_Loss: 12.1235\n",
      "val Classificatoin_Loss: 4.7189 Regression_Loss: 10.3048\n",
      "\n",
      "Epoch 28/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7036 Regression_Loss: 12.0199\n",
      "val Classificatoin_Loss: 4.7766 Regression_Loss: 10.1083\n",
      "\n",
      "Epoch 29/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7228 Regression_Loss: 11.9816\n",
      "val Classificatoin_Loss: 4.8068 Regression_Loss: 9.9871\n",
      "\n",
      "Epoch 30/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7015 Regression_Loss: 12.0012\n",
      "val Classificatoin_Loss: 4.7514 Regression_Loss: 10.1196\n",
      "\n",
      "Epoch 31/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6997 Regression_Loss: 12.0865\n",
      "val Classificatoin_Loss: 4.6971 Regression_Loss: 10.0915\n",
      "\n",
      "Epoch 32/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6965 Regression_Loss: 12.0949\n",
      "val Classificatoin_Loss: 4.7967 Regression_Loss: 10.0325\n",
      "\n",
      "Epoch 33/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6874 Regression_Loss: 12.0565\n",
      "val Classificatoin_Loss: 4.7629 Regression_Loss: 10.0389\n",
      "\n",
      "Epoch 34/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6941 Regression_Loss: 12.1295\n",
      "val Classificatoin_Loss: 4.7635 Regression_Loss: 10.0157\n",
      "\n",
      "Epoch 35/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6742 Regression_Loss: 12.1257\n",
      "val Classificatoin_Loss: 4.7743 Regression_Loss: 10.1322\n",
      "\n",
      "Epoch 36/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7011 Regression_Loss: 11.9826\n",
      "val Classificatoin_Loss: 4.7300 Regression_Loss: 10.0302\n",
      "\n",
      "Epoch 37/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7118 Regression_Loss: 12.0150\n",
      "val Classificatoin_Loss: 4.6912 Regression_Loss: 10.2331\n",
      "\n",
      "Epoch 38/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7163 Regression_Loss: 12.0901\n",
      "val Classificatoin_Loss: 4.7445 Regression_Loss: 9.9313\n",
      "\n",
      "Epoch 39/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7110 Regression_Loss: 12.1244\n",
      "val Classificatoin_Loss: 4.7566 Regression_Loss: 10.1120\n",
      "\n",
      "Epoch 40/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7117 Regression_Loss: 12.0368\n",
      "val Classificatoin_Loss: 4.7979 Regression_Loss: 10.0976\n",
      "\n",
      "Epoch 41/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6873 Regression_Loss: 12.0664\n",
      "val Classificatoin_Loss: 4.7902 Regression_Loss: 10.1106\n",
      "\n",
      "Epoch 42/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6939 Regression_Loss: 12.1795\n",
      "val Classificatoin_Loss: 4.8093 Regression_Loss: 10.0430\n",
      "\n",
      "Epoch 43/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7013 Regression_Loss: 12.1492\n",
      "val Classificatoin_Loss: 4.6901 Regression_Loss: 10.3355\n",
      "\n",
      "Epoch 44/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6963 Regression_Loss: 12.1500\n",
      "val Classificatoin_Loss: 4.7514 Regression_Loss: 10.0511\n",
      "\n",
      "Epoch 45/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7024 Regression_Loss: 12.1162\n",
      "val Classificatoin_Loss: 4.7594 Regression_Loss: 9.8776\n",
      "\n",
      "Epoch 46/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7000 Regression_Loss: 12.0815\n",
      "val Classificatoin_Loss: 4.7320 Regression_Loss: 10.3482\n",
      "\n",
      "Epoch 47/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7111 Regression_Loss: 12.0185\n",
      "val Classificatoin_Loss: 4.7282 Regression_Loss: 10.2306\n",
      "\n",
      "Epoch 48/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7025 Regression_Loss: 12.0847\n",
      "val Classificatoin_Loss: 4.7568 Regression_Loss: 10.2426\n",
      "\n",
      "Epoch 49/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7125 Regression_Loss: 12.0113\n",
      "val Classificatoin_Loss: 4.7560 Regression_Loss: 10.0456\n",
      "\n",
      "Epoch 50/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6886 Regression_Loss: 12.0437\n",
      "val Classificatoin_Loss: 4.7794 Regression_Loss: 10.0339\n",
      "\n",
      "Epoch 51/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6886 Regression_Loss: 12.1805\n",
      "val Classificatoin_Loss: 4.7967 Regression_Loss: 10.0076\n",
      "\n",
      "Epoch 52/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7001 Regression_Loss: 12.1494\n",
      "val Classificatoin_Loss: 4.7230 Regression_Loss: 10.1506\n",
      "\n",
      "Epoch 53/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6793 Regression_Loss: 11.9902\n",
      "val Classificatoin_Loss: 4.7563 Regression_Loss: 10.1202\n",
      "\n",
      "Epoch 54/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6963 Regression_Loss: 12.0294\n",
      "val Classificatoin_Loss: 4.7092 Regression_Loss: 10.2010\n",
      "\n",
      "Epoch 55/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7109 Regression_Loss: 12.1249\n",
      "val Classificatoin_Loss: 4.7743 Regression_Loss: 10.1087\n",
      "\n",
      "Epoch 56/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7003 Regression_Loss: 12.0159\n",
      "val Classificatoin_Loss: 4.7433 Regression_Loss: 9.9821\n",
      "\n",
      "Epoch 57/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7092 Regression_Loss: 12.1069\n",
      "val Classificatoin_Loss: 4.7315 Regression_Loss: 10.0781\n",
      "\n",
      "Epoch 58/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6898 Regression_Loss: 12.0115\n",
      "val Classificatoin_Loss: 4.8204 Regression_Loss: 10.1386\n",
      "\n",
      "Epoch 59/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6933 Regression_Loss: 12.1000\n",
      "val Classificatoin_Loss: 4.7533 Regression_Loss: 10.1833\n",
      "\n",
      "Epoch 60/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7214 Regression_Loss: 12.1215\n",
      "val Classificatoin_Loss: 4.7619 Regression_Loss: 10.1255\n",
      "\n",
      "Epoch 61/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7130 Regression_Loss: 12.0723\n",
      "val Classificatoin_Loss: 4.7482 Regression_Loss: 10.1056\n",
      "\n",
      "Epoch 62/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7030 Regression_Loss: 12.0698\n",
      "val Classificatoin_Loss: 4.7742 Regression_Loss: 10.0934\n",
      "\n",
      "Epoch 63/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6895 Regression_Loss: 12.0844\n",
      "val Classificatoin_Loss: 4.7741 Regression_Loss: 10.1843\n",
      "\n",
      "Epoch 64/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7020 Regression_Loss: 12.0014\n",
      "val Classificatoin_Loss: 4.7236 Regression_Loss: 10.0825\n",
      "\n",
      "Epoch 65/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6983 Regression_Loss: 12.1781\n",
      "val Classificatoin_Loss: 4.7225 Regression_Loss: 10.1134\n",
      "\n",
      "Epoch 66/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6945 Regression_Loss: 12.0818\n",
      "val Classificatoin_Loss: 4.7327 Regression_Loss: 10.0959\n",
      "\n",
      "Epoch 67/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7010 Regression_Loss: 12.0826\n",
      "val Classificatoin_Loss: 4.7575 Regression_Loss: 9.9975\n",
      "\n",
      "Epoch 68/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7116 Regression_Loss: 12.0389\n",
      "val Classificatoin_Loss: 4.7801 Regression_Loss: 10.0549\n",
      "\n",
      "Epoch 69/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7020 Regression_Loss: 12.0209\n",
      "val Classificatoin_Loss: 4.7741 Regression_Loss: 10.0749\n",
      "\n",
      "Epoch 70/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6938 Regression_Loss: 11.9777\n",
      "val Classificatoin_Loss: 4.7515 Regression_Loss: 10.2787\n",
      "\n",
      "Epoch 71/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6908 Regression_Loss: 12.0075\n",
      "val Classificatoin_Loss: 4.7278 Regression_Loss: 10.1366\n",
      "\n",
      "Epoch 72/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6758 Regression_Loss: 12.0526\n",
      "val Classificatoin_Loss: 4.7610 Regression_Loss: 10.3223\n",
      "\n",
      "Epoch 73/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6905 Regression_Loss: 12.0607\n",
      "val Classificatoin_Loss: 4.7522 Regression_Loss: 10.2487\n",
      "\n",
      "Epoch 74/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7144 Regression_Loss: 12.0102\n",
      "val Classificatoin_Loss: 4.7414 Regression_Loss: 10.0316\n",
      "\n",
      "Epoch 75/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7021 Regression_Loss: 12.0506\n",
      "val Classificatoin_Loss: 4.7670 Regression_Loss: 10.2172\n",
      "\n",
      "Epoch 76/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6999 Regression_Loss: 11.9971\n",
      "val Classificatoin_Loss: 4.7104 Regression_Loss: 10.2386\n",
      "\n",
      "Epoch 77/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6825 Regression_Loss: 12.1470\n",
      "val Classificatoin_Loss: 4.7320 Regression_Loss: 10.0541\n",
      "\n",
      "Epoch 78/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7172 Regression_Loss: 12.0179\n",
      "val Classificatoin_Loss: 4.7524 Regression_Loss: 10.0641\n",
      "\n",
      "Epoch 79/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6990 Regression_Loss: 11.9991\n",
      "val Classificatoin_Loss: 4.7419 Regression_Loss: 10.0440\n",
      "\n",
      "Epoch 80/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6955 Regression_Loss: 11.9573\n",
      "val Classificatoin_Loss: 4.7567 Regression_Loss: 10.1477\n",
      "\n",
      "Epoch 81/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7106 Regression_Loss: 12.1405\n",
      "val Classificatoin_Loss: 4.7478 Regression_Loss: 10.0720\n",
      "\n",
      "Epoch 82/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7092 Regression_Loss: 11.9880\n",
      "val Classificatoin_Loss: 4.7500 Regression_Loss: 10.2556\n",
      "\n",
      "Epoch 83/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7051 Regression_Loss: 12.0815\n",
      "val Classificatoin_Loss: 4.7459 Regression_Loss: 10.2547\n",
      "\n",
      "Epoch 84/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7133 Regression_Loss: 11.9506\n",
      "val Classificatoin_Loss: 4.7750 Regression_Loss: 9.9659\n",
      "\n",
      "Epoch 85/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7040 Regression_Loss: 11.9794\n",
      "val Classificatoin_Loss: 4.7971 Regression_Loss: 10.0810\n",
      "\n",
      "Epoch 86/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6996 Regression_Loss: 12.0974\n",
      "val Classificatoin_Loss: 4.7646 Regression_Loss: 10.3051\n",
      "\n",
      "Epoch 87/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7020 Regression_Loss: 12.1054\n",
      "val Classificatoin_Loss: 4.7282 Regression_Loss: 10.1081\n",
      "\n",
      "Epoch 88/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6806 Regression_Loss: 11.9551\n",
      "val Classificatoin_Loss: 4.7369 Regression_Loss: 10.1449\n",
      "\n",
      "Epoch 89/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6913 Regression_Loss: 12.2134\n",
      "val Classificatoin_Loss: 4.7246 Regression_Loss: 10.1037\n",
      "\n",
      "Epoch 90/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7014 Regression_Loss: 11.9342\n",
      "val Classificatoin_Loss: 4.7268 Regression_Loss: 10.1083\n",
      "\n",
      "Epoch 91/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7234 Regression_Loss: 12.1416\n",
      "val Classificatoin_Loss: 4.7402 Regression_Loss: 10.2719\n",
      "\n",
      "Epoch 92/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6970 Regression_Loss: 11.9303\n",
      "val Classificatoin_Loss: 4.7830 Regression_Loss: 10.0885\n",
      "\n",
      "Epoch 93/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7042 Regression_Loss: 12.1095\n",
      "val Classificatoin_Loss: 4.7644 Regression_Loss: 10.0274\n",
      "\n",
      "Epoch 94/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7210 Regression_Loss: 12.2102\n",
      "val Classificatoin_Loss: 4.7826 Regression_Loss: 10.1873\n",
      "\n",
      "Epoch 95/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6985 Regression_Loss: 12.1498\n",
      "val Classificatoin_Loss: 4.7853 Regression_Loss: 10.0212\n",
      "\n",
      "Epoch 96/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6992 Regression_Loss: 12.1033\n",
      "val Classificatoin_Loss: 4.7575 Regression_Loss: 10.0882\n",
      "\n",
      "Epoch 97/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7075 Regression_Loss: 12.0178\n",
      "val Classificatoin_Loss: 4.7419 Regression_Loss: 10.0775\n",
      "\n",
      "Epoch 98/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7025 Regression_Loss: 12.0697\n",
      "val Classificatoin_Loss: 4.7535 Regression_Loss: 9.9656\n",
      "\n",
      "Epoch 99/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7033 Regression_Loss: 12.0447\n",
      "val Classificatoin_Loss: 4.7087 Regression_Loss: 10.2732\n",
      "\n",
      "Epoch 100/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6994 Regression_Loss: 12.0895\n",
      "val Classificatoin_Loss: 4.7697 Regression_Loss: 10.2396\n",
      "\n",
      "Epoch 101/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6881 Regression_Loss: 12.1201\n",
      "val Classificatoin_Loss: 4.7738 Regression_Loss: 10.2040\n",
      "\n",
      "Epoch 102/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7168 Regression_Loss: 12.0612\n",
      "val Classificatoin_Loss: 4.7773 Regression_Loss: 10.1153\n",
      "\n",
      "Epoch 103/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7153 Regression_Loss: 12.1928\n",
      "val Classificatoin_Loss: 4.7777 Regression_Loss: 9.9840\n",
      "\n",
      "Epoch 104/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7082 Regression_Loss: 12.0434\n",
      "val Classificatoin_Loss: 4.7459 Regression_Loss: 9.9621\n",
      "\n",
      "Epoch 105/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6954 Regression_Loss: 12.0183\n",
      "val Classificatoin_Loss: 4.7547 Regression_Loss: 10.1523\n",
      "\n",
      "Epoch 106/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7075 Regression_Loss: 11.9969\n",
      "val Classificatoin_Loss: 4.7247 Regression_Loss: 10.0234\n",
      "\n",
      "Epoch 107/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7076 Regression_Loss: 12.0213\n",
      "val Classificatoin_Loss: 4.8008 Regression_Loss: 10.2169\n",
      "\n",
      "Epoch 108/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6987 Regression_Loss: 12.1453\n",
      "val Classificatoin_Loss: 4.7855 Regression_Loss: 9.9831\n",
      "\n",
      "Epoch 109/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6949 Regression_Loss: 12.0361\n",
      "val Classificatoin_Loss: 4.7456 Regression_Loss: 10.2439\n",
      "\n",
      "Epoch 110/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7002 Regression_Loss: 12.0154\n",
      "val Classificatoin_Loss: 4.7868 Regression_Loss: 10.1734\n",
      "\n",
      "Epoch 111/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7010 Regression_Loss: 12.1738\n",
      "val Classificatoin_Loss: 4.8051 Regression_Loss: 10.0418\n",
      "\n",
      "Epoch 112/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6946 Regression_Loss: 12.1021\n",
      "val Classificatoin_Loss: 4.7500 Regression_Loss: 10.0550\n",
      "\n",
      "Epoch 113/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6913 Regression_Loss: 11.9453\n",
      "val Classificatoin_Loss: 4.7827 Regression_Loss: 10.1687\n",
      "\n",
      "Epoch 114/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6897 Regression_Loss: 12.1253\n",
      "val Classificatoin_Loss: 4.7226 Regression_Loss: 10.1664\n",
      "\n",
      "Epoch 115/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6780 Regression_Loss: 12.0007\n",
      "val Classificatoin_Loss: 4.7680 Regression_Loss: 10.1341\n",
      "\n",
      "Epoch 116/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7004 Regression_Loss: 12.0384\n",
      "val Classificatoin_Loss: 4.7352 Regression_Loss: 10.1346\n",
      "\n",
      "Epoch 117/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6952 Regression_Loss: 12.1000\n",
      "val Classificatoin_Loss: 4.7715 Regression_Loss: 10.1031\n",
      "\n",
      "Epoch 118/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7033 Regression_Loss: 12.0599\n",
      "val Classificatoin_Loss: 4.7615 Regression_Loss: 10.1450\n",
      "\n",
      "Epoch 119/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6832 Regression_Loss: 12.0586\n",
      "val Classificatoin_Loss: 4.7893 Regression_Loss: 10.1542\n",
      "\n",
      "Epoch 120/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7142 Regression_Loss: 12.1190\n",
      "val Classificatoin_Loss: 4.8019 Regression_Loss: 10.0113\n",
      "\n",
      "Epoch 121/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7109 Regression_Loss: 12.1223\n",
      "val Classificatoin_Loss: 4.7461 Regression_Loss: 10.2500\n",
      "\n",
      "Epoch 122/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6798 Regression_Loss: 11.9890\n",
      "val Classificatoin_Loss: 4.7181 Regression_Loss: 10.0873\n",
      "\n",
      "Epoch 123/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7010 Regression_Loss: 11.9532\n",
      "val Classificatoin_Loss: 4.7200 Regression_Loss: 10.2748\n",
      "\n",
      "Epoch 124/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7077 Regression_Loss: 12.2024\n",
      "val Classificatoin_Loss: 4.6975 Regression_Loss: 10.0994\n",
      "\n",
      "Epoch 125/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6897 Regression_Loss: 12.1459\n",
      "val Classificatoin_Loss: 4.7433 Regression_Loss: 9.8890\n",
      "\n",
      "Epoch 126/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7106 Regression_Loss: 12.1089\n",
      "val Classificatoin_Loss: 4.7886 Regression_Loss: 10.0767\n",
      "\n",
      "Epoch 127/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6758 Regression_Loss: 12.1379\n",
      "val Classificatoin_Loss: 4.7415 Regression_Loss: 10.2321\n",
      "\n",
      "Epoch 128/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6811 Regression_Loss: 12.0065\n",
      "val Classificatoin_Loss: 4.6995 Regression_Loss: 9.9459\n",
      "\n",
      "Epoch 129/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6952 Regression_Loss: 12.1510\n",
      "val Classificatoin_Loss: 4.7228 Regression_Loss: 10.1691\n",
      "\n",
      "Epoch 130/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7279 Regression_Loss: 12.0325\n",
      "val Classificatoin_Loss: 4.7328 Regression_Loss: 10.1639\n",
      "\n",
      "Epoch 131/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7090 Regression_Loss: 12.0251\n",
      "val Classificatoin_Loss: 4.7114 Regression_Loss: 10.0598\n",
      "\n",
      "Epoch 132/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6597 Regression_Loss: 11.9819\n",
      "val Classificatoin_Loss: 4.7696 Regression_Loss: 10.0831\n",
      "\n",
      "Epoch 133/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6873 Regression_Loss: 11.9044\n",
      "val Classificatoin_Loss: 4.7692 Regression_Loss: 9.9732\n",
      "\n",
      "Epoch 134/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6792 Regression_Loss: 12.0682\n",
      "val Classificatoin_Loss: 4.7634 Regression_Loss: 10.1458\n",
      "\n",
      "Epoch 135/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6964 Regression_Loss: 12.0677\n",
      "val Classificatoin_Loss: 4.7804 Regression_Loss: 10.0543\n",
      "\n",
      "Epoch 136/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7015 Regression_Loss: 12.0670\n",
      "val Classificatoin_Loss: 4.6807 Regression_Loss: 10.0314\n",
      "\n",
      "Epoch 137/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7082 Regression_Loss: 12.1075\n",
      "val Classificatoin_Loss: 4.7562 Regression_Loss: 10.3189\n",
      "\n",
      "Epoch 138/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7048 Regression_Loss: 12.1283\n",
      "val Classificatoin_Loss: 4.7644 Regression_Loss: 10.0650\n",
      "\n",
      "Epoch 139/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7014 Regression_Loss: 12.0607\n",
      "val Classificatoin_Loss: 4.7742 Regression_Loss: 9.9139\n",
      "\n",
      "Epoch 140/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7021 Regression_Loss: 11.9784\n",
      "val Classificatoin_Loss: 4.7826 Regression_Loss: 10.1810\n",
      "\n",
      "Epoch 141/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7099 Regression_Loss: 12.0240\n",
      "val Classificatoin_Loss: 4.7213 Regression_Loss: 10.1413\n",
      "\n",
      "Epoch 142/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7026 Regression_Loss: 12.1463\n",
      "val Classificatoin_Loss: 4.7724 Regression_Loss: 10.1414\n",
      "\n",
      "Epoch 143/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6828 Regression_Loss: 12.2005\n",
      "val Classificatoin_Loss: 4.7904 Regression_Loss: 10.2352\n",
      "\n",
      "Epoch 144/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7178 Regression_Loss: 12.0222\n",
      "val Classificatoin_Loss: 4.7140 Regression_Loss: 10.2082\n",
      "\n",
      "Epoch 145/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7118 Regression_Loss: 11.9788\n",
      "val Classificatoin_Loss: 4.7473 Regression_Loss: 10.2275\n",
      "\n",
      "Epoch 146/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6841 Regression_Loss: 12.0615\n",
      "val Classificatoin_Loss: 4.7472 Regression_Loss: 10.0819\n",
      "\n",
      "Epoch 147/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.6998 Regression_Loss: 12.1335\n",
      "val Classificatoin_Loss: 4.7678 Regression_Loss: 10.1003\n",
      "\n",
      "Epoch 148/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7167 Regression_Loss: 12.1243\n",
      "val Classificatoin_Loss: 4.7436 Regression_Loss: 10.2004\n",
      "\n",
      "Epoch 149/149\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7036 Regression_Loss: 12.0758\n",
      "val Classificatoin_Loss: 4.7709 Regression_Loss: 10.0234\n",
      "\n",
      "Training complete in 250m 46s\n",
      "Best val loss: 7.267849\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_proxyless_frozen_backbone.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "model_proxyless_frozen_backbone = train_model(model_proxyless_frozen_backbone, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_proxyless_frozen_backbone.state_dict(),'/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_frozen_age_trained_3_heads.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1700,  0.4067]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "#Validating on 1st image that all the gender-trained parameters haven't changed \n",
    "tensor = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "pic = PIL.Image.open('/storage_labs/3030/BelyakovM/FaceMask_presence/ds/train/wo_mask/sibur/0/1_2020-07-10_19-18-18.jpg')\n",
    "#pic = data_transforms['val'](image = pic)\n",
    "pic = tensor(pic)\n",
    "pic = pic.unsqueeze(0)\n",
    "pic = pic.to(device)\n",
    "model_proxyless_frozen_backbone.to(device)\n",
    "outputs = model_proxyless_frozen_backbone(pic)\n",
    "_, preds = torch.max(outputs[0], 1)\n",
    "\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1195, 0.4292]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "#Validating on 2nd image that all the gender-trained parameters haven't changed\n",
    "tensor = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "pic = PIL.Image.open('/storage_labs/3030/BelyakovM/FaceMask_presence/ds/train/wo_mask/sibur/0/4853_2020-08-12_09-49-32.jpg')\n",
    "pic = tensor(pic)\n",
    "pic = pic.unsqueeze(0)\n",
    "pic = pic.to(device)\n",
    "model_proxyless_frozen_backbone.to(device)\n",
    "outputs = model_proxyless_frozen_backbone(pic)\n",
    "_, preds = torch.max(outputs[0], 1)\n",
    "\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare frozen proxyless backbone with resnet18 frozen backbone whet it comes to only age-head training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_baseline(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential()\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=90, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=7, bias=True)\n",
       "  (age_group_head): Linear(in_features=90, out_features=31, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only training of resnet18-baseline age-head \n",
    "from utils.MultiTaskModel_baseline import MultiTaskModel_baseline\n",
    "\n",
    "model_resnet18_frozen_backbone = models.resnet18(pretrained = True)\n",
    "model_resnet18_frozen_backbone.fc = nn.Sequential(*list(model_resnet18_frozen_backbone.fc.children())[:-3])\n",
    "model_resnet18_frozen_backbone = MultiTaskModel_baseline(model_resnet18_frozen_backbone)\n",
    "\n",
    "model_resnet18_frozen_backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "for module in model_resnet18_frozen_backbone.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_resnet18_frozen_backbone.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_resnet18_frozen_backbone.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_resnet18_frozen_backbone.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_resnet18_frozen_backbone.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_resnet18_frozen_backbone.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/13\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9286 Regression_Loss: 17.8083\n",
      "val Classificatoin_Loss: 3.7560 Regression_Loss: 13.5887\n",
      "\n",
      "Epoch 1/13\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9904 Regression_Loss: 16.1013\n",
      "val Classificatoin_Loss: 3.8600 Regression_Loss: 12.9088\n",
      "\n",
      "Epoch 2/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.0240 Regression_Loss: 15.6662\n",
      "val Classificatoin_Loss: 3.8370 Regression_Loss: 13.3476\n",
      "\n",
      "Epoch 3/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.0975 Regression_Loss: 15.5192\n",
      "val Classificatoin_Loss: 3.9120 Regression_Loss: 12.7324\n",
      "\n",
      "Epoch 4/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.2055 Regression_Loss: 15.2444\n",
      "val Classificatoin_Loss: 3.9437 Regression_Loss: 13.2061\n",
      "\n",
      "Epoch 5/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.1960 Regression_Loss: 15.0251\n",
      "val Classificatoin_Loss: 4.2497 Regression_Loss: 12.4198\n",
      "\n",
      "Epoch 6/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.2517 Regression_Loss: 14.8936\n",
      "val Classificatoin_Loss: 4.1818 Regression_Loss: 12.3079\n",
      "\n",
      "Epoch 7/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.2432 Regression_Loss: 14.8662\n",
      "val Classificatoin_Loss: 4.1988 Regression_Loss: 12.2773\n",
      "\n",
      "Epoch 8/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.2758 Regression_Loss: 14.7018\n",
      "val Classificatoin_Loss: 4.2355 Regression_Loss: 12.2527\n",
      "\n",
      "Epoch 9/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.3219 Regression_Loss: 14.6998\n",
      "val Classificatoin_Loss: 4.2915 Regression_Loss: 12.4894\n",
      "\n",
      "Epoch 10/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.3720 Regression_Loss: 14.6382\n",
      "val Classificatoin_Loss: 4.2974 Regression_Loss: 12.5795\n",
      "\n",
      "Epoch 11/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.4274 Regression_Loss: 14.5702\n",
      "val Classificatoin_Loss: 4.3742 Regression_Loss: 12.2649\n",
      "\n",
      "Epoch 12/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.4165 Regression_Loss: 14.6523\n",
      "val Classificatoin_Loss: 4.3604 Regression_Loss: 12.5225\n",
      "\n",
      "Epoch 13/13\n",
      "----------\n",
      "train Classificatoin_Loss: 4.4402 Regression_Loss: 14.6872\n",
      "val Classificatoin_Loss: 4.3262 Regression_Loss: 12.2694\n",
      "\n",
      "Training complete in 23m 11s\n",
      "Best val loss: 8.238085\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_resnet18_frozen_backbone.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_resnet18_frozen_backbone = train_model(model_resnet18_frozen_backbone, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems like proxyless is able to predict age more precisely by 2 year on average \n",
    "\n",
    "### Next, we will see how accurate the models can predict age if trained entirely on age problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    }
   ],
   "source": [
    "from utils.MultiTaskModel_grouped_age_head_proxyless import MultiTaskModel_grouped_age_head\n",
    "from utils.MultiTaskModel_proxyless import MultiTaskModel\n",
    "\n",
    "model_proxyless_entirely_trained = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_entirely_trained.classifier = nn.Sequential(*list(model_proxyless_entirely_trained.classifier.children())[:-3])\n",
    "model_proxyless_entirely_trained = MultiTaskModel(model_proxyless_entirely_trained)\n",
    "\n",
    "model_proxyless_entirely_trained.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_proxyless_entirely_trained = MultiTaskModel_grouped_age_head(model_proxyless_entirely_trained)\n",
    "model_proxyless_entirely_trained.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_age_trained_3_heads.pth',map_location=device))\n",
    "model_proxyless_entirely_trained = model_proxyless_entirely_trained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0222 Regression_Loss: 6.6122\n",
      "val Classificatoin_Loss: 2.9361 Regression_Loss: 6.9793\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0098 Regression_Loss: 6.5539\n",
      "val Classificatoin_Loss: 3.1233 Regression_Loss: 7.2251\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0086 Regression_Loss: 6.4846\n",
      "val Classificatoin_Loss: 2.9325 Regression_Loss: 6.5183\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9815 Regression_Loss: 6.4546\n",
      "val Classificatoin_Loss: 2.9355 Regression_Loss: 7.0199\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9898 Regression_Loss: 6.4036\n",
      "val Classificatoin_Loss: 2.9345 Regression_Loss: 6.6375\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0123 Regression_Loss: 6.5584\n",
      "val Classificatoin_Loss: 3.0100 Regression_Loss: 6.9943\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0075 Regression_Loss: 6.3125\n",
      "val Classificatoin_Loss: 3.0112 Regression_Loss: 7.0738\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9432 Regression_Loss: 5.9577\n",
      "val Classificatoin_Loss: 2.9349 Regression_Loss: 6.3056\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9358 Regression_Loss: 5.8421\n",
      "val Classificatoin_Loss: 2.9216 Regression_Loss: 6.3070\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9151 Regression_Loss: 5.7932\n",
      "val Classificatoin_Loss: 2.9229 Regression_Loss: 6.2716\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9312 Regression_Loss: 5.7989\n",
      "val Classificatoin_Loss: 2.9941 Regression_Loss: 6.3636\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9044 Regression_Loss: 5.7646\n",
      "val Classificatoin_Loss: 2.8602 Regression_Loss: 6.2712\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9267 Regression_Loss: 5.6833\n",
      "val Classificatoin_Loss: 2.9449 Regression_Loss: 6.1927\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9187 Regression_Loss: 5.6715\n",
      "val Classificatoin_Loss: 2.9765 Regression_Loss: 6.2517\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9098 Regression_Loss: 5.6142\n",
      "val Classificatoin_Loss: 2.9263 Regression_Loss: 6.1884\n",
      "\n",
      "Training complete in 22m 29s\n",
      "Best val loss: 4.557349\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_proxyless_entirely_trained.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_proxyless_entirely_trained = train_model(model_proxyless_entirely_trained, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_proxyless_entirely_trained.state_dict(),'/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_age_trained_3_heads.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_baseline(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential()\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=90, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=7, bias=True)\n",
       "  (age_group_head): Linear(in_features=90, out_features=31, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training of resnet18-baseline entirely  \n",
    "from utils.MultiTaskModel_baseline import MultiTaskModel_baseline\n",
    "\n",
    "model_resnet18_entirely_trained = models.resnet18(pretrained = True)\n",
    "model_resnet18_entirely_trained.fc = nn.Sequential(*list(model_resnet18_entirely_trained.fc.children())[:-3])\n",
    "model_resnet18_entirely_trained = MultiTaskModel_baseline(model_resnet18_entirely_trained)\n",
    "\n",
    "model_resnet18_entirely_trained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Classificatoin_Loss: 3.9272 Regression_Loss: 18.2065\n",
      "val Classificatoin_Loss: 3.6288 Regression_Loss: 11.1864\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.7504 Regression_Loss: 12.2583\n",
      "val Classificatoin_Loss: 3.4483 Regression_Loss: 9.0381\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.7597 Regression_Loss: 10.5774\n",
      "val Classificatoin_Loss: 3.5435 Regression_Loss: 8.3888\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.8265 Regression_Loss: 9.7596\n",
      "val Classificatoin_Loss: 3.4168 Regression_Loss: 8.8448\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.8135 Regression_Loss: 9.2476\n",
      "val Classificatoin_Loss: 3.3498 Regression_Loss: 8.1534\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.7880 Regression_Loss: 8.9575\n",
      "val Classificatoin_Loss: 3.5571 Regression_Loss: 7.9151\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.8281 Regression_Loss: 8.4207\n",
      "val Classificatoin_Loss: 3.4573 Regression_Loss: 7.7976\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9311 Regression_Loss: 7.6771\n",
      "val Classificatoin_Loss: 3.6920 Regression_Loss: 7.2664\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9159 Regression_Loss: 7.5400\n",
      "val Classificatoin_Loss: 3.5346 Regression_Loss: 7.3471\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9619 Regression_Loss: 7.4512\n",
      "val Classificatoin_Loss: 3.6668 Regression_Loss: 7.0502\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9600 Regression_Loss: 7.4557\n",
      "val Classificatoin_Loss: 3.5815 Regression_Loss: 7.0511\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9298 Regression_Loss: 7.3209\n",
      "val Classificatoin_Loss: 3.6156 Regression_Loss: 7.1450\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9790 Regression_Loss: 7.3739\n",
      "val Classificatoin_Loss: 3.5824 Regression_Loss: 6.9945\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9684 Regression_Loss: 7.2285\n",
      "val Classificatoin_Loss: 3.6792 Regression_Loss: 6.9441\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Classificatoin_Loss: 3.9878 Regression_Loss: 7.2054\n",
      "val Classificatoin_Loss: 3.5458 Regression_Loss: 7.0612\n",
      "\n",
      "Training complete in 23m 55s\n",
      "Best val loss: 5.288437\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_resnet18_entirely_trained.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_resnet18_entirely_trained = train_model(model_resnet18_entirely_trained, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proxyless copes better by 1 year\n",
    "\n",
    "\n",
    "### Further, we compute statistic for proxyless trained entirely and head-trained: for each age the most frequently confused ages, average confused age, mean deviation of gt-age and predicted age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing entirely trained proxyless on \"over-dataset\" val set\n",
    "dsdir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset/val'\n",
    "path2save = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset/proxyless_confused/Entirely_trained'\n",
    "model_proxyless_entirely_trained.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_age_trained_3_heads.pth'))\n",
    "transformations = transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "net_predictions = [[] for i in range(1,91)]\n",
    "count = 0\n",
    "\n",
    "for age_gt in os.listdir(dsdir):\n",
    "    for img_path in os.listdir(os.path.join(dsdir,age_gt)):\n",
    "        count += 1\n",
    "        img = default_loader(os.path.join(dsdir,age_gt,img_path))\n",
    "        img = transformations(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        _,age_pred = model_proxyless_entirely_trained(img)[1]\n",
    "        #if age_gt[0] == '0': age_gt = age_gt.replace('0','')\n",
    "        net_predictions[round(age_pred.item())-1].append(int(age_gt))\n",
    "        if age_pred.item() < 9.5: \n",
    "            age_pred = '0'+ str(round(age_pred.item())) \n",
    "        else: \n",
    "            age_pred = str(round(age_pred.item()))\n",
    "        img_pil = default_loader(os.path.join(dsdir,age_gt,img_path))\n",
    "        img_pil = img_pil.save(os.path.join(path2save,age_pred,'gt-label:'+age_gt+'_pred:'+age_pred+'number:'+str(count)+'.jpg'))\n",
    "        #print('Gt:'+age_gt+'pred:'+age_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top frequent ages in 1:[1, 2, 3, 4]. Average predicted age is 2.5,mean deviation is 1.8708286933869707\n",
      "Top frequent ages in 2:[1, 2, 3, 4]. Average predicted age is 2.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 3:[1, 2, 3, 4]. Average predicted age is 2.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 4:[3, 4, 2, 5]. Average predicted age is 3.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 5:[2, 4, 3, 7]. Average predicted age is 4.0,mean deviation is 2.1213203435596424\n",
      "Top frequent ages in 6:[5, 7, 6, 4]. Average predicted age is 5.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 7:[6, 4, 9, 2]. Average predicted age is 5.25,mean deviation is 3.122498999199199\n",
      "Top frequent ages in 8:[8, 10, 4, 6]. Average predicted age is 7.0,mean deviation is 2.449489742783178\n",
      "Top frequent ages in 9:[10, 8, 9, 5]. Average predicted age is 8.0,mean deviation is 2.1213203435596424\n",
      "Top frequent ages in 10:[9, 10, 8, 2]. Average predicted age is 7.25,mean deviation is 4.153311931459037\n",
      "Top frequent ages in 11:[9, 13, 8, 7]. Average predicted age is 9.25,mean deviation is 2.8722813232690143\n",
      "Top frequent ages in 12:[13, 14, 11, 12]. Average predicted age is 12.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 13:[12, 10, 8, 13]. Average predicted age is 10.75,mean deviation is 2.958039891549808\n",
      "Top frequent ages in 14:[15, 12, 22, 26]. Average predicted age is 18.75,mean deviation is 7.297259759663212\n",
      "Top frequent ages in 15:[16, 12, 21, 25]. Average predicted age is 18.5,mean deviation is 6.041522986797286\n",
      "Top frequent ages in 16:[16, 18, 27, 8]. Average predicted age is 17.25,mean deviation is 6.87386354243376\n",
      "Top frequent ages in 17:[16, 19, 18, 32]. Average predicted age is 21.25,mean deviation is 7.599342076785332\n",
      "Top frequent ages in 18:[22, 17, 20, 16]. Average predicted age is 18.75,mean deviation is 2.5\n",
      "Top frequent ages in 19:[24, 18, 27, 16]. Average predicted age is 21.25,mean deviation is 4.9749371855331\n",
      "Top frequent ages in 20:[27, 24, 28, 20]. Average predicted age is 24.75,mean deviation is 5.678908345800274\n",
      "Top frequent ages in 21:[24, 26, 27, 23]. Average predicted age is 25.0,mean deviation is 4.301162633521313\n",
      "Top frequent ages in 22:[24, 25, 26, 27]. Average predicted age is 25.5,mean deviation is 3.6742346141747673\n",
      "Top frequent ages in 23:[26, 24, 27, 29]. Average predicted age is 26.5,mean deviation is 3.9370039370059056\n",
      "Top frequent ages in 24:[26, 28, 23, 27]. Average predicted age is 26.0,mean deviation is 2.7386127875258306\n",
      "Top frequent ages in 25:[26, 24, 29, 21]. Average predicted age is 25.0,mean deviation is 2.9154759474226504\n",
      "Top frequent ages in 26:[26, 27, 29, 25]. Average predicted age is 26.75,mean deviation is 1.6583123951777\n",
      "Top frequent ages in 27:[26, 31, 27, 23]. Average predicted age is 26.75,mean deviation is 2.8722813232690143\n",
      "Top frequent ages in 28:[26, 27, 29, 24]. Average predicted age is 26.5,mean deviation is 2.345207879911715\n",
      "Top frequent ages in 29:[26, 25, 23, 32]. Average predicted age is 26.5,mean deviation is 4.183300132670378\n",
      "Top frequent ages in 30:[28, 26, 27, 31]. Average predicted age is 28.0,mean deviation is 2.7386127875258306\n",
      "Top frequent ages in 31:[26, 28, 35, 27]. Average predicted age is 29.0,mean deviation is 4.06201920231798\n",
      "Top frequent ages in 32:[26, 32, 29, 27]. Average predicted age is 28.5,mean deviation is 4.183300132670378\n",
      "Top frequent ages in 33:[26, 28, 31, 32]. Average predicted age is 29.25,mean deviation is 4.444097208657794\n",
      "Top frequent ages in 34:[32, 36, 26, 28]. Average predicted age is 30.5,mean deviation is 5.196152422706632\n",
      "Top frequent ages in 35:[34, 26, 32, 27]. Average predicted age is 29.75,mean deviation is 6.224949798994366\n",
      "Top frequent ages in 36:[36, 28, 33, 37]. Average predicted age is 33.5,mean deviation is 4.301162633521313\n",
      "Top frequent ages in 37:[34, 35, 28, 29]. Average predicted age is 31.5,mean deviation is 6.284902544988268\n",
      "Top frequent ages in 38:[35, 26, 33, 36]. Average predicted age is 32.5,mean deviation is 6.745368781616021\n",
      "Top frequent ages in 39:[36, 35, 38, 39]. Average predicted age is 37.0,mean deviation is 2.5495097567963922\n",
      "Top frequent ages in 40:[32, 34, 46, 35]. Average predicted age is 36.75,mean deviation is 6.34428877022476\n",
      "Top frequent ages in 41:[34, 36, 35, 30]. Average predicted age is 33.75,mean deviation is 7.599342076785332\n",
      "Top frequent ages in 42:[38, 36, 43, 37]. Average predicted age is 38.5,mean deviation is 4.415880433163924\n",
      "Top frequent ages in 43:[38, 35, 40, 43]. Average predicted age is 39.0,mean deviation is 4.949747468305833\n",
      "Top frequent ages in 44:[39, 50, 35, 37]. Average predicted age is 40.25,mean deviation is 6.910137480542627\n",
      "Top frequent ages in 45:[37, 42, 29, 30]. Average predicted age is 34.5,mean deviation is 11.76860229593982\n",
      "Top frequent ages in 46:[50, 43, 38, 40]. Average predicted age is 42.75,mean deviation is 5.5901699437494745\n",
      "Top frequent ages in 47:[46, 53, 45, 39]. Average predicted age is 45.75,mean deviation is 5.123475382979799\n",
      "Top frequent ages in 48:[45, 35, 40, 41]. Average predicted age is 40.25,mean deviation is 8.52936105461599\n",
      "Top frequent ages in 49:[42, 51, 54, 46]. Average predicted age is 48.25,mean deviation is 4.663689526544408\n",
      "Top frequent ages in 50:[56, 44, 55, 42]. Average predicted age is 49.25,mean deviation is 6.34428877022476\n",
      "Top frequent ages in 51:[42, 51, 56, 57]. Average predicted age is 51.5,mean deviation is 5.958187643906492\n",
      "Top frequent ages in 52:[43, 47, 49, 50]. Average predicted age is 47.25,mean deviation is 5.454356057317857\n",
      "Top frequent ages in 53:[45, 52, 56, 60]. Average predicted age is 53.25,mean deviation is 5.545268253204709\n",
      "Top frequent ages in 54:[49, 54, 52, 60]. Average predicted age is 53.75,mean deviation is 4.031128874149275\n",
      "Top frequent ages in 55:[50, 51, 54, 56]. Average predicted age is 52.75,mean deviation is 3.278719262151\n",
      "Top frequent ages in 56:[51, 47, 53, 43]. Average predicted age is 48.5,mean deviation is 8.426149773176359\n",
      "Top frequent ages in 57:[59, 52, 56, 54]. Average predicted age is 55.25,mean deviation is 3.122498999199199\n",
      "Top frequent ages in 58:[59, 56, 58, 43]. Average predicted age is 54.0,mean deviation is 7.582875444051551\n",
      "Top frequent ages in 59:[56, 55, 57, 54]. Average predicted age is 55.5,mean deviation is 3.6742346141747673\n",
      "Top frequent ages in 60:[60, 57, 59, 47]. Average predicted age is 55.75,mean deviation is 6.689544080129826\n",
      "Top frequent ages in 61:[65, 66, 52, 43]. Average predicted age is 56.5,mean deviation is 10.559356040971437\n",
      "Top frequent ages in 62:[54, 58, 52, 62]. Average predicted age is 56.5,mean deviation is 6.708203932499369\n",
      "Top frequent ages in 63:[61, 64, 54, 56]. Average predicted age is 58.75,mean deviation is 5.809475019311125\n",
      "Top frequent ages in 64:[60, 61, 65, 75]. Average predicted age is 65.25,mean deviation is 6.06217782649107\n",
      "Top frequent ages in 65:[65, 61, 54, 60]. Average predicted age is 60.0,mean deviation is 6.363961030678928\n",
      "Top frequent ages in 66:[61, 53, 60, 65]. Average predicted age is 59.75,mean deviation is 7.599342076785332\n",
      "Top frequent ages in 67:[66, 54, 65, 69]. Average predicted age is 63.5,mean deviation is 6.670832032063167\n",
      "Top frequent ages in 68:[75, 80, 66, 70]. Average predicted age is 72.75,mean deviation is 7.088723439378913\n",
      "Top frequent ages in 69:[68, 67, 69, 74]. Average predicted age is 69.5,mean deviation is 2.7386127875258306\n",
      "Top frequent ages in 70:[75, 58, 60, 62]. Average predicted age is 63.75,mean deviation is 9.12414379544733\n",
      "Top frequent ages in 71:[69, 61, 78, 80]. Average predicted age is 72.0,mean deviation is 7.648529270389178\n",
      "Top frequent ages in 72:[70, 68, 71, 76]. Average predicted age is 71.25,mean deviation is 3.0413812651491097\n",
      "Top frequent ages in 73:[65, 66, 68, 69]. Average predicted age is 67.0,mean deviation is 6.2048368229954285\n",
      "Top frequent ages in 74:[80, 67, 74, 75]. Average predicted age is 74.0,mean deviation is 4.636809247747852\n",
      "Top frequent ages in 75:[75, 77, 68, 53]. Average predicted age is 68.25,mean deviation is 11.586630226256467\n",
      "Top frequent ages in 76:[73, 78, 75, 76]. Average predicted age is 75.5,mean deviation is 1.8708286933869707\n",
      "Top frequent ages in 77:[67, 69, 77, 78]. Average predicted age is 72.75,mean deviation is 6.422616289332565\n",
      "Top frequent ages in 78:[80, 76, 79, 72]. Average predicted age is 76.75,mean deviation is 3.3541019662496847\n",
      "Top frequent ages in 79:[64, 70, 78, 48]. Average predicted age is 65.0,mean deviation is 17.804493814764857\n",
      "Top frequent ages in 80:[80, 74, 85, 61]. Average predicted age is 75.0,mean deviation is 10.27131929208707\n",
      "Top frequent ages in 81:[90, 79, 80, 81]. Average predicted age is 82.5,mean deviation is 4.636809247747852\n",
      "Top frequent ages in 82:[80, 72, 75, 82]. Average predicted age is 77.25,mean deviation is 6.18465843842649\n",
      "Top frequent ages in 83:[85, 65, 74, 77]. Average predicted age is 75.25,mean deviation is 10.547511554864494\n",
      "Top frequent ages in 84:[85, 90, 78, 82]. Average predicted age is 83.75,mean deviation is 4.387482193696061\n",
      "Top frequent ages in 85:[88, 83, 84]. Average predicted age is 85.0,mean deviation is 2.160246899469287\n",
      "Top frequent ages in 86:[89, 81, 85, 61]. Average predicted age is 79.0,mean deviation is 12.84523257866513\n",
      "Top frequent ages in 87:[90, 1, 76, 79]. Average predicted age is 61.5,mean deviation is 43.560303029249006\n",
      "Top frequent ages in 88:[90, 78]. Average predicted age is 84.0,mean deviation is 7.211102550927978\n",
      "Top frequent ages in 89:[75]. Average predicted age is 75.0,mean deviation is 14.0\n",
      "Average deviation is 5.8114155506776095\n"
     ]
    }
   ],
   "source": [
    "deviations = []\n",
    "for arr in net_predictions:\n",
    "    if arr:\n",
    "        deviations.append()\n",
    "        gt_count = {age: arr.count(age) for age in set(arr)}\n",
    "        try:\n",
    "            top_occurrence = sorted(gt_count,key = gt_count.get,reverse=True)[:4]\n",
    "        except:\n",
    "            top_occurrence = sorted(gt_count,key = gt_count.get,reverse=True)[:2]\n",
    "        print('Top frequent ages in {0}:{1}. Average predicted age is {2},mean deviation is {3}'.format(net_predictions.index(arr)+1,top_occurrence,round(sum(top_occurrence)/len(top_occurrence),2),math.sqrt(sum(abs(net_predictions.index(arr)+1-int(gt))**2 for gt in top_occurrence)/len(top_occurrence))))\n",
    "        deviations.append(math.sqrt(sum(abs(net_predictions.index(arr)+1-int(gt))**2 for gt in top_occurrence)/len(top_occurrence)))\n",
    "print('Average deviation is {0}'.format(sum(deviations)/len(deviations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing  proxyless frozen backbone on \"over-dataset\" val set\n",
    "\n",
    "dsdir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset/val'\n",
    "path2save = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset/proxyless_confused/frozen_backbone'\n",
    "model_proxyless_frozen_backbone.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_frozen_age_trained_3_heads.pth'))\n",
    "transformations = transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "net_predictions = [[] for i in range(1,91)]\n",
    "count = 0\n",
    "\n",
    "for age_gt in os.listdir(dsdir):\n",
    "    for img_path in os.listdir(os.path.join(dsdir,age_gt)):\n",
    "        count += 1\n",
    "        img = default_loader(os.path.join(dsdir,age_gt,img_path))\n",
    "        img = transformations(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        _,age_pred = model_proxyless_frozen_backbone(img)[1]\n",
    "        #if age_gt[0] == '0': age_gt = age_gt.replace('0','')\n",
    "        net_predictions[round(age_pred.item())-1].append(int(age_gt))\n",
    "        if age_pred.item() < 9.5: \n",
    "            if round(age_pred.item()) < 1:\n",
    "                age_pred = '01'\n",
    "            else:\n",
    "                age_pred = '0'+ str(round(age_pred.item())) \n",
    "        else: \n",
    "            age_pred = str(round(age_pred.item()))\n",
    "        img_pil = default_loader(os.path.join(dsdir,age_gt,img_path))\n",
    "        img_pil = img_pil.save(os.path.join(path2save,age_pred,'gt-label:'+age_gt+'_pred:'+age_pred+'number:'+str(count)+'.jpg'))\n",
    "        #print('Gt:'+age_gt+'pred:'+age_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top frequent ages in 1:[1, 2, 3, 4]. Average predicted age is 2.5,mean deviation is 1.8708286933869707\n",
      "Top frequent ages in 2:[1, 2, 3, 4]. Average predicted age is 2.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 3:[1, 2, 4, 3]. Average predicted age is 2.5,mean deviation is 1.224744871391589\n",
      "Top frequent ages in 4:[1, 2, 3, 6]. Average predicted age is 3.0,mean deviation is 2.1213203435596424\n",
      "Top frequent ages in 5:[2, 3, 1, 4]. Average predicted age is 2.5,mean deviation is 2.7386127875258306\n",
      "Top frequent ages in 6:[2, 1, 6, 3]. Average predicted age is 3.0,mean deviation is 3.5355339059327378\n",
      "Top frequent ages in 7:[7, 1, 2, 3]. Average predicted age is 3.25,mean deviation is 4.387482193696061\n",
      "Top frequent ages in 8:[2, 6, 3, 7]. Average predicted age is 4.5,mean deviation is 4.06201920231798\n",
      "Top frequent ages in 9:[4, 3, 5, 2]. Average predicted age is 3.5,mean deviation is 5.612486080160912\n",
      "Top frequent ages in 10:[3, 8, 4, 5]. Average predicted age is 5.0,mean deviation is 5.338539126015656\n",
      "Top frequent ages in 11:[8, 6, 3, 7]. Average predicted age is 6.0,mean deviation is 5.338539126015656\n",
      "Top frequent ages in 12:[10, 3, 7, 12]. Average predicted age is 8.0,mean deviation is 5.244044240850758\n",
      "Top frequent ages in 13:[11, 6, 8, 10]. Average predicted age is 8.75,mean deviation is 4.663689526544408\n",
      "Top frequent ages in 14:[5, 8, 7, 11]. Average predicted age is 7.75,mean deviation is 6.614378277661476\n",
      "Top frequent ages in 15:[9, 4, 6, 14]. Average predicted age is 8.25,mean deviation is 7.729812416870153\n",
      "Top frequent ages in 16:[10, 21, 8, 9]. Average predicted age is 12.0,mean deviation is 6.59545297913646\n",
      "Top frequent ages in 17:[26, 28, 17, 7]. Average predicted age is 19.5,mean deviation is 8.689073598491383\n",
      "Top frequent ages in 18:[20, 29, 25, 26]. Average predicted age is 25.0,mean deviation is 7.713624310270756\n",
      "Top frequent ages in 19:[26, 21, 32, 11]. Average predicted age is 22.5,mean deviation is 8.455767262643882\n",
      "Top frequent ages in 20:[26, 18, 27, 21]. Average predicted age is 23.0,mean deviation is 4.743416490252569\n",
      "Top frequent ages in 21:[26, 24, 28, 22]. Average predicted age is 25.0,mean deviation is 4.58257569495584\n",
      "Top frequent ages in 22:[24, 26, 23, 27]. Average predicted age is 25.0,mean deviation is 3.391164991562634\n",
      "Top frequent ages in 23:[26, 24, 30, 25]. Average predicted age is 26.25,mean deviation is 3.968626966596886\n",
      "Top frequent ages in 24:[26, 28, 29, 25]. Average predicted age is 27.0,mean deviation is 3.391164991562634\n",
      "Top frequent ages in 25:[26, 24, 28, 32]. Average predicted age is 27.5,mean deviation is 3.872983346207417\n",
      "Top frequent ages in 26:[28, 24, 26, 25]. Average predicted age is 25.75,mean deviation is 1.5\n",
      "Top frequent ages in 27:[26, 21, 27, 28]. Average predicted age is 25.5,mean deviation is 3.082207001484488\n",
      "Top frequent ages in 28:[27, 35, 25, 26]. Average predicted age is 28.25,mean deviation is 3.968626966596886\n",
      "Top frequent ages in 29:[26, 22, 35, 27]. Average predicted age is 27.5,mean deviation is 4.949747468305833\n",
      "Top frequent ages in 30:[26, 27, 28, 25]. Average predicted age is 26.5,mean deviation is 3.6742346141747673\n",
      "Top frequent ages in 31:[25, 35, 27, 31]. Average predicted age is 29.5,mean deviation is 4.123105625617661\n",
      "Top frequent ages in 32:[26, 28, 30, 35]. Average predicted age is 29.75,mean deviation is 4.031128874149275\n",
      "Top frequent ages in 33:[28, 26, 30, 36]. Average predicted age is 30.0,mean deviation is 4.795831523312719\n",
      "Top frequent ages in 34:[26, 27, 35, 29]. Average predicted age is 29.25,mean deviation is 5.894913061275798\n",
      "Top frequent ages in 35:[26, 32, 28, 34]. Average predicted age is 30.0,mean deviation is 5.916079783099616\n",
      "Top frequent ages in 36:[26, 27, 28, 34]. Average predicted age is 28.75,mean deviation is 7.88986691902975\n",
      "Top frequent ages in 37:[26, 28, 29, 33]. Average predicted age is 29.0,mean deviation is 8.396427811873332\n",
      "Top frequent ages in 38:[31, 34, 27, 30]. Average predicted age is 30.5,mean deviation is 7.905694150420948\n",
      "Top frequent ages in 39:[31, 26, 27, 32]. Average predicted age is 29.0,mean deviation is 10.319883720275147\n",
      "Top frequent ages in 40:[28, 31, 33, 26]. Average predicted age is 29.5,mean deviation is 10.8397416943394\n",
      "Top frequent ages in 41:[36, 26, 29, 28]. Average predicted age is 29.75,mean deviation is 11.863810517704673\n",
      "Top frequent ages in 42:[29, 32, 25, 26]. Average predicted age is 28.0,mean deviation is 14.265342617687105\n",
      "Top frequent ages in 43:[35, 36, 27, 29]. Average predicted age is 31.75,mean deviation is 11.884864324004713\n",
      "Top frequent ages in 44:[30, 26, 34, 28]. Average predicted age is 29.5,mean deviation is 14.798648586948742\n",
      "Top frequent ages in 45:[28, 36, 37, 35]. Average predicted age is 34.0,mean deviation is 11.554220008291344\n",
      "Top frequent ages in 46:[26, 37, 32, 38]. Average predicted age is 33.25,mean deviation is 13.6106575888162\n",
      "Top frequent ages in 47:[29, 30, 34, 42]. Average predicted age is 33.75,mean deviation is 14.203872711341791\n",
      "Top frequent ages in 48:[45, 26, 27, 35]. Average predicted age is 33.25,mean deviation is 16.605721905415614\n",
      "Top frequent ages in 49:[45, 38, 33, 35]. Average predicted age is 37.75,mean deviation is 12.134661099511597\n",
      "Top frequent ages in 50:[35, 40, 46, 53]. Average predicted age is 43.5,mean deviation is 9.354143466934854\n",
      "Top frequent ages in 51:[37, 36, 40, 41]. Average predicted age is 38.5,mean deviation is 12.668859459319927\n",
      "Top frequent ages in 52:[43, 27, 32, 40]. Average predicted age is 35.5,mean deviation is 17.67766952966369\n",
      "Top frequent ages in 53:[31, 35, 49, 33]. Average predicted age is 37.0,mean deviation is 17.4928556845359\n",
      "Top frequent ages in 54:[35, 38, 42, 47]. Average predicted age is 40.5,mean deviation is 14.230249470757707\n",
      "Top frequent ages in 55:[29, 43, 54, 35]. Average predicted age is 40.25,mean deviation is 17.471405209656147\n",
      "Top frequent ages in 56:[52, 59, 26, 45]. Average predicted age is 45.5,mean deviation is 16.170961628796228\n",
      "Top frequent ages in 57:[50, 26, 32, 46]. Average predicted age is 38.5,mean deviation is 20.952326839756964\n",
      "Top frequent ages in 58:[34, 26, 27, 35]. Average predicted age is 30.5,mean deviation is 27.793884219374593\n",
      "Top frequent ages in 59:[51, 40, 57, 65]. Average predicted age is 53.25,mean deviation is 10.781929326423912\n",
      "Top frequent ages in 60:[42, 52, 28, 30]. Average predicted age is 38.0,mean deviation is 24.041630560342615\n",
      "Top frequent ages in 61:[26, 30, 35, 53]. Average predicted age is 36.0,mean deviation is 27.046256672597043\n",
      "Top frequent ages in 62:[60, 66, 59, 26]. Average predicted age is 52.75,mean deviation is 18.200274723201296\n",
      "Top frequent ages in 63:[54, 26, 40, 47]. Average predicted age is 41.75,mean deviation is 23.637893307145628\n",
      "Top frequent ages in 64:[34, 52, 53, 3]. Average predicted age is 35.5,mean deviation is 34.94996423460259\n",
      "Top frequent ages in 65:[54, 64, 43, 58]. Average predicted age is 54.75,mean deviation is 12.796483892069727\n",
      "Top frequent ages in 66:[56, 78, 58, 68]. Average predicted age is 65.0,mean deviation is 8.831760866327848\n",
      "Top frequent ages in 67:[64, 54, 57, 58]. Average predicted age is 58.25,mean deviation is 9.473647660748208\n",
      "Top frequent ages in 68:[65, 60, 28, 36]. Average predicted age is 47.25,mean deviation is 25.96632434519757\n",
      "Top frequent ages in 69:[58, 67, 54, 61]. Average predicted age is 60.0,mean deviation is 10.173494974687902\n",
      "Top frequent ages in 70:[55, 26, 70, 53]. Average predicted age is 51.0,mean deviation is 24.748737341529164\n",
      "Top frequent ages in 71:[56, 78, 80, 53]. Average predicted age is 66.75,mean deviation is 13.028814220795383\n",
      "Top frequent ages in 72:[62, 61, 54, 67]. Average predicted age is 61.0,mean deviation is 11.937336386313323\n",
      "Top frequent ages in 73:[75, 41, 49, 53]. Average predicted age is 54.5,mean deviation is 22.38302928559939\n",
      "Top frequent ages in 74:[54, 73, 42, 51]. Average predicted age is 55.0,mean deviation is 22.102036105300343\n",
      "Top frequent ages in 75:[78, 56, 60, 61]. Average predicted age is 63.75,mean deviation is 14.062361110425233\n",
      "Top frequent ages in 76:[65, 78, 80, 75]. Average predicted age is 74.5,mean deviation is 5.958187643906492\n",
      "Top frequent ages in 77:[75, 70, 71, 74]. Average predicted age is 72.5,mean deviation is 4.949747468305833\n",
      "Top frequent ages in 78:[65, 66, 70, 73]. Average predicted age is 68.5,mean deviation is 10.024968827881711\n",
      "Top frequent ages in 79:[77, 79, 82, 78]. Average predicted age is 79.0,mean deviation is 1.8708286933869707\n",
      "Top frequent ages in 80:[66, 68, 76, 77]. Average predicted age is 71.75,mean deviation is 9.5524865872714\n",
      "Top frequent ages in 81:[26, 68, 69, 76]. Average predicted age is 59.75,mean deviation is 28.99568933479596\n",
      "Top frequent ages in 82:[70, 89, 65, 67]. Average predicted age is 72.75,mean deviation is 13.294735800308331\n",
      "Top frequent ages in 83:[90, 75, 78, 80]. Average predicted age is 80.75,mean deviation is 6.06217782649107\n",
      "Top frequent ages in 84:[74, 75, 85, 86]. Average predicted age is 80.0,mean deviation is 6.819090848492928\n",
      "Top frequent ages in 85:[79]. Average predicted age is 79.0,mean deviation is 6.0\n",
      "Top frequent ages in 87:[88]. Average predicted age is 88.0,mean deviation is 1.0\n",
      "Top frequent ages in 90:[1, 2]. Average predicted age is 1.5,mean deviation is 88.50141241810776\n",
      "Average deviation is 11.22211000965208\n"
     ]
    }
   ],
   "source": [
    "deviations = []\n",
    "for arr in net_predictions:\n",
    "    if arr:\n",
    "        #deviations.append()   \n",
    "        gt_count = {age: arr.count(age) for age in set(arr)}\n",
    "        try:\n",
    "            top_occurrence = sorted(gt_count,key = gt_count.get,reverse=True)[:4]\n",
    "        except:\n",
    "            top_occurrence = sorted(gt_count,key = gt_count.get,reverse=True)[:2]\n",
    "        print('Top frequent ages in {0}:{1}. Average predicted age is {2},mean deviation is {3}'.format(net_predictions.index(arr)+1,top_occurrence,round(sum(top_occurrence)/len(top_occurrence),2),math.sqrt(sum(abs(net_predictions.index(arr)+1-int(gt))**2 for gt in top_occurrence)/len(top_occurrence))))\n",
    "        deviations.append(math.sqrt(sum(abs(net_predictions.index(arr)+1-int(gt))**2 for gt in top_occurrence)/len(top_occurrence)))\n",
    "print('Average deviation is {0}'.format(sum(deviations)/len(deviations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proxyless trained entirely predicts far more precisely then one with frozen backbone. At least by 5 year\n",
    "\n",
    "\n",
    "## Here starts modeified approach training section.\n",
    "## First, let's weaken the augmentations, and change our regression vector: reduce output units to 10 representing following age ranges  ['1-2', '3-6', '7-12', '13-17', '18-22', '23-26', '27-33', '34-44', '45-59', '60-90'], the mean age tensor is as follows [1.5, 4.5, 9.5, 15, 20, 24.5, 30, 39, 52, 75]. The main idea behind the vector is to make each unit represent age whitin which human appereance doesn't differ a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {'train': transforms.Compose([\n",
    "        transforms.Resize(random.randint(56,224)),\n",
    "        transforms.RandomRotation((90,90)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize((112,112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor()\n",
    "        ,transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])}\n",
    "\n",
    "from Datasets.age_data_pipeline import MyDataset_age,dataloader_age\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,x,annotations[x],list(range(10)),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=90,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean aged-tensor model class\n",
    "class MultiTaskModel_aged_Tensor(nn.Module):\n",
    "    def __init__(self,model_backbone):\n",
    "        super(MultiTaskModel_aged_Tensor,self).__init__()\n",
    "        self.encoder = model_backbone\n",
    "        self.gender_head = nn.Linear(in_features=1432, out_features=2, bias=True)    \n",
    "        self.age_prehead = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "        self.age_group_head = nn.Linear(in_features=1400, out_features=10, bias=True)\n",
    "        self.expression_head = nn.Linear(in_features=1432, out_features=7, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        #Age groups: ['1-2', '3-6', '7-12', '13-17', '18-22', '23-26', '27-33', '34-44', '45-59', '60-90']\n",
    "        self.idx_tensor = torch.from_numpy(np.array([1.5, 4.5, 9.5, 15, 20, 24.5, 30, 39, 52, 75])).to(device)\n",
    "    def forward(self,x):\n",
    "        features = self.encoder(x)\n",
    "        gender = self.gender_head(self.relu(features))\n",
    "        expression = self.expression_head(self.relu(features))\n",
    "        age_feats = self.age_prehead(self.relu(features))\n",
    "        grouped_age = self.age_group_head(self.relu(age_feats))\n",
    "        regression_age = torch.sum(self.Softmax(grouped_age) * self.idx_tensor, axis=1)\n",
    "        return [gender, (grouped_age,regression_age),  expression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_aged_Tensor(\n",
       "  (encoder): ProxylessNASNets(\n",
       "    (first_conv): ConvLayer(\n",
       "      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (3): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (4): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (5): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (7): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (8): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (9): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (11): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (12): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (13): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (15): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (16): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (17): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (19): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (20): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (21): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_mix_layer): ConvLayer(\n",
       "      (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential()\n",
       "  )\n",
       "  (gender_head): Linear(in_features=1432, out_features=2, bias=True)\n",
       "  (age_prehead): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "  (age_group_head): Linear(in_features=1400, out_features=10, bias=True)\n",
       "  (expression_head): Linear(in_features=1432, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proxyless_entirely_3heads_aged_tensor = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_entirely_3heads_aged_tensor.classifier = nn.Sequential(*list(model_proxyless_entirely_3heads_aged_tensor.classifier.children())[:-3])\n",
    "model_proxyless_entirely_3heads_aged_tensor = MultiTaskModel_aged_Tensor(model_proxyless_entirely_3heads_aged_tensor)\n",
    "model_proxyless_entirely_3heads_aged_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 5.1689 Regression_Loss: 12.1690\n",
      "val Classificatoin_Loss: 5.3879 Regression_Loss: 17.0259\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 5.1925 Regression_Loss: 11.8665\n",
      "val Classificatoin_Loss: 5.1436 Regression_Loss: 16.6995\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 5.0718 Regression_Loss: 11.8086\n",
      "val Classificatoin_Loss: 4.4125 Regression_Loss: 16.8642\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7453 Regression_Loss: 11.6068\n",
      "val Classificatoin_Loss: 5.2816 Regression_Loss: 16.9324\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.6916 Regression_Loss: 9.6837\n",
      "val Classificatoin_Loss: 2.0155 Regression_Loss: 15.5942\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.0971 Regression_Loss: 6.8594\n",
      "val Classificatoin_Loss: 1.9372 Regression_Loss: 15.4283\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.0523 Regression_Loss: 6.5474\n",
      "val Classificatoin_Loss: 1.9783 Regression_Loss: 15.5626\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9566 Regression_Loss: 5.7641\n",
      "val Classificatoin_Loss: 1.8201 Regression_Loss: 14.2305\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9437 Regression_Loss: 5.5968\n",
      "val Classificatoin_Loss: 1.8180 Regression_Loss: 14.3394\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9297 Regression_Loss: 5.5057\n",
      "val Classificatoin_Loss: 1.7858 Regression_Loss: 14.5066\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9133 Regression_Loss: 5.3580\n",
      "val Classificatoin_Loss: 1.8165 Regression_Loss: 14.1779\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9097 Regression_Loss: 5.3396\n",
      "val Classificatoin_Loss: 1.7860 Regression_Loss: 13.9997\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9066 Regression_Loss: 5.2742\n",
      "val Classificatoin_Loss: 1.7913 Regression_Loss: 13.9868\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9152 Regression_Loss: 5.2721\n",
      "val Classificatoin_Loss: 1.7591 Regression_Loss: 14.0695\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.8999 Regression_Loss: 5.1594\n",
      "val Classificatoin_Loss: 1.7890 Regression_Loss: 14.0486\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9033 Regression_Loss: 5.1992\n",
      "val Classificatoin_Loss: 1.7540 Regression_Loss: 13.9887\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.8954 Regression_Loss: 5.1697\n",
      "val Classificatoin_Loss: 1.7975 Regression_Loss: 14.1959\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.8917 Regression_Loss: 5.0894\n",
      "val Classificatoin_Loss: 1.7605 Regression_Loss: 13.7933\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.8895 Regression_Loss: 5.0991\n",
      "val Classificatoin_Loss: 1.7634 Regression_Loss: 14.1095\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 0.9005 Regression_Loss: 5.1393\n",
      "val Classificatoin_Loss: 1.7756 Regression_Loss: 14.1169\n",
      "\n",
      "Training complete in 16m 30s\n",
      "Best val loss: 7.776924\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_proxyless_entirely_3heads_aged_tensor.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "model_proxyless_entirely_3heads_aged_tensor = train_model(model_proxyless_entirely_3heads_aged_tensor, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The conclusion is that strong augmentations are necessary in order to avoid overfiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further goes training with Albumetntations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1701: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1727: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "data_transforms_A = {\n",
    "    'train': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.RandomResizedCrop(height=112,width=112,scale=(0.5, 1.0)),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.Blur(p=0.5),#Размытие входного изображения с помощью ядра случайного размера. \n",
    "            A.GaussianBlur(p=0.5),#Размытие входного изображения с помощью фильтра Гаусса со случайным размером ядра. \n",
    "            A.GaussNoise(p=0.5),#Примените гауссовский шум к входному изображению. \n",
    "            A.ISONoise(p=0.5),#Примените шум сенсора камеры. \n",
    "            A.MedianBlur(p=0.5),#Размытие входного изображения с помощью медианного фильтра со случайным линейным размером апертуры.\n",
    "            A.MotionBlur(p=0.5),#Примените размытие движения к входному изображению, используя ядро случайного размера. \n",
    "            A.CLAHE(p=0.5),#Примените коррекцию адаптивной гистограммы с ограничением контраста к входному изображению.\n",
    "            A.Equalize(p=0.5),#Выровняйте гистограмму изображения. \n",
    "        ], p = 1),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.ChannelDropout(p=0.5),#Случайно отбросьте каналы во входном изображении.\n",
    "            A.ChannelShuffle(p=0.5),#Произвольно переставьте каналы входного изображения RGB.\n",
    "            A.InvertImg(p=0.5),#Инвертируйте входное изображение, вычитая значения пикселей из 255\n",
    "            A.Solarize(p=0.5),#Инвертировать все значения пикселей выше порога. \n",
    "            A.ToGray(p=0.5),#Преобразуйте входное изображение RGB в оттенки серого.\n",
    "            A.HueSaturationValue(p=0.5),#Произвольно изменяйте оттенок, насыщенность и значение входного изображения. \n",
    "            A.RandomBrightness(p=0.5),#Произвольно изменяйте яркость входного изображения. \n",
    "            A.RandomBrightnessContrast(p=0.5),#Произвольно изменяйте яркость и контраст входного изображения.\n",
    "            A.RandomContrast(p=0.5)#Произвольно изменяйте контраст входного изображения.\n",
    "        ], p = 1),\n",
    "        A.core.composition.OneOf ([ \n",
    "           A.Downscale(scale_min=0.2, scale_max=0.2,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.3, scale_max=0.3,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.4, scale_max=0.4,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.5, scale_max=0.5,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.6, scale_max=0.6,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.7, scale_max=0.7,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.8, scale_max=0.8,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.9, scale_max=0.9,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.99, scale_max=0.99,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "        ], p = 1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.age_data_pipeline import MyDataset_age,dataloader_age\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,x,annotations[x],list(range(10)),\n",
    "                                          data_transforms_A[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=90,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_aged_Tensor(\n",
       "  (encoder): ProxylessNASNets(\n",
       "    (first_conv): ConvLayer(\n",
       "      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (3): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (4): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (5): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (7): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (8): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (9): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (11): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (12): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (13): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (15): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (16): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (17): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (19): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (20): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (21): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_mix_layer): ConvLayer(\n",
       "      (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential()\n",
       "  )\n",
       "  (gender_head): Linear(in_features=1432, out_features=2, bias=True)\n",
       "  (age_prehead): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "  (age_group_head): Linear(in_features=1400, out_features=10, bias=True)\n",
       "  (expression_head): Linear(in_features=1432, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proxyless_entirely_3heads_aged_tensor = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_entirely_3heads_aged_tensor.classifier = nn.Sequential(*list(model_proxyless_entirely_3heads_aged_tensor.classifier.children())[:-3])\n",
    "model_proxyless_entirely_3heads_aged_tensor = MultiTaskModel_aged_Tensor(model_proxyless_entirely_3heads_aged_tensor)\n",
    "model_proxyless_entirely_3heads_aged_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop for age training \n",
    "def train_model(model, classification_criterion,regression_criterion, dataloaders,dataset_sizes,optimizer, scheduler, losses_ratio = None,num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_class_loss = 0.0\n",
    "            running_regress_loss = 0.0\n",
    "            \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, class_labels,regress_labels in dataloaders[phase]:\n",
    "                class_labels = class_labels.type(torch.FloatTensor)\n",
    "                regress_labels = regress_labels.type(torch.FloatTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                class_labels = class_labels.to(device)\n",
    "                regress_labels = regress_labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    age_group,age_digit = model(inputs)[1]\n",
    "                    batch_regression_loss = regression_criterion(age_digit, regress_labels)\n",
    "                    batch_classification_loss = classification_criterion(age_group, class_labels.long())\n",
    "                    \n",
    "                    \n",
    "                    if (losses_ratio == None):\n",
    "                        if (batch_regression_loss > batch_classification_loss):\n",
    "                            alpha = batch_regression_loss / batch_classification_loss\n",
    "                            loss = alpha * batch_classification_loss + batch_regression_loss\n",
    "                        else:\n",
    "                            alpha = batch_classification_loss / batch_regression_loss\n",
    "                            loss = batch_classification_loss +  alpha * batch_regression_loss\n",
    "                    else:\n",
    "                        loss = losses_ratio[0] * batch_regression_loss + losses_ratio[1] * batch_classification_loss\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_class_loss += batch_classification_loss.item() * inputs.size(0)\n",
    "                running_regress_loss += batch_regression_loss.item() * inputs.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_class_loss = running_class_loss / dataset_sizes[phase]\n",
    "            epoch_regress_loss = running_regress_loss/ dataset_sizes[phase]\n",
    "            avrg_epoch_loss = (epoch_class_loss+epoch_regress_loss)/2\n",
    "\n",
    "            \n",
    "            print('{} Classificatoin_Loss: {:.4f} Regression_Loss: {:.4f}'.format(\n",
    "                phase, epoch_class_loss, epoch_regress_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and avrg_epoch_loss < best_loss:\n",
    "                best_loss = avrg_epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2954 Regression_Loss: 8.5370\n",
      "val Classificatoin_Loss: 1.2595 Regression_Loss: 7.8371\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.3187 Regression_Loss: 8.7002\n",
      "val Classificatoin_Loss: 1.1964 Regression_Loss: 7.6545\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2994 Regression_Loss: 8.4573\n",
      "val Classificatoin_Loss: 1.2028 Regression_Loss: 7.6607\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2767 Regression_Loss: 8.2858\n",
      "val Classificatoin_Loss: 1.1719 Regression_Loss: 7.7281\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2866 Regression_Loss: 8.3278\n",
      "val Classificatoin_Loss: 1.1934 Regression_Loss: 7.7911\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2428 Regression_Loss: 8.0375\n",
      "val Classificatoin_Loss: 1.1726 Regression_Loss: 7.5327\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2744 Regression_Loss: 8.2396\n",
      "val Classificatoin_Loss: 1.2499 Regression_Loss: 8.1740\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1927 Regression_Loss: 7.6813\n",
      "val Classificatoin_Loss: 1.1704 Regression_Loss: 7.5922\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1599 Regression_Loss: 7.4502\n",
      "val Classificatoin_Loss: 1.1805 Regression_Loss: 7.6032\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1467 Regression_Loss: 7.2851\n",
      "val Classificatoin_Loss: 1.1417 Regression_Loss: 7.3575\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1345 Regression_Loss: 7.2337\n",
      "val Classificatoin_Loss: 1.1007 Regression_Loss: 7.0879\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1326 Regression_Loss: 7.2300\n",
      "val Classificatoin_Loss: 1.1425 Regression_Loss: 7.3804\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1349 Regression_Loss: 7.2160\n",
      "val Classificatoin_Loss: 1.1460 Regression_Loss: 7.2139\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1319 Regression_Loss: 7.1826\n",
      "val Classificatoin_Loss: 1.1335 Regression_Loss: 7.2771\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1389 Regression_Loss: 7.2837\n",
      "val Classificatoin_Loss: 1.1215 Regression_Loss: 7.0784\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1187 Regression_Loss: 7.0861\n",
      "val Classificatoin_Loss: 1.1319 Regression_Loss: 7.1760\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1232 Regression_Loss: 7.1024\n",
      "val Classificatoin_Loss: 1.1012 Regression_Loss: 7.0595\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1210 Regression_Loss: 7.1362\n",
      "val Classificatoin_Loss: 1.1170 Regression_Loss: 7.2193\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1219 Regression_Loss: 7.1484\n",
      "val Classificatoin_Loss: 1.1341 Regression_Loss: 7.0774\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1201 Regression_Loss: 7.0800\n",
      "val Classificatoin_Loss: 1.1014 Regression_Loss: 7.0672\n",
      "\n",
      "Training complete in 67m 6s\n",
      "Best val loss: 4.080337\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_proxyless_entirely_3heads_aged_tensor.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "model_proxyless_entirely_3heads_aged_tensor = train_model(model_proxyless_entirely_3heads_aged_tensor, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Such aged tensor approach infers slightly worse average result (by 0.8 year)\n",
    "\n",
    "## Let's try aged tensor with dimension of 30 - almost the same as the 1st approach, but the tensor represents average age of each age group(1.5,4.5,7.5,...,87.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.age_data_pipeline import MyDataset_age,dataloader_age\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,x,annotations[x],list(range(10)),\n",
    "                                          data_transforms_A[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=90,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean aged-tensor model class\n",
    "class MultiTaskModel_aged_Tensor30(nn.Module):\n",
    "    def __init__(self,model_backbone):\n",
    "        super(MultiTaskModel_aged_Tensor30,self).__init__()\n",
    "        self.encoder = model_backbone\n",
    "        self.gender_head = nn.Linear(in_features=1432, out_features=2, bias=True)    \n",
    "        self.age_prehead = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "        self.age_group_head = nn.Linear(in_features=1400, out_features=31, bias=True)\n",
    "        self.expression_head = nn.Linear(in_features=1432, out_features=7, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        mean_ages = [(3*i+3*(i-1))/2 for i in range(1,32)]\n",
    "        self.idx_tensor = torch.from_numpy(np.array(mean_ages)).to(device)\n",
    "    def forward(self,x):\n",
    "        features = self.encoder(x)\n",
    "        gender = self.gender_head(self.relu(features))\n",
    "        expression = self.expression_head(self.relu(features))\n",
    "        age_feats = self.age_prehead(self.relu(features))\n",
    "        grouped_age = self.age_group_head(self.relu(age_feats))\n",
    "        regression_age = torch.sum(self.Softmax(grouped_age) * self.idx_tensor, axis=1)\n",
    "        return [gender, (grouped_age,regression_age),  expression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_aged_Tensor30(\n",
       "  (encoder): ProxylessNASNets(\n",
       "    (first_conv): ConvLayer(\n",
       "      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (3): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (4): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (5): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (7): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (8): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (9): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (11): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (12): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (13): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (15): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (16): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (17): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (19): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (20): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (21): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_mix_layer): ConvLayer(\n",
       "      (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential()\n",
       "  )\n",
       "  (gender_head): Linear(in_features=1432, out_features=2, bias=True)\n",
       "  (age_prehead): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "  (age_group_head): Linear(in_features=1400, out_features=31, bias=True)\n",
       "  (expression_head): Linear(in_features=1432, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proxyless_entirely_3heads_aged_tensor30 = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_entirely_3heads_aged_tensor30.classifier = nn.Sequential(*list(model_proxyless_entirely_3heads_aged_tensor30.classifier.children())[:-3])\n",
    "model_proxyless_entirely_3heads_aged_tensor30 = MultiTaskModel_aged_Tensor30(model_proxyless_entirely_3heads_aged_tensor30)\n",
    "model_proxyless_entirely_3heads_aged_tensor30.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.4485 Regression_Loss: 22.3987\n",
      "val Classificatoin_Loss: 3.4336 Regression_Loss: 22.4969\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 4.7244 Regression_Loss: 22.1276\n",
      "val Classificatoin_Loss: 7.4573 Regression_Loss: 22.7817\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.7986 Regression_Loss: 17.8704\n",
      "val Classificatoin_Loss: 3.0919 Regression_Loss: 12.8597\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.2869 Regression_Loss: 12.5522\n",
      "val Classificatoin_Loss: 3.2693 Regression_Loss: 9.8905\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.2882 Regression_Loss: 10.8660\n",
      "val Classificatoin_Loss: 3.3457 Regression_Loss: 9.3379\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.2854 Regression_Loss: 10.0605\n",
      "val Classificatoin_Loss: 3.3757 Regression_Loss: 12.1198\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.2551 Regression_Loss: 9.5580\n",
      "val Classificatoin_Loss: 3.1250 Regression_Loss: 8.5498\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.1984 Regression_Loss: 8.5265\n",
      "val Classificatoin_Loss: 3.1136 Regression_Loss: 7.8424\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.1557 Regression_Loss: 8.2290\n",
      "val Classificatoin_Loss: 3.0511 Regression_Loss: 7.6770\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.1257 Regression_Loss: 8.1768\n",
      "val Classificatoin_Loss: 2.9946 Regression_Loss: 7.7168\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0632 Regression_Loss: 8.0739\n",
      "val Classificatoin_Loss: 2.9841 Regression_Loss: 7.6209\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 3.0065 Regression_Loss: 8.0136\n",
      "val Classificatoin_Loss: 2.9567 Regression_Loss: 7.3905\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9878 Regression_Loss: 7.8966\n",
      "val Classificatoin_Loss: 2.9042 Regression_Loss: 7.4501\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9900 Regression_Loss: 7.9403\n",
      "val Classificatoin_Loss: 2.9829 Regression_Loss: 7.5089\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9657 Regression_Loss: 7.7346\n",
      "val Classificatoin_Loss: 2.9368 Regression_Loss: 7.3945\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9828 Regression_Loss: 7.8116\n",
      "val Classificatoin_Loss: 2.9515 Regression_Loss: 7.4781\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9732 Regression_Loss: 7.6750\n",
      "val Classificatoin_Loss: 2.9585 Regression_Loss: 7.2914\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9815 Regression_Loss: 7.7801\n",
      "val Classificatoin_Loss: 2.9608 Regression_Loss: 7.3957\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9687 Regression_Loss: 7.7003\n",
      "val Classificatoin_Loss: 2.9555 Regression_Loss: 7.3242\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.9509 Regression_Loss: 7.6793\n",
      "val Classificatoin_Loss: 2.9700 Regression_Loss: 7.5785\n",
      "\n",
      "Training complete in 50m 38s\n",
      "Best val loss: 5.124949\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_proxyless_entirely_3heads_aged_tensor30.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "model_proxyless_entirely_3heads_aged_tensor30 = train_model(model_proxyless_entirely_3heads_aged_tensor30, class_criterion,regress_criterion,dataloaders,dataset_sizes, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Such approach seems to infer results worse  than the 2 previous ones by 1.3 , 0,5 years correspondingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
