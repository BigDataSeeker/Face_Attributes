{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as Ap\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import PIL\n",
    "import pandas\n",
    "from os.path import join\n",
    "import copy\n",
    "import timm \n",
    "from collections import OrderedDict\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Dataset and Dataloader for age training  with Albumentations\n",
    "class MyDataset_age(torch.utils.data.Dataset):\n",
    "    def __init__(self,root,phase,annotation_name,classes,transform = None,loader = default_loader):\n",
    "\n",
    "        self.group_dict = {0:list(range(1,3)), 1:list(range(3,7)), 2:list(range(7,13)), 3:list(range(13,18)), 4:list(range(18,23)), 5:list(range(23,27)), 6:list(range(27,34)), 7:list(range(34,45)), 8:list(range(45,60)), 9:list(range(60,91))}\n",
    "        self.phase = phase\n",
    "        self.classes = classes\n",
    "        self.attribute_frame = pandas.read_csv(join(root,annotation_name))\n",
    "        self.root = root\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        group_label = 4\n",
    "        img_path , target = join(self.root, self.attribute_frame.iloc[index, 0]), int(self.attribute_frame.iloc[index, 1])\n",
    "        for key in self.group_dict:\n",
    "            if int(target) in self.group_dict[key]:\n",
    "                group_label = key\n",
    "                break\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "    \n",
    "        \n",
    "        return img, group_label,target\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.attribute_frame)\n",
    "    \n",
    "def dataloader_age(MyDataset,root,item_prob_filename,batch_size,shuffle , num_workers):\n",
    "    item_prob_file =open(root + \"/\" + item_prob_filename, \"r\")\n",
    "    item_prob_list = item_prob_file.readlines()\n",
    "    item_prob_list = [float(item_prob_list[i]) for i in range(len(item_prob_list))]\n",
    "    t = item_prob_list.pop(0)\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(item_prob_list, len(item_prob_list))\n",
    "    return torch.utils.data.DataLoader(MyDataset, batch_size=batch_size, num_workers=num_workers,shuffle=shuffle,sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1701: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1727: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "data_transforms_A = {\n",
    "    'train': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.RandomResizedCrop(height=112,width=112,scale=(0.5, 1.0)),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.Blur(p=0.5),#Размытие входного изображения с помощью ядра случайного размера. \n",
    "            A.GaussianBlur(p=0.5),#Размытие входного изображения с помощью фильтра Гаусса со случайным размером ядра. \n",
    "            A.GaussNoise(p=0.5),#Примените гауссовский шум к входному изображению. \n",
    "            A.ISONoise(p=0.5),#Примените шум сенсора камеры. \n",
    "            A.MedianBlur(p=0.5),#Размытие входного изображения с помощью медианного фильтра со случайным линейным размером апертуры.\n",
    "            A.MotionBlur(p=0.5),#Примените размытие движения к входному изображению, используя ядро случайного размера. \n",
    "            A.CLAHE(p=0.5),#Примените коррекцию адаптивной гистограммы с ограничением контраста к входному изображению.\n",
    "            A.Equalize(p=0.5),#Выровняйте гистограмму изображения. \n",
    "        ], p = 1),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.ChannelDropout(p=0.5),#Случайно отбросьте каналы во входном изображении.\n",
    "            A.ChannelShuffle(p=0.5),#Произвольно переставьте каналы входного изображения RGB.\n",
    "            A.InvertImg(p=0.5),#Инвертируйте входное изображение, вычитая значения пикселей из 255\n",
    "            A.Solarize(p=0.5),#Инвертировать все значения пикселей выше порога. \n",
    "            A.ToGray(p=0.5),#Преобразуйте входное изображение RGB в оттенки серого.\n",
    "            A.HueSaturationValue(p=0.5),#Произвольно изменяйте оттенок, насыщенность и значение входного изображения. \n",
    "            A.RandomBrightness(p=0.5),#Произвольно изменяйте яркость входного изображения. \n",
    "            A.RandomBrightnessContrast(p=0.5),#Произвольно изменяйте яркость и контраст входного изображения.\n",
    "            A.RandomContrast(p=0.5)#Произвольно изменяйте контраст входного изображения.\n",
    "        ], p = 1),\n",
    "        A.core.composition.OneOf ([ \n",
    "           A.Downscale(scale_min=0.2, scale_max=0.2,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.3, scale_max=0.3,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.4, scale_max=0.4,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.5, scale_max=0.5,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.6, scale_max=0.6,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.7, scale_max=0.7,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.8, scale_max=0.8,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.9, scale_max=0.9,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.99, scale_max=0.99,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "        ], p = 1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "}\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,x,annotations[x],list(range(10)),\n",
    "                                          data_transforms_A[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=90,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean aged-tensor model class\n",
    "class MultiTaskModel_aged_Tensor(nn.Module):\n",
    "    def __init__(self,model_backbone):\n",
    "        super(MultiTaskModel_aged_Tensor,self).__init__()\n",
    "        self.encoder = model_backbone\n",
    "        self.gender_head = nn.Linear(in_features=1432, out_features=2, bias=True)    \n",
    "        self.age_prehead = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "        self.age_group_head = nn.Linear(in_features=1400, out_features=10, bias=True)\n",
    "        self.expression_head = nn.Linear(in_features=1432, out_features=7, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        #Age groups: ['1-2', '3-6', '7-12', '13-17', '18-22', '23-26', '27-33', '34-44', '45-59', '60-90']\n",
    "        self.idx_tensor = torch.from_numpy(np.array([1.5, 4.5, 9.5, 15, 20, 24.5, 30, 39, 52, 75])).to(device)\n",
    "    def forward(self,x):\n",
    "        features = self.encoder(x)\n",
    "        gender = self.gender_head(self.relu(features))\n",
    "        expression = self.expression_head(self.relu(features))\n",
    "        age_feats = self.age_prehead(self.relu(features))\n",
    "        grouped_age = self.age_group_head(self.relu(age_feats))\n",
    "        regression_age = torch.sum(self.Softmax(grouped_age) * self.idx_tensor, axis=1)\n",
    "        return [gender, (grouped_age,regression_age),  expression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop for age training \n",
    "def train_model(model,regression_criterion, optimizer, scheduler, losses_ratio = None,num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            #running_class_loss = 0.0\n",
    "            running_regress_loss = 0.0\n",
    "            \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, class_labels,regress_labels in dataloaders[phase]:\n",
    "                #class_labels = class_labels.type(torch.FloatTensor)\n",
    "                regress_labels = regress_labels.type(torch.FloatTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                #class_labels = class_labels.to(device)\n",
    "                regress_labels = regress_labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    age_group,age_digit = model(inputs)[1]\n",
    "                    batch_regression_loss = regression_criterion(age_digit, regress_labels)\n",
    "                    #batch_classification_loss = classification_criterion(age_group, class_labels.long())\n",
    "                    \n",
    "                    \n",
    "                    '''if (losses_ratio == None):\n",
    "                        if (batch_regression_loss > batch_classification_loss):\n",
    "                            alpha = batch_regression_loss / batch_classification_loss\n",
    "                            loss = alpha * batch_classification_loss + batch_regression_loss\n",
    "                        else:\n",
    "                            alpha = batch_classification_loss / batch_regression_loss\n",
    "                            loss = batch_classification_loss +  alpha * batch_regression_loss\n",
    "                    else:\n",
    "                        loss = losses_ratio[0] * batch_regression_loss + losses_ratio[1] * batch_classification_loss'''\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        batch_regression_loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                #running_class_loss += batch_classification_loss.item() * inputs.size(0)\n",
    "                running_regress_loss += batch_regression_loss.item() * inputs.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            #epoch_class_loss = running_class_loss / dataset_sizes[phase]\n",
    "            epoch_regress_loss = running_regress_loss/ dataset_sizes[phase]\n",
    "            #avrg_epoch_loss = (epoch_class_loss+epoch_regress_loss)/2\n",
    "\n",
    "            \n",
    "            print('{} Regression_Loss: {:.4f}'.format(\n",
    "                phase, epoch_regress_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_regress_loss < best_loss:\n",
    "                best_loss = epoch_regress_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_aged_Tensor(\n",
       "  (encoder): ProxylessNASNets(\n",
       "    (first_conv): ConvLayer(\n",
       "      (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (3): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (4): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (5): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (7): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (8): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "            (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (9): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (11): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): ZeroLayer()\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (12): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "            (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (13): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "            (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (15): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (16): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "            (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (17): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "            (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (19): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (20): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "            (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (shortcut): IdentityLayer()\n",
       "      )\n",
       "      (21): MobileInvertedResidualBlock(\n",
       "        (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "          (inverted_bottleneck): Sequential(\n",
       "            (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (depth_conv): Sequential(\n",
       "            (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "            (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "          (point_linear): Sequential(\n",
       "            (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_mix_layer): ConvLayer(\n",
       "      (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU6(inplace=True)\n",
       "      (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential()\n",
       "  )\n",
       "  (gender_head): Linear(in_features=1432, out_features=2, bias=True)\n",
       "  (age_prehead): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "  (age_group_head): Linear(in_features=1400, out_features=10, bias=True)\n",
       "  (expression_head): Linear(in_features=1432, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_proxyless_entirely_3heads_aged_tensor = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_proxyless_entirely_3heads_aged_tensor.classifier = nn.Sequential(*list(model_proxyless_entirely_3heads_aged_tensor.classifier.children())[:-3])\n",
    "model_proxyless_entirely_3heads_aged_tensor = MultiTaskModel_aged_Tensor(model_proxyless_entirely_3heads_aged_tensor)\n",
    "model_proxyless_entirely_3heads_aged_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Regression_Loss: 15.4675\n",
      "val Regression_Loss: 11.0494\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Regression_Loss: 11.2902\n",
      "val Regression_Loss: 9.7016\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Regression_Loss: 10.3520\n",
      "val Regression_Loss: 8.9333\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Regression_Loss: 9.8348\n",
      "val Regression_Loss: 8.2555\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Regression_Loss: 9.4276\n",
      "val Regression_Loss: 8.8825\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Regression_Loss: 9.1441\n",
      "val Regression_Loss: 9.0305\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Regression_Loss: 8.9676\n",
      "val Regression_Loss: 8.0226\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Regression_Loss: 8.2927\n",
      "val Regression_Loss: 7.5854\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Regression_Loss: 8.2156\n",
      "val Regression_Loss: 7.8520\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Regression_Loss: 8.0799\n",
      "val Regression_Loss: 7.7053\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Regression_Loss: 8.0354\n",
      "val Regression_Loss: 7.4921\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Regression_Loss: 7.9377\n",
      "val Regression_Loss: 7.6006\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Regression_Loss: 7.9142\n",
      "val Regression_Loss: 7.5819\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Regression_Loss: 7.8966\n",
      "val Regression_Loss: 7.6844\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Regression_Loss: 7.8997\n",
      "val Regression_Loss: 7.5790\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Regression_Loss: 7.8556\n",
      "val Regression_Loss: 7.6624\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Regression_Loss: 7.9259\n",
      "val Regression_Loss: 7.5052\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Regression_Loss: 7.8251\n",
      "val Regression_Loss: 7.5363\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Regression_Loss: 7.8577\n",
      "val Regression_Loss: 7.6607\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Regression_Loss: 7.8328\n",
      "val Regression_Loss: 7.4453\n",
      "\n",
      "Training complete in 63m 39s\n",
      "Best val loss: 7.445292\n"
     ]
    }
   ],
   "source": [
    "#class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_proxyless_entirely_3heads_aged_tensor.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Regression_Loss: 7.8165\n",
      "val Regression_Loss: 7.6078\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Regression_Loss: 7.8504\n",
      "val Regression_Loss: 7.6358\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Regression_Loss: 7.7932\n",
      "val Regression_Loss: 7.6471\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Regression_Loss: 7.8033\n",
      "val Regression_Loss: 7.4946\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Regression_Loss: 7.8138\n",
      "val Regression_Loss: 7.6126\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Regression_Loss: 7.8545\n",
      "val Regression_Loss: 7.4883\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Regression_Loss: 7.8024\n",
      "val Regression_Loss: 7.4637\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Regression_Loss: 7.8904\n",
      "val Regression_Loss: 7.6082\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Regression_Loss: 7.7934\n",
      "val Regression_Loss: 7.4255\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Regression_Loss: 7.7282\n",
      "val Regression_Loss: 7.5129\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Regression_Loss: 7.8617\n",
      "val Regression_Loss: 7.6750\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Regression_Loss: 7.8342\n",
      "val Regression_Loss: 7.5597\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Regression_Loss: 7.8198\n",
      "val Regression_Loss: 7.6093\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Regression_Loss: 7.8701\n",
      "val Regression_Loss: 7.6618\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Regression_Loss: 7.8101\n",
      "val Regression_Loss: 7.6099\n",
      "\n",
      "Training complete in 29m 49s\n",
      "Best val loss: 7.425488\n"
     ]
    }
   ],
   "source": [
    "model_proxyless_entirely_3heads_aged_tensor = train_model(model_proxyless_entirely_3heads_aged_tensor,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
