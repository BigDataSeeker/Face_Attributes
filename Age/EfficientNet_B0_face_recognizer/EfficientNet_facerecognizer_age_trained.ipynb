{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import math\n",
    "import pandas\n",
    "import collections\n",
    "from functools import partial\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as Ap\n",
    "import random\n",
    "from os.path import join\n",
    "import torch\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch.utils import model_zoo\n",
    "from torch.nn import Sequential, BatchNorm1d, BatchNorm2d, Dropout, Module, Linear\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "import timm\n",
    "import time\n",
    "import sys\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook aims to find out how accurate efficientnet-b0 can converge on the age estiamtion problem and find out whether recognition pretrained weights boost the model convergence on age estiamtion problem in contrast to ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = argparse.ArgumentParser(description='traditional_training for face recognition.')\n",
    "\n",
    "conf.add_argument(\"--backbone_type\", type = str,default = 'EfficientNet',\n",
    "                      help = \"Mobilefacenets, Resnet.\")\n",
    "conf.add_argument(\"--backbone_conf_file\", type = str ,default ='/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/training_mode/backbone_conf.yaml', \n",
    "                      help = \"the path of backbone_conf.yaml.\")\n",
    "conf.add_argument(\"--head_type\", type = str ,default = 'AdaM-Softmax', \n",
    "                      help = \"mv-softmax, arcface, npc-face.\")\n",
    "conf.add_argument(\"--head_conf_file\", type = str ,default = '/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/training_mode/head_conf.yaml', \n",
    "                      help = \"the path of head_conf.yaml.\")\n",
    "    \n",
    "args = conf.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, model_name, weights_path=None, load_fc=True, advprop=False):\n",
    "    \"\"\"Loads pretrained weights from weights path or download using url.\n",
    "    Args:\n",
    "        model (Module): The whole model of efficientnet.\n",
    "        model_name (str): Model name of efficientnet.\n",
    "        weights_path (None or str):\n",
    "            str: path to pretrained weights file on the local disk.\n",
    "            None: use pretrained weights downloaded from the Internet.\n",
    "        load_fc (bool): Whether to load pretrained weights for fc layer at the end of the model.\n",
    "        advprop (bool): Whether to load pretrained weights\n",
    "                        trained with advprop (valid when weights_path is None).\n",
    "    \"\"\"\n",
    "    if isinstance(weights_path, str):\n",
    "        state_dict = torch.load(weights_path)['state_dict']\n",
    "        for key_name in list(state_dict.keys()):\n",
    "            new_key = key_name.replace('backbone.','')\n",
    "            state_dict[new_key] = state_dict.pop(key_name)\n",
    "    else:\n",
    "        # AutoAugment or Advprop (different preprocessing)\n",
    "        url_map_ = url_map_advprop if advprop else url_map\n",
    "        state_dict = model_zoo.load_url(url_map_[model_name])\n",
    "\n",
    "    if load_fc:\n",
    "        state_dict.pop('head.weight')\n",
    "        ret = model.load_state_dict(state_dict, strict=False)\n",
    "        assert not ret.missing_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)\n",
    "    else:\n",
    "        state_dict.pop('backbone._fc.weight')\n",
    "        state_dict.pop('backbone._fc.bias')\n",
    "        ret = model.load_state_dict(state_dict, strict=False)\n",
    "        assert set(ret.missing_keys) == set(\n",
    "            ['_fc.weight', '_fc.bias']), 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)\n",
    "    assert not ret.unexpected_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.unexpected_keys)\n",
    "\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo')\n",
    "from backbone.backbone_def import BackboneFactory\n",
    "from head.head_def import HeadFactory\n",
    "class FaceModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, backbone_factory, head_factory):\n",
    "        super(FaceModel, self).__init__()\n",
    "        #Age groups: ['1-2', '3-6', '7-12', '13-17', '18-22', '23-26', '27-33', '34-44', '45-59', '60-90']\n",
    "        self.idx_tensor = torch.from_numpy(np.array([1.5, 4.5, 9.5, 15, 20, 24.5, 30, 39, 52, 75])).to(device)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        self.backbone = backbone_factory.get_backbone()\n",
    "        self.head = head_factory.get_head()\n",
    "        self.age_group_head = Sequential(nn.BatchNorm2d(1280),nn.Flatten(),nn.Linear(in_features=62720, out_features=1000, bias=True),self.relu ,nn.Linear(in_features=1000, out_features=30, bias=True),self.relu ,nn.Linear(in_features=30, out_features=10, bias=True))\n",
    "\n",
    "    def forward(self, data):\n",
    "        grouped_age = self.age_group_head(self.backbone.extract_features(data))\n",
    "        regression_age = torch.sum(self.Softmax(grouped_age) * self.idx_tensor, axis=1)\n",
    "        return grouped_age,regression_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/backbone/backbone_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  backbone_conf = yaml.load(f)\n",
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/head/head_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  head_conf = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone param:\n",
      "{'width': 1.0, 'depth': 1.0, 'image_size': 112, 'drop_ratio': 0.2, 'out_h': 7, 'out_w': 7, 'feat_dim': 512}\n",
      "head param:\n",
      "{'feat_dim': 512, 'num_class': 72778, 'scale': 32, 'lamda': 70.0}\n",
      "Loaded pretrained weights for EfficientNet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FaceModel(\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       "  (backbone): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "    (output_layer): Sequential(\n",
       "      (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Flatten()\n",
       "      (3): Linear(in_features=62720, out_features=512, bias=True)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Adam_Softmax()\n",
       "  (age_group_head): Sequential(\n",
       "    (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=62720, out_features=1000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1000, out_features=30, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=30, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "backbone_factory = BackboneFactory(args.backbone_type, args.backbone_conf_file)   \n",
    "head_factory = HeadFactory(args.head_type, args.head_conf_file)\n",
    "efficientnet_b0_pretrained_frozen_age_head2feats = FaceModel(backbone_factory, head_factory)\n",
    "load_pretrained_weights(efficientnet_b0_pretrained_frozen_age_head2feats.backbone,args.backbone_type,weights_path ='/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/efficientnet_facerecognition_weights.pt',load_fc=True )\n",
    "efficientnet_b0_pretrained_frozen_age_head2feats.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group_head.0.weight\n",
      "age_group_head.0.bias\n",
      "age_group_head.2.weight\n",
      "age_group_head.2.bias\n",
      "age_group_head.4.weight\n",
      "age_group_head.4.bias\n",
      "age_group_head.6.weight\n",
      "age_group_head.6.bias\n"
     ]
    }
   ],
   "source": [
    "for module in efficientnet_b0_pretrained_frozen_age_head2feats.backbone.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in efficientnet_b0_pretrained_frozen_age_head2feats.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in efficientnet_b0_pretrained_frozen_age_head2feats.age_group_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name,param in efficientnet_b0_pretrained_frozen_age_head2feats.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Dataset and Dataloader for age training  with Albumentations\n",
    "class MyDataset_age(torch.utils.data.Dataset):\n",
    "    def __init__(self,root,phase,annotation_name,classes,transform = None,loader = default_loader):\n",
    "\n",
    "        self.group_dict = {0:list(range(1,3)), 1:list(range(3,7)), 2:list(range(7,13)), 3:list(range(13,18)), 4:list(range(18,23)), 5:list(range(23,27)), 6:list(range(27,34)), 7:list(range(34,45)), 8:list(range(45,60)), 9:list(range(60,91))}\n",
    "        self.phase = phase\n",
    "        self.classes = classes\n",
    "        self.attribute_frame = pandas.read_csv(join(root,annotation_name))\n",
    "        self.root = root\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        group_label = 4\n",
    "        img_path , target = join(self.root, self.attribute_frame.iloc[index, 0]), int(self.attribute_frame.iloc[index, 1])\n",
    "        for key in self.group_dict:\n",
    "            if int(target) in self.group_dict[key]:\n",
    "                group_label = key\n",
    "                break\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "    \n",
    "        \n",
    "        return img, group_label,target\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.attribute_frame)\n",
    "    \n",
    "def dataloader_age(MyDataset,root,item_prob_filename,batch_size,shuffle , num_workers):\n",
    "    item_prob_file =open(root + \"/\" + item_prob_filename, \"r\")\n",
    "    item_prob_list = item_prob_file.readlines()\n",
    "    item_prob_list = [float(item_prob_list[i]) for i in range(len(item_prob_list))]\n",
    "    t = item_prob_list.pop(0)\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(item_prob_list, len(item_prob_list))\n",
    "    return torch.utils.data.DataLoader(MyDataset, batch_size=batch_size, num_workers=num_workers,shuffle=shuffle,sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1701: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:1727: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "data_transforms_A = {\n",
    "    'train': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.RandomResizedCrop(height=112,width=112,scale=(0.5, 1.0)),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.Blur(p=0.5),#Размытие входного изображения с помощью ядра случайного размера. \n",
    "            A.GaussianBlur(p=0.5),#Размытие входного изображения с помощью фильтра Гаусса со случайным размером ядра. \n",
    "            A.GaussNoise(p=0.5),#Примените гауссовский шум к входному изображению. \n",
    "            A.ISONoise(p=0.5),#Примените шум сенсора камеры. \n",
    "            A.MedianBlur(p=0.5),#Размытие входного изображения с помощью медианного фильтра со случайным линейным размером апертуры.\n",
    "            A.MotionBlur(p=0.5),#Примените размытие движения к входному изображению, используя ядро случайного размера. \n",
    "            A.CLAHE(p=0.5),#Примените коррекцию адаптивной гистограммы с ограничением контраста к входному изображению.\n",
    "            A.Equalize(p=0.5),#Выровняйте гистограмму изображения. \n",
    "        ], p = 1),\n",
    "\n",
    "        A.core.composition.OneOf ([ \n",
    "            A.ChannelDropout(p=0.5),#Случайно отбросьте каналы во входном изображении.\n",
    "            A.ChannelShuffle(p=0.5),#Произвольно переставьте каналы входного изображения RGB.\n",
    "            A.InvertImg(p=0.5),#Инвертируйте входное изображение, вычитая значения пикселей из 255\n",
    "            A.Solarize(p=0.5),#Инвертировать все значения пикселей выше порога. \n",
    "            A.ToGray(p=0.5),#Преобразуйте входное изображение RGB в оттенки серого.\n",
    "            A.HueSaturationValue(p=0.5),#Произвольно изменяйте оттенок, насыщенность и значение входного изображения. \n",
    "            A.RandomBrightness(p=0.5),#Произвольно изменяйте яркость входного изображения. \n",
    "            A.RandomBrightnessContrast(p=0.5),#Произвольно изменяйте яркость и контраст входного изображения.\n",
    "            A.RandomContrast(p=0.5)#Произвольно изменяйте контраст входного изображения.\n",
    "        ], p = 1),\n",
    "        A.core.composition.OneOf ([ \n",
    "           A.Downscale(scale_min=0.2, scale_max=0.2,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.3, scale_max=0.3,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.4, scale_max=0.4,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.5, scale_max=0.5,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.6, scale_max=0.6,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.7, scale_max=0.7,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.8, scale_max=0.8,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.9, scale_max=0.9,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "           A.Downscale(scale_min=0.99, scale_max=0.99,p=0.5),#Уменьшает качество изображения за счет уменьшения и обратного увеличения. \n",
    "        ], p = 1),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(112, 112),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Ap.transforms.ToTensorV2()\n",
    "        ]),\n",
    "}\n",
    "\n",
    "data_dir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_GordeevN/Over_dataset'\n",
    "annotations = {'train':'anataishon_train.csv','val':'anataishon_val.csv'}\n",
    "item_probabilities = {'train':'anataishon_train_rasp.txt','val':'anataishon_val_rasp.txt'}\n",
    "image_datasets = {x: MyDataset_age(data_dir,x,annotations[x],list(range(10)),\n",
    "                                          data_transforms_A[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: dataloader_age(image_datasets[x],data_dir,item_probabilities[x], batch_size=60,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: image_datasets[x].__len__() for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train loop for age training \n",
    "def train_model(model, classification_criterion,regression_criterion, optimizer, scheduler, losses_ratio = None,num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_class_loss = 0.0\n",
    "            running_regress_loss = 0.0\n",
    "            \n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, class_labels,regress_labels in dataloaders[phase]:\n",
    "                class_labels = class_labels.type(torch.FloatTensor)\n",
    "                regress_labels = regress_labels.type(torch.FloatTensor)\n",
    "                inputs = inputs.to(device)\n",
    "                class_labels = class_labels.to(device)\n",
    "                regress_labels = regress_labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    age_group,age_digit = model(inputs)[1]\n",
    "                    batch_regression_loss = regression_criterion(age_digit, regress_labels)\n",
    "                    batch_classification_loss = classification_criterion(age_group, class_labels.long())\n",
    "                    \n",
    "                    \n",
    "                    if (losses_ratio == None):\n",
    "                        if (batch_regression_loss > batch_classification_loss):\n",
    "                            alpha = batch_regression_loss / batch_classification_loss\n",
    "                            loss = alpha * batch_classification_loss + batch_regression_loss\n",
    "                        else:\n",
    "                            alpha = batch_classification_loss / batch_regression_loss\n",
    "                            loss = batch_classification_loss +  alpha * batch_regression_loss\n",
    "                    else:\n",
    "                        loss = losses_ratio[0] * batch_regression_loss + losses_ratio[1] * batch_classification_loss\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_class_loss += batch_classification_loss.item() * inputs.size(0)\n",
    "                running_regress_loss += batch_regression_loss.item() * inputs.size(0)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_class_loss = running_class_loss / dataset_sizes[phase]\n",
    "            epoch_regress_loss = running_regress_loss/ dataset_sizes[phase]\n",
    "            avrg_epoch_loss = (epoch_class_loss+epoch_regress_loss)/2\n",
    "\n",
    "            \n",
    "            print('{} Classificatoin_Loss: {:.4f} Regression_Loss: {:.4f}'.format(\n",
    "                phase, epoch_class_loss, epoch_regress_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and avrg_epoch_loss < best_loss:\n",
    "                best_loss = avrg_epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the section below we are going to train efficient-b0 model with recognition weights with frozen backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.4769 Regression_Loss: 22.5765\n",
      "val Classificatoin_Loss: 2.5571 Regression_Loss: 22.3863\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.4636 Regression_Loss: 22.3584\n",
      "val Classificatoin_Loss: 2.3597 Regression_Loss: 22.4925\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.1732 Regression_Loss: 22.3991\n",
      "val Classificatoin_Loss: 2.0201 Regression_Loss: 21.8635\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0259 Regression_Loss: 22.0205\n",
      "val Classificatoin_Loss: 1.9702 Regression_Loss: 21.5281\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0099 Regression_Loss: 21.7250\n",
      "val Classificatoin_Loss: 1.9717 Regression_Loss: 20.9239\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0117 Regression_Loss: 21.6252\n",
      "val Classificatoin_Loss: 2.0489 Regression_Loss: 22.1098\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0106 Regression_Loss: 21.4589\n",
      "val Classificatoin_Loss: 1.9625 Regression_Loss: 21.2065\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.9889 Regression_Loss: 20.9971\n",
      "val Classificatoin_Loss: 1.9797 Regression_Loss: 20.7230\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0160 Regression_Loss: 20.8099\n",
      "val Classificatoin_Loss: 1.9708 Regression_Loss: 20.5305\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0152 Regression_Loss: 20.6660\n",
      "val Classificatoin_Loss: 1.9821 Regression_Loss: 19.9553\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0167 Regression_Loss: 20.8627\n",
      "val Classificatoin_Loss: 1.9791 Regression_Loss: 20.3403\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0084 Regression_Loss: 20.5975\n",
      "val Classificatoin_Loss: 1.9895 Regression_Loss: 20.3208\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0222 Regression_Loss: 20.6660\n",
      "val Classificatoin_Loss: 1.9739 Regression_Loss: 20.3748\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0238 Regression_Loss: 20.7030\n",
      "val Classificatoin_Loss: 2.0278 Regression_Loss: 20.2707\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0152 Regression_Loss: 20.5217\n",
      "val Classificatoin_Loss: 1.9987 Regression_Loss: 20.0580\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0031 Regression_Loss: 20.4359\n",
      "val Classificatoin_Loss: 1.9962 Regression_Loss: 20.2204\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0077 Regression_Loss: 20.4470\n",
      "val Classificatoin_Loss: 1.9876 Regression_Loss: 20.3413\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0147 Regression_Loss: 20.3888\n",
      "val Classificatoin_Loss: 1.9868 Regression_Loss: 20.2046\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0072 Regression_Loss: 20.4705\n",
      "val Classificatoin_Loss: 1.9794 Regression_Loss: 20.2060\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0167 Regression_Loss: 20.4122\n",
      "val Classificatoin_Loss: 2.0160 Regression_Loss: 20.1746\n",
      "\n",
      "Training complete in 37m 52s\n",
      "Best val loss: 10.968652\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(efficientnet_b0_pretrained_frozen_age_head2feats.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "efficientnet_b0_pretrained_frozen_age_head2feats = train_model(efficientnet_b0_pretrained_frozen_age_head2feats, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age-head training of efficent-b0 hasn't yielded considerable accuracy. Merely 20 loss converece \n",
    "\n",
    "## Further let's train recognition efficient-b0 entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/backbone/backbone_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  backbone_conf = yaml.load(f)\n",
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/head/head_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  head_conf = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone param:\n",
      "{'width': 1.0, 'depth': 1.0, 'image_size': 112, 'drop_ratio': 0.2, 'out_h': 7, 'out_w': 7, 'feat_dim': 512}\n",
      "head param:\n",
      "{'feat_dim': 512, 'num_class': 72778, 'scale': 32, 'lamda': 70.0}\n",
      "Loaded pretrained weights for EfficientNet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FaceModel(\n",
       "  (relu): ReLU()\n",
       "  (Softmax): Softmax(dim=1)\n",
       "  (backbone): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "    (output_layer): Sequential(\n",
       "      (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Flatten()\n",
       "      (3): Linear(in_features=62720, out_features=512, bias=True)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Adam_Softmax()\n",
       "  (age_group_head): Sequential(\n",
       "    (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=62720, out_features=1000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1000, out_features=30, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=30, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_factory = BackboneFactory(args.backbone_type, args.backbone_conf_file)   \n",
    "head_factory = HeadFactory(args.head_type, args.head_conf_file)\n",
    "efficientnet_b0_pretrained_entirely_age_head2feats = FaceModel(backbone_factory, head_factory)\n",
    "load_pretrained_weights(efficientnet_b0_pretrained_entirely_age_head2feats.backbone,args.backbone_type,weights_path ='/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/efficientnet_facerecognition_weights.pt',load_fc=True )\n",
    "efficientnet_b0_pretrained_entirely_age_head2feats.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.6525 Regression_Loss: 22.2847\n",
      "val Classificatoin_Loss: 2.2526 Regression_Loss: 21.0732\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.9758 Regression_Loss: 13.6190\n",
      "val Classificatoin_Loss: 1.8279 Regression_Loss: 9.0696\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.6739 Regression_Loss: 10.1495\n",
      "val Classificatoin_Loss: 1.5256 Regression_Loss: 9.2586\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.6127 Regression_Loss: 9.2943\n",
      "val Classificatoin_Loss: 1.6316 Regression_Loss: 7.4620\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.5762 Regression_Loss: 9.0202\n",
      "val Classificatoin_Loss: 1.5283 Regression_Loss: 7.3777\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4965 Regression_Loss: 8.5143\n",
      "val Classificatoin_Loss: 1.4622 Regression_Loss: 6.9260\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.5270 Regression_Loss: 8.1669\n",
      "val Classificatoin_Loss: 1.3838 Regression_Loss: 7.1983\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4695 Regression_Loss: 7.6170\n",
      "val Classificatoin_Loss: 1.4365 Regression_Loss: 6.8511\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4822 Regression_Loss: 7.4509\n",
      "val Classificatoin_Loss: 1.4388 Regression_Loss: 6.7342\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4749 Regression_Loss: 7.4302\n",
      "val Classificatoin_Loss: 1.3964 Regression_Loss: 6.7468\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4693 Regression_Loss: 7.3480\n",
      "val Classificatoin_Loss: 1.4700 Regression_Loss: 6.6746\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4873 Regression_Loss: 7.3330\n",
      "val Classificatoin_Loss: 1.4119 Regression_Loss: 6.5859\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4645 Regression_Loss: 7.3017\n",
      "val Classificatoin_Loss: 1.4703 Regression_Loss: 6.6285\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4707 Regression_Loss: 7.2936\n",
      "val Classificatoin_Loss: 1.4287 Regression_Loss: 6.6964\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4785 Regression_Loss: 7.2162\n",
      "val Classificatoin_Loss: 1.4331 Regression_Loss: 6.5267\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.5003 Regression_Loss: 7.1703\n",
      "val Classificatoin_Loss: 1.4311 Regression_Loss: 6.5643\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4532 Regression_Loss: 7.1983\n",
      "val Classificatoin_Loss: 1.4082 Regression_Loss: 6.5530\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4712 Regression_Loss: 7.1344\n",
      "val Classificatoin_Loss: 1.4187 Regression_Loss: 6.4801\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4543 Regression_Loss: 7.1361\n",
      "val Classificatoin_Loss: 1.4231 Regression_Loss: 6.5383\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4605 Regression_Loss: 7.1623\n",
      "val Classificatoin_Loss: 1.4120 Regression_Loss: 6.6213\n",
      "\n",
      "Training complete in 38m 1s\n",
      "Best val loss: 3.949399\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(efficientnet_b0_pretrained_entirely_age_head2feats.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "efficientnet_b0_pretrained_entirely_age_head2feats = train_model(efficientnet_b0_pretrained_entirely_age_head2feats, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4744 Regression_Loss: 7.1828\n",
      "val Classificatoin_Loss: 1.4226 Regression_Loss: 6.4838\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4786 Regression_Loss: 7.1702\n",
      "val Classificatoin_Loss: 1.4321 Regression_Loss: 6.5857\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4663 Regression_Loss: 7.1440\n",
      "val Classificatoin_Loss: 1.4612 Regression_Loss: 6.5708\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4530 Regression_Loss: 7.1184\n",
      "val Classificatoin_Loss: 1.4395 Regression_Loss: 6.6653\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4494 Regression_Loss: 7.1719\n",
      "val Classificatoin_Loss: 1.3832 Regression_Loss: 6.5508\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4631 Regression_Loss: 7.1412\n",
      "val Classificatoin_Loss: 1.4231 Regression_Loss: 6.4754\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4626 Regression_Loss: 7.1027\n",
      "val Classificatoin_Loss: 1.4327 Regression_Loss: 6.5219\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4546 Regression_Loss: 7.1211\n",
      "val Classificatoin_Loss: 1.4604 Regression_Loss: 6.5355\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4600 Regression_Loss: 7.1749\n",
      "val Classificatoin_Loss: 1.4189 Regression_Loss: 6.6556\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4659 Regression_Loss: 7.0580\n",
      "val Classificatoin_Loss: 1.4254 Regression_Loss: 6.4453\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4697 Regression_Loss: 7.1648\n",
      "val Classificatoin_Loss: 1.4545 Regression_Loss: 6.4870\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4695 Regression_Loss: 7.2063\n",
      "val Classificatoin_Loss: 1.4448 Regression_Loss: 6.5892\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4810 Regression_Loss: 7.1451\n",
      "val Classificatoin_Loss: 1.4624 Regression_Loss: 6.6105\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4636 Regression_Loss: 7.2043\n",
      "val Classificatoin_Loss: 1.4402 Regression_Loss: 6.4220\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4685 Regression_Loss: 7.1411\n",
      "val Classificatoin_Loss: 1.4553 Regression_Loss: 6.5913\n",
      "\n",
      "Training complete in 43m 18s\n",
      "Best val loss: 3.931109\n"
     ]
    }
   ],
   "source": [
    "efficientnet_b0_pretrained_entirely_age_head2feats = train_model(efficientnet_b0_pretrained_entirely_age_head2feats, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not bad results. Mean age error is 6.5 years\n",
    "\n",
    "\n",
    "## Let's train the same model versions(frozen backbone,trained entirely), but with ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group_head.0.weight\n",
      "age_group_head.0.bias\n",
      "age_group_head.2.weight\n",
      "age_group_head.2.bias\n"
     ]
    }
   ],
   "source": [
    "class MultiTaskModel_aged_Tensor(nn.Module):\n",
    "    def __init__(self,model_backbone):\n",
    "        super(MultiTaskModel_aged_Tensor,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.Softmax = nn.Softmax(1)\n",
    "        self.encoder = model_backbone\n",
    "        self.gender_head = Sequential(nn.Linear(in_features=1280, out_features=1000, bias=True),self.relu ,nn.Linear(in_features=1000, out_features=30, bias=True),self.relu,nn.Linear(30,2))   \n",
    "\n",
    "        self.age_group_head = Sequential(nn.Linear(in_features=1280, out_features=1400, bias=True),self.relu,nn.Linear(in_features=1400, out_features=10, bias=True))\n",
    "        self.expression_head =  Sequential(nn.Linear(in_features=1280, out_features=1400, bias=True),self.relu,nn.Linear(in_features=1400, out_features=7, bias=True))\n",
    "        #Age groups: ['1-2', '3-6', '7-12', '13-17', '18-22', '23-26', '27-33', '34-44', '45-59', '60-90']\n",
    "        self.idx_tensor = torch.from_numpy(np.array([1.5, 4.5, 9.5, 15, 20, 24.5, 30, 39, 52, 75])).to(device)\n",
    "    def forward(self,x):\n",
    "        features = self.encoder(x)\n",
    "        gender = self.gender_head(self.relu(features))\n",
    "        expression = self.expression_head(self.relu(features))\n",
    "        \n",
    "        grouped_age = self.age_group_head(self.relu(features))\n",
    "        regression_age = torch.sum(self.Softmax(grouped_age) * self.idx_tensor, axis=1)\n",
    "        return [gender, (grouped_age,regression_age),  expression]\n",
    "    \n",
    "    \n",
    "efficientb0_imagnet_frozen = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "efficientb0_imagnet_frozen.classifier = nn.Sequential(*list(efficientb0_imagnet_frozen.classifier.children())[:-3])\n",
    "efficientb0_imagnet_frozen = MultiTaskModel_aged_Tensor(efficientb0_imagnet_frozen)\n",
    "\n",
    "efficientb0_imagnet_frozen = efficientb0_imagnet_frozen.to(device)\n",
    "\n",
    "for module in efficientb0_imagnet_frozen.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in efficientb0_imagnet_frozen.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in efficientb0_imagnet_frozen.age_group_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name,param in efficientb0_imagnet_frozen.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0373 Regression_Loss: 18.3849\n",
      "val Classificatoin_Loss: 1.9782 Regression_Loss: 13.1766\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0751 Regression_Loss: 16.4312\n",
      "val Classificatoin_Loss: 1.9432 Regression_Loss: 12.4817\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0469 Regression_Loss: 15.9618\n",
      "val Classificatoin_Loss: 1.9085 Regression_Loss: 12.1514\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0275 Regression_Loss: 15.6369\n",
      "val Classificatoin_Loss: 1.9052 Regression_Loss: 12.2448\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0061 Regression_Loss: 15.5745\n",
      "val Classificatoin_Loss: 1.9262 Regression_Loss: 11.9246\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.9970 Regression_Loss: 15.3033\n",
      "val Classificatoin_Loss: 1.8413 Regression_Loss: 11.7910\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.9967 Regression_Loss: 15.1258\n",
      "val Classificatoin_Loss: 1.8690 Regression_Loss: 11.9358\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.9858 Regression_Loss: 14.9961\n",
      "val Classificatoin_Loss: 1.8828 Regression_Loss: 11.5550\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0058 Regression_Loss: 14.8322\n",
      "val Classificatoin_Loss: 1.8987 Regression_Loss: 11.5947\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0055 Regression_Loss: 14.8804\n",
      "val Classificatoin_Loss: 1.9103 Regression_Loss: 11.8203\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0147 Regression_Loss: 14.9601\n",
      "val Classificatoin_Loss: 1.8855 Regression_Loss: 11.5110\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0331 Regression_Loss: 14.7363\n",
      "val Classificatoin_Loss: 1.8855 Regression_Loss: 11.6829\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0370 Regression_Loss: 14.7205\n",
      "val Classificatoin_Loss: 1.8884 Regression_Loss: 11.4733\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0317 Regression_Loss: 14.8669\n",
      "val Classificatoin_Loss: 1.9268 Regression_Loss: 11.3059\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0383 Regression_Loss: 14.8869\n",
      "val Classificatoin_Loss: 1.8912 Regression_Loss: 11.4823\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0414 Regression_Loss: 14.8318\n",
      "val Classificatoin_Loss: 1.8961 Regression_Loss: 11.6420\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0406 Regression_Loss: 14.7813\n",
      "val Classificatoin_Loss: 1.8835 Regression_Loss: 11.3436\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0361 Regression_Loss: 14.7018\n",
      "val Classificatoin_Loss: 1.9212 Regression_Loss: 11.5863\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0464 Regression_Loss: 14.7635\n",
      "val Classificatoin_Loss: 1.9223 Regression_Loss: 11.4826\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 2.0501 Regression_Loss: 14.8630\n",
      "val Classificatoin_Loss: 1.9115 Regression_Loss: 11.5422\n",
      "\n",
      "Training complete in 26m 23s\n",
      "Best val loss: 6.613585\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(efficientb0_imagnet_frozen.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "efficientb0_imagnet_frozen = train_model(efficientb0_imagnet_frozen, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientb0_imagnet_entirely = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "efficientb0_imagnet_entirely.classifier = nn.Sequential(*list(efficientb0_imagnet_entirely.classifier.children())[:-3])\n",
    "efficientb0_imagnet_entirely = MultiTaskModel_aged_Tensor(efficientb0_imagnet_entirely)\n",
    "\n",
    "efficientb0_imagnet_entirely = efficientb0_imagnet_entirely.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.7724 Regression_Loss: 14.8265\n",
      "val Classificatoin_Loss: 1.5822 Regression_Loss: 11.0553\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.6207 Regression_Loss: 11.0434\n",
      "val Classificatoin_Loss: 1.5522 Regression_Loss: 10.3698\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.5018 Regression_Loss: 9.9029\n",
      "val Classificatoin_Loss: 1.3788 Regression_Loss: 8.5092\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4642 Regression_Loss: 9.4897\n",
      "val Classificatoin_Loss: 1.4420 Regression_Loss: 10.0156\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.4139 Regression_Loss: 9.1387\n",
      "val Classificatoin_Loss: 1.3156 Regression_Loss: 8.2566\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.3831 Regression_Loss: 8.8564\n",
      "val Classificatoin_Loss: 1.2902 Regression_Loss: 8.3827\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.3447 Regression_Loss: 8.6463\n",
      "val Classificatoin_Loss: 1.2441 Regression_Loss: 7.7302\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2743 Regression_Loss: 7.9354\n",
      "val Classificatoin_Loss: 1.2038 Regression_Loss: 7.3419\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2634 Regression_Loss: 7.7507\n",
      "val Classificatoin_Loss: 1.2220 Regression_Loss: 7.3682\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2618 Regression_Loss: 7.6429\n",
      "val Classificatoin_Loss: 1.2391 Regression_Loss: 7.3679\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2598 Regression_Loss: 7.6274\n",
      "val Classificatoin_Loss: 1.2005 Regression_Loss: 7.3503\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2492 Regression_Loss: 7.6640\n",
      "val Classificatoin_Loss: 1.2113 Regression_Loss: 7.3100\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2504 Regression_Loss: 7.6234\n",
      "val Classificatoin_Loss: 1.2118 Regression_Loss: 7.3478\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2659 Regression_Loss: 7.5638\n",
      "val Classificatoin_Loss: 1.2136 Regression_Loss: 7.2659\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2421 Regression_Loss: 7.4350\n",
      "val Classificatoin_Loss: 1.2186 Regression_Loss: 7.2496\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2505 Regression_Loss: 7.4215\n",
      "val Classificatoin_Loss: 1.1900 Regression_Loss: 7.1245\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2419 Regression_Loss: 7.4344\n",
      "val Classificatoin_Loss: 1.1774 Regression_Loss: 7.1653\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2502 Regression_Loss: 7.5458\n",
      "val Classificatoin_Loss: 1.2080 Regression_Loss: 7.2036\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2447 Regression_Loss: 7.4276\n",
      "val Classificatoin_Loss: 1.1911 Regression_Loss: 7.1966\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2395 Regression_Loss: 7.4267\n",
      "val Classificatoin_Loss: 1.2079 Regression_Loss: 7.2398\n",
      "\n",
      "Training complete in 26m 2s\n",
      "Best val loss: 4.157284\n"
     ]
    }
   ],
   "source": [
    "class_criterion = nn.CrossEntropyLoss()\n",
    "regress_criterion = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_ft = optim.SGD(efficientb0_imagnet_entirely.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "efficientb0_imagnet_entirely = train_model(efficientb0_imagnet_entirely, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.3159 Regression_Loss: 8.1332\n",
      "val Classificatoin_Loss: 1.2150 Regression_Loss: 7.3968\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.3203 Regression_Loss: 8.2050\n",
      "val Classificatoin_Loss: 1.2514 Regression_Loss: 7.6909\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2774 Regression_Loss: 7.9809\n",
      "val Classificatoin_Loss: 1.2209 Regression_Loss: 7.6197\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2583 Regression_Loss: 7.8078\n",
      "val Classificatoin_Loss: 1.1754 Regression_Loss: 7.5947\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2500 Regression_Loss: 7.8101\n",
      "val Classificatoin_Loss: 1.2142 Regression_Loss: 7.4053\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2541 Regression_Loss: 7.7957\n",
      "val Classificatoin_Loss: 1.1909 Regression_Loss: 7.3045\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.2317 Regression_Loss: 7.6584\n",
      "val Classificatoin_Loss: 1.1730 Regression_Loss: 7.2762\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1770 Regression_Loss: 7.0916\n",
      "val Classificatoin_Loss: 1.1481 Regression_Loss: 6.8834\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1689 Regression_Loss: 7.0920\n",
      "val Classificatoin_Loss: 1.1355 Regression_Loss: 6.8540\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1636 Regression_Loss: 7.0324\n",
      "val Classificatoin_Loss: 1.1331 Regression_Loss: 7.0377\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1669 Regression_Loss: 6.9823\n",
      "val Classificatoin_Loss: 1.1683 Regression_Loss: 7.0055\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1613 Regression_Loss: 6.8752\n",
      "val Classificatoin_Loss: 1.1671 Regression_Loss: 6.9265\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1642 Regression_Loss: 6.9574\n",
      "val Classificatoin_Loss: 1.1446 Regression_Loss: 6.9364\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1464 Regression_Loss: 6.9216\n",
      "val Classificatoin_Loss: 1.1222 Regression_Loss: 6.8371\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Classificatoin_Loss: 1.1470 Regression_Loss: 6.8345\n",
      "val Classificatoin_Loss: 1.1094 Regression_Loss: 6.9896\n",
      "\n",
      "Training complete in 19m 50s\n",
      "Best val loss: 3.979669\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(efficientb0_imagnet_entirely.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "efficientb0_imagnet_entirely = train_model(efficientb0_imagnet_entirely, class_criterion,regress_criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As can be concluded, ImageNet weights brought significant L1loss when it comes to frozen version\n",
    "\n",
    "## As for entirely trained version, seems like face recognition weights boost expression training more than ImageNet ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
