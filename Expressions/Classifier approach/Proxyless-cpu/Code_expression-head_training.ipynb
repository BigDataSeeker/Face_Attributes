{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook aims to train proxyless with frozen backbone on different facial expression datasets and find out which datasets enable better convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as Ap\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import csv\n",
    "import PIL\n",
    "import pandas\n",
    "from os.path import join\n",
    "import copy\n",
    "import timm \n",
    "from collections import OrderedDict\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.MyDataset_expression_IMFDB import MyDataset_expression_IMFDB\n",
    "from Datasets.MyDataset_expression_FER2013 import MyDataset_expression_FER2013\n",
    "from Datasets.MyDataset_expression_OZON import MyDataset_expression_OZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(112),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(112),\n",
    "        transforms.CenterCrop(100),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Let's create dataloader for FER2013 dataset only\n",
    "to_csv_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/fer2013/train.csv'\n",
    "image_datasets_FER2013 = {x: MyDataset_expression_FER2013(to_csv_path,x,{0:4,1:5,2:6,3:1,4:2,5:3,6:0},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders_FER2013 = {x: torch.utils.data.DataLoader(image_datasets_FER2013[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes_FER2013 = {x: image_datasets_FER2013[x].__len__() for x in ['train', 'val']}\n",
    "\n",
    "# Let's create dataloader for IMFDB dataset only\n",
    "annotations_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/IMFDB_final_processed/overall_path_expression_annotation_existing_files.txt'\n",
    "image_datasets_IMFDB = {x: MyDataset_expression_IMFDB(annotations_path,x,{'NEUTRAL':0, 'HAPPINESS':1, 'SADNESS':2, 'SURPRISE':3, 'ANGER':4, 'DISGUST':5,'FEAR':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders_IMFDB = {x: torch.utils.data.DataLoader(image_datasets_IMFDB[x], batch_size=28,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes_IMFDB = {x: image_datasets_IMFDB[x].__len__() for x in ['train', 'val']}\n",
    "\n",
    "# Let's create dataloader for IMFDB-FER2013 composite dataset\n",
    "image_datasets_IMFDB_FER2013 = {x: torch.utils.data.ConcatDataset([image_datasets_FER2013[x],image_datasets_IMFDB[x]]) for x in ['train', 'val']}\n",
    "dataloaders_IMFDB_FER2013 = {x: torch.utils.data.DataLoader(image_datasets_IMFDB_FER2013[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes_IMFDB_FER2013 = {x: image_datasets_IMFDB_FER2013[x].__len__() for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create dataloader for OZON dataset only\n",
    "annotations_path_ozon = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train_7expressions_annotation.txt'\n",
    "image_datasets_ozon = {x: MyDataset_expression_OZON(annotations_path_ozon,x,{'neutral':0, 'happy':1, 'sad':2, 'surprise':3, 'anger':4, 'disgust':5,'fear':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders_ozon = {x: torch.utils.data.DataLoader(image_datasets_ozon[x], batch_size=28,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes_ozon = {x: image_datasets_ozon[x].__len__() for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create dataloader for IMFDB-FER2013-OZON composite dataset\n",
    "image_datasets_IMFDB_FER2013_OZON = {x: torch.utils.data.ConcatDataset([image_datasets_FER2013[x],image_datasets_IMFDB[x],image_datasets_ozon[x]]) for x in ['train', 'val']}\n",
    "dataloaders_IMFDB_FER2013_OZON = {x: torch.utils.data.DataLoader(image_datasets_IMFDB_FER2013_OZON[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes_IMFDB_FER2013_OZON = {x: image_datasets_IMFDB_FER2013_OZON[x].__len__() for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create dataloader for IMFDB-OZON composite dataset\n",
    "image_datasets_IMFDB_OZON = {x: torch.utils.data.ConcatDataset([image_datasets_IMFDB[x],image_datasets_ozon[x]]) for x in ['train', 'val']}\n",
    "dataloaders_IMFDB_OZON = {x: torch.utils.data.DataLoader(image_datasets_IMFDB_OZON[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes_IMFDB_OZON = {x: image_datasets_IMFDB_OZON[x].__len__() for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler,dataloaders,dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)[2]\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.MultiTaskModel_grouped_age_head_proxyless import MultiTaskModel_grouped_age_head\n",
    "from utils.MultiTaskModel_proxyless import MultiTaskModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiTaskModel_grouped_age_head(\n",
       "  (encoder): MultiTaskModel(\n",
       "    (encoder): ProxylessNASNets(\n",
       "      (first_conv): ConvLayer(\n",
       "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6(inplace=True)\n",
       "        (conv): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "              (bn): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (3): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (4): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (5): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (7): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (8): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "              (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (9): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): ZeroLayer()\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (11): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): ZeroLayer()\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (12): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(88, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=264, bias=False)\n",
       "              (bn): BatchNorm2d(264, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(264, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (13): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "              (bn): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(528, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (15): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (16): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 312, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(312, 312, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=312, bias=False)\n",
       "              (bn): BatchNorm2d(312, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(312, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(104, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (17): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(104, 624, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(624, 624, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=624, bias=False)\n",
       "              (bn): BatchNorm2d(624, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(624, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (19): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (20): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 648, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(648, 648, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=648, bias=False)\n",
       "              (bn): BatchNorm2d(648, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(648, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(216, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (shortcut): IdentityLayer()\n",
       "        )\n",
       "        (21): MobileInvertedResidualBlock(\n",
       "          (mobile_inverted_conv): MBInvertedConvLayer(\n",
       "            (inverted_bottleneck): Sequential(\n",
       "              (conv): Conv2d(216, 1296, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (depth_conv): Sequential(\n",
       "              (conv): Conv2d(1296, 1296, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1296, bias=False)\n",
       "              (bn): BatchNorm2d(1296, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (relu): ReLU6(inplace=True)\n",
       "            )\n",
       "            (point_linear): Sequential(\n",
       "              (conv): Conv2d(1296, 360, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(360, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (feature_mix_layer): ConvLayer(\n",
       "        (bn): BatchNorm2d(1432, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU6(inplace=True)\n",
       "        (conv): Conv2d(360, 1432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (global_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "      (classifier): Sequential()\n",
       "    )\n",
       "    (fc1): Linear(in_features=1432, out_features=2, bias=True)\n",
       "    (fc2): Linear(in_features=1432, out_features=1400, bias=True)\n",
       "    (fc3): Linear(in_features=1432, out_features=7, bias=True)\n",
       "  )\n",
       "  (age_group_head): Linear(in_features=1400, out_features=31, bias=True)\n",
       "  (Softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_age_trained.pth',map_location=device))\n",
    "model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "#Freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen model training on FER2013 dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.8163 Acc: 0.2430\n",
      "val Loss: 1.8044 Acc: 0.2526\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.8043 Acc: 0.2462\n",
      "val Loss: 1.8136 Acc: 0.2548\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.8024 Acc: 0.2474\n",
      "val Loss: 1.8181 Acc: 0.2562\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.7994 Acc: 0.2468\n",
      "val Loss: 1.8236 Acc: 0.2473\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.7997 Acc: 0.2476\n",
      "val Loss: 1.7993 Acc: 0.2538\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.7994 Acc: 0.2540\n",
      "val Loss: 1.8122 Acc: 0.2526\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.7981 Acc: 0.2497\n",
      "val Loss: 1.7981 Acc: 0.2543\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.7908 Acc: 0.2551\n",
      "val Loss: 1.7915 Acc: 0.2555\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.7904 Acc: 0.2579\n",
      "val Loss: 1.7932 Acc: 0.2557\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.7890 Acc: 0.2570\n",
      "val Loss: 1.7950 Acc: 0.2554\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.7919 Acc: 0.2555\n",
      "val Loss: 1.7945 Acc: 0.2552\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.7898 Acc: 0.2580\n",
      "val Loss: 1.7933 Acc: 0.2552\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.7904 Acc: 0.2577\n",
      "val Loss: 1.7914 Acc: 0.2545\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.2569\n",
      "val Loss: 1.7964 Acc: 0.2552\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.7907 Acc: 0.2564\n",
      "val Loss: 1.7934 Acc: 0.2555\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.7890 Acc: 0.2552\n",
      "val Loss: 1.7929 Acc: 0.2550\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.7880 Acc: 0.2584\n",
      "val Loss: 1.7926 Acc: 0.2554\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.7893 Acc: 0.2591\n",
      "val Loss: 1.7929 Acc: 0.2552\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.7889 Acc: 0.2556\n",
      "val Loss: 1.7926 Acc: 0.2557\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.7884 Acc: 0.2561\n",
      "val Loss: 1.7926 Acc: 0.2554\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.7884 Acc: 0.2586\n",
      "val Loss: 1.7925 Acc: 0.2555\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.7863 Acc: 0.2580\n",
      "val Loss: 1.7925 Acc: 0.2554\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.7882 Acc: 0.2585\n",
      "val Loss: 1.7925 Acc: 0.2555\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.7890 Acc: 0.2586\n",
      "val Loss: 1.7925 Acc: 0.2555\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.7873 Acc: 0.2576\n",
      "val Loss: 1.7925 Acc: 0.2555\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.7884 Acc: 0.2592\n",
      "val Loss: 1.7925 Acc: 0.2555\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.7894 Acc: 0.2567\n",
      "val Loss: 1.7924 Acc: 0.2559\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.7880 Acc: 0.2567\n",
      "val Loss: 1.7925 Acc: 0.2559\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.7891 Acc: 0.2567\n",
      "val Loss: 1.7925 Acc: 0.2559\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.7874 Acc: 0.2598\n",
      "val Loss: 1.7925 Acc: 0.2559\n",
      "\n",
      "Training complete in 10m 57s\n",
      "Best val Acc: 0.256227\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_FER2013,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_age_trained.pth',map_location=device))\n",
    "model_ft.to(device)\n",
    "\n",
    "#freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozem model training on IMFDB dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.6863 Acc: 0.3411\n",
      "val Loss: 1.5876 Acc: 0.3868\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.6451 Acc: 0.3611\n",
      "val Loss: 1.5858 Acc: 0.3972\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.6467 Acc: 0.3620\n",
      "val Loss: 1.6213 Acc: 0.3454\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.6313 Acc: 0.3693\n",
      "val Loss: 1.5572 Acc: 0.3956\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.6240 Acc: 0.3705\n",
      "val Loss: 1.5400 Acc: 0.4127\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.6260 Acc: 0.3676\n",
      "val Loss: 1.5389 Acc: 0.4136\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.6200 Acc: 0.3690\n",
      "val Loss: 1.5554 Acc: 0.3972\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.5653 Acc: 0.3946\n",
      "val Loss: 1.5043 Acc: 0.4217\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.5630 Acc: 0.3956\n",
      "val Loss: 1.5037 Acc: 0.4171\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.5566 Acc: 0.3992\n",
      "val Loss: 1.4977 Acc: 0.4265\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.5544 Acc: 0.3973\n",
      "val Loss: 1.5041 Acc: 0.4176\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.5548 Acc: 0.3969\n",
      "val Loss: 1.5008 Acc: 0.4165\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.5488 Acc: 0.4011\n",
      "val Loss: 1.4940 Acc: 0.4288\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.5500 Acc: 0.3997\n",
      "val Loss: 1.4963 Acc: 0.4226\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.5419 Acc: 0.4018\n",
      "val Loss: 1.4913 Acc: 0.4282\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.5458 Acc: 0.4037\n",
      "val Loss: 1.4902 Acc: 0.4275\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.5494 Acc: 0.3999\n",
      "val Loss: 1.4904 Acc: 0.4275\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.5414 Acc: 0.4046\n",
      "val Loss: 1.4912 Acc: 0.4269\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.5446 Acc: 0.4054\n",
      "val Loss: 1.4883 Acc: 0.4307\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.5453 Acc: 0.4032\n",
      "val Loss: 1.4909 Acc: 0.4256\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.5450 Acc: 0.4024\n",
      "val Loss: 1.4893 Acc: 0.4285\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.5460 Acc: 0.3983\n",
      "val Loss: 1.4893 Acc: 0.4277\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.5448 Acc: 0.4067\n",
      "val Loss: 1.4892 Acc: 0.4272\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.5414 Acc: 0.4042\n",
      "val Loss: 1.4893 Acc: 0.4282\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.5429 Acc: 0.4034\n",
      "val Loss: 1.4893 Acc: 0.4277\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.5437 Acc: 0.4056\n",
      "val Loss: 1.4893 Acc: 0.4278\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.5429 Acc: 0.4038\n",
      "val Loss: 1.4892 Acc: 0.4277\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.5380 Acc: 0.4066\n",
      "val Loss: 1.4892 Acc: 0.4283\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.5414 Acc: 0.4055\n",
      "val Loss: 1.4892 Acc: 0.4283\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.5434 Acc: 0.4054\n",
      "val Loss: 1.4892 Acc: 0.4286\n",
      "\n",
      "Training complete in 14m 37s\n",
      "Best val Acc: 0.430749\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_IMFDB,dataset_sizes_IMFDB,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_age_trained.pth',map_location=device))\n",
    "model_ft.to(device)\n",
    "\n",
    "#Freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen model training on IMFDB-FER2013 composite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9967 Acc: 0.1289\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9940 Acc: 0.1352\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9962 Acc: 0.1346\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9959 Acc: 0.1339\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9942 Acc: 0.1329\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9926 Acc: 0.1345\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9954 Acc: 0.1309\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9929 Acc: 0.1356\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9947 Acc: 0.1318\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.9957 Acc: 0.1328\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.9945 Acc: 0.1340\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.9940 Acc: 0.1334\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.9959 Acc: 0.1326\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.9947 Acc: 0.1331\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.9952 Acc: 0.1332\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.9971 Acc: 0.1306\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.9952 Acc: 0.1336\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.9941 Acc: 0.1344\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.9955 Acc: 0.1345\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.9944 Acc: 0.1338\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.9962 Acc: 0.1297\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.9956 Acc: 0.1308\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.9954 Acc: 0.1329\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.9951 Acc: 0.1339\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.9966 Acc: 0.1339\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.9933 Acc: 0.1353\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.9951 Acc: 0.1314\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.9960 Acc: 0.1317\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.9957 Acc: 0.1320\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.9958 Acc: 0.1308\n",
      "val Loss: 2.0480 Acc: 0.0832\n",
      "\n",
      "Training complete in 25m 15s\n",
      "Best val Acc: 0.083228\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_IMFDB_FER2013,dataset_sizes_IMFDB_FER2013,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n"
     ]
    }
   ],
   "source": [
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_classes_3_heads.pth',map_location=device))\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "\n",
    "model_ft.to(device)\n",
    "\n",
    "#freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen model training on OZON dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7420 Acc: 0.3419\n",
      "val Loss: 1.6746 Acc: 0.3511\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.7132 Acc: 0.3477\n",
      "val Loss: 1.6441 Acc: 0.3624\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.7143 Acc: 0.3489\n",
      "val Loss: 1.6273 Acc: 0.3744\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.7083 Acc: 0.3503\n",
      "val Loss: 1.6874 Acc: 0.3529\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.7030 Acc: 0.3542\n",
      "val Loss: 1.6313 Acc: 0.3763\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6092 Acc: 0.3834\n",
      "val Loss: 1.5831 Acc: 0.3845\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.5960 Acc: 0.3907\n",
      "val Loss: 1.5734 Acc: 0.3926\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.5956 Acc: 0.3888\n",
      "val Loss: 1.5693 Acc: 0.3974\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.5933 Acc: 0.3896\n",
      "val Loss: 1.5615 Acc: 0.3947\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.5888 Acc: 0.3934\n",
      "val Loss: 1.5623 Acc: 0.4001\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.5864 Acc: 0.3942\n",
      "val Loss: 1.5549 Acc: 0.4003\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.5860 Acc: 0.3946\n",
      "val Loss: 1.5568 Acc: 0.3962\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.5769 Acc: 0.3976\n",
      "val Loss: 1.5514 Acc: 0.4018\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.5770 Acc: 0.3946\n",
      "val Loss: 1.5508 Acc: 0.4024\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.5723 Acc: 0.3992\n",
      "val Loss: 1.5507 Acc: 0.4006\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.5732 Acc: 0.4000\n",
      "val Loss: 1.5516 Acc: 0.4010\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.5772 Acc: 0.3994\n",
      "val Loss: 1.5503 Acc: 0.4015\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.5723 Acc: 0.4019\n",
      "val Loss: 1.5519 Acc: 0.4012\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.5774 Acc: 0.3990\n",
      "val Loss: 1.5517 Acc: 0.4012\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5787 Acc: 0.4003\n",
      "val Loss: 1.5505 Acc: 0.4018\n",
      "\n",
      "Training complete in 62m 4s\n",
      "Best val Acc: 0.402388\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_ozon,dataset_sizes_ozon,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen model training on IMFDB-FER2013-OZON composite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_age_trained.pth',map_location=device))\n",
    "model_ft.to(device)\n",
    "\n",
    "#freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7715 Acc: 0.2941\n",
      "val Loss: 1.7154 Acc: 0.3175\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.7338 Acc: 0.3111\n",
      "val Loss: 1.7017 Acc: 0.3221\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.7241 Acc: 0.3181\n",
      "val Loss: 1.6963 Acc: 0.3167\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.7156 Acc: 0.3205\n",
      "val Loss: 1.6756 Acc: 0.3379\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.7138 Acc: 0.3213\n",
      "val Loss: 1.6936 Acc: 0.3248\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.7142 Acc: 0.3207\n",
      "val Loss: 1.6814 Acc: 0.3303\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.7086 Acc: 0.3251\n",
      "val Loss: 1.6858 Acc: 0.3295\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.6828 Acc: 0.3358\n",
      "val Loss: 1.6552 Acc: 0.3472\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.6767 Acc: 0.3400\n",
      "val Loss: 1.6569 Acc: 0.3435\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.6773 Acc: 0.3386\n",
      "val Loss: 1.6570 Acc: 0.3451\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.6766 Acc: 0.3395\n",
      "val Loss: 1.6524 Acc: 0.3498\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.6761 Acc: 0.3393\n",
      "val Loss: 1.6520 Acc: 0.3494\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.6773 Acc: 0.3398\n",
      "val Loss: 1.6569 Acc: 0.3476\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.6743 Acc: 0.3397\n",
      "val Loss: 1.6526 Acc: 0.3506\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.6728 Acc: 0.3401\n",
      "val Loss: 1.6517 Acc: 0.3488\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.6733 Acc: 0.3403\n",
      "val Loss: 1.6513 Acc: 0.3499\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.6734 Acc: 0.3410\n",
      "val Loss: 1.6512 Acc: 0.3486\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.6708 Acc: 0.3407\n",
      "val Loss: 1.6500 Acc: 0.3501\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.6716 Acc: 0.3416\n",
      "val Loss: 1.6504 Acc: 0.3505\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.6711 Acc: 0.3416\n",
      "val Loss: 1.6499 Acc: 0.3508\n",
      "\n",
      "Training complete in 79m 45s\n",
      "Best val Acc: 0.350768\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_IMFDB_FER2013_OZON,dataset_sizes_IMFDB_FER2013_OZON,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen model training on IMFDB-OZON composite dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.fc2.weight\n",
      "encoder.fc2.bias\n",
      "encoder.fc3.weight\n",
      "encoder.fc3.bias\n",
      "age_group_head.weight\n",
      "age_group_head.bias\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.7524 Acc: 0.3142\n",
      "val Loss: 1.6680 Acc: 0.3472\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.7003 Acc: 0.3406\n",
      "val Loss: 1.6474 Acc: 0.3630\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6860 Acc: 0.3468\n",
      "val Loss: 1.6412 Acc: 0.3610\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.6792 Acc: 0.3496\n",
      "val Loss: 1.6641 Acc: 0.3465\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.6744 Acc: 0.3524\n",
      "val Loss: 1.6354 Acc: 0.3643\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6670 Acc: 0.3548\n",
      "val Loss: 1.6111 Acc: 0.3714\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.6668 Acc: 0.3549\n",
      "val Loss: 1.6102 Acc: 0.3750\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.6316 Acc: 0.3723\n",
      "val Loss: 1.5940 Acc: 0.3809\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.6287 Acc: 0.3727\n",
      "val Loss: 1.5912 Acc: 0.3855\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.6281 Acc: 0.3724\n",
      "val Loss: 1.5969 Acc: 0.3811\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.6251 Acc: 0.3762\n",
      "val Loss: 1.5868 Acc: 0.3883\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.6227 Acc: 0.3758\n",
      "val Loss: 1.5896 Acc: 0.3885\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.6255 Acc: 0.3742\n",
      "val Loss: 1.5884 Acc: 0.3880\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.6223 Acc: 0.3761\n",
      "val Loss: 1.5861 Acc: 0.3897\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.6205 Acc: 0.3758\n",
      "val Loss: 1.5860 Acc: 0.3899\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.6214 Acc: 0.3755\n",
      "val Loss: 1.5864 Acc: 0.3897\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.6181 Acc: 0.3791\n",
      "val Loss: 1.5862 Acc: 0.3893\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.6205 Acc: 0.3757\n",
      "val Loss: 1.5855 Acc: 0.3899\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.6197 Acc: 0.3767\n",
      "val Loss: 1.5849 Acc: 0.3906\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.6189 Acc: 0.3805\n",
      "val Loss: 1.5864 Acc: 0.3895\n",
      "\n",
      "Training complete in 70m 44s\n",
      "Best val Acc: 0.390621\n"
     ]
    }
   ],
   "source": [
    "model_ft = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "model_ft.classifier = nn.Sequential(*list(model_ft.classifier.children())[:-3])\n",
    "model_ft = MultiTaskModel(model_ft)\n",
    "\n",
    "model_ft.fc2 = nn.Linear(in_features=1432, out_features=1400, bias=True)\n",
    "model_ft = MultiTaskModel_grouped_age_head(model_ft)\n",
    "model_ft.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless-cpu_gender_age_trained.pth',map_location=device))\n",
    "model_ft.to(device)\n",
    "\n",
    "#freezing all the parameters and batchnorms except parameters of age and emotion heads\n",
    "for module in model_ft.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in model_ft.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in model_ft.encoder.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "for k in model_ft.encoder.fc3.parameters():\n",
    "    k.requires_grad = True\n",
    "for k in model_ft.age_group_head.parameters():\n",
    "    k.requires_grad = True\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.6227 Acc: 0.3765\n",
      "val Loss: 1.5852 Acc: 0.3893\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.6218 Acc: 0.3781\n",
      "val Loss: 1.5853 Acc: 0.3890\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.6203 Acc: 0.3772\n",
      "val Loss: 1.5854 Acc: 0.3891\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.6191 Acc: 0.3788\n",
      "val Loss: 1.5853 Acc: 0.3898\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.6207 Acc: 0.3759\n",
      "val Loss: 1.5854 Acc: 0.3895\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.6196 Acc: 0.3773\n",
      "val Loss: 1.5854 Acc: 0.3893\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.6198 Acc: 0.3753\n",
      "val Loss: 1.5853 Acc: 0.3902\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.6180 Acc: 0.3785\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.6182 Acc: 0.3794\n",
      "val Loss: 1.5853 Acc: 0.3895\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.6164 Acc: 0.3791\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 1.6202 Acc: 0.3776\n",
      "val Loss: 1.5853 Acc: 0.3895\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 1.6201 Acc: 0.3761\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.6201 Acc: 0.3760\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.6188 Acc: 0.3770\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.6199 Acc: 0.3759\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.6166 Acc: 0.3789\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 1.6193 Acc: 0.3753\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.6182 Acc: 0.3772\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.6199 Acc: 0.3788\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.6182 Acc: 0.3795\n",
      "val Loss: 1.5853 Acc: 0.3894\n",
      "\n",
      "Training complete in 52m 54s\n",
      "Best val Acc: 0.390203\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion,optimizer_ft, exp_lr_scheduler,dataloaders_IMFDB_OZON,dataset_sizes_IMFDB_OZON,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
