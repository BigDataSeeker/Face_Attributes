{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook aims to test approach of simple expression classification training of frozen backbone model: see the results of training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import math\n",
    "import collections\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "from torch.utils import model_zoo\n",
    "from torch.nn import Sequential, BatchNorm1d, BatchNorm2d, Dropout, Module, Linear\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(112),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(120),\n",
    "        transforms.CenterCrop(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.MyDataset_expression_OZON import MyDataset_expression_OZON\n",
    "    \n",
    "annotations_path_ozon = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train_7expressions_annotation.txt'\n",
    "image_datasets_ozon = {x: MyDataset_expression_OZON(annotations_path_ozon,x,{'neutral':0, 'happy':1, 'sad':2, 'surprise':3, 'anger':4, 'disgust':5,'fear':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.MyDataset_expression_AffectPartly import MyDataset_expression_AffectPartly\n",
    "    \n",
    "annotations_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/annotation_'\n",
    "image_datasets_AffectPartly = {x: MyDataset_expression_AffectPartly(annotations_path,x,{'neutral':0, 'happiness':1, 'sadness':2, 'surprise':3, 'anger':4, 'disgust':5,'fear':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create training set by concatenating 2 datasets: OZON and AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets_AffectPartly_OZON = {'train': torch.utils.data.ConcatDataset([image_datasets_AffectPartly['train'],image_datasets_ozon['train']]),\n",
    "                                    'val_AffectPartly': image_datasets_AffectPartly['val'],'val_ozon':image_datasets_ozon['val']}\n",
    "dataloaders_AffectPartly_OZON = {x: torch.utils.data.DataLoader(image_datasets_AffectPartly_OZON[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val_AffectPartly','val_ozon']}\n",
    "\n",
    "dataset_sizes_AffectPartly_OZON = {x: image_datasets_AffectPartly_OZON[x].__len__() for x in ['train', 'val_AffectPartly','val_ozon']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler,dataloaders,dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val_AffectPartly','val_ozon']:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val_ozon' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mit-han-lab_ProxylessNAS_master\n"
     ]
    }
   ],
   "source": [
    "class only_expressions_head(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a MTL model with the encoder from \"model_backbone\" \n",
    "    \"\"\"\n",
    "    def __init__(self, model_backbone):\n",
    "        super(only_expressions_head,self).__init__()\n",
    "        self.encoder = model_backbone       #fastai function that creates an encoder given an architecture\n",
    "        self.expression_head = nn.Linear(in_features=1000, out_features=7, bias=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        emotions = self.expression_head(x)\n",
    "\n",
    "        return emotions\n",
    "\n",
    "\n",
    "proxyless_frozen_trained_only_expressions = torch.hub.load('mit-han-lab/ProxylessNAS', \"proxyless_cpu\" , pretrained=True)\n",
    "proxyless_frozen_trained_only_expressions = only_expressions_head(proxyless_frozen_trained_only_expressions)\n",
    "proxyless_frozen_trained_only_expressions = proxyless_frozen_trained_only_expressions.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression_head.weight\n",
      "expression_head.bias\n"
     ]
    }
   ],
   "source": [
    "# Freezing backbone params\n",
    "for module in proxyless_frozen_trained_only_expressions.encoder.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in proxyless_frozen_trained_only_expressions.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in proxyless_frozen_trained_only_expressions.expression_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name,param in proxyless_frozen_trained_only_expressions.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_proxyless_frozen_trained_only_expressions = optim.SGD(proxyless_frozen_trained_only_expressions.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_proxyless_frozen_trained_only_expressions, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.8948 Acc: 0.2890\n",
      "val_AffectPartly Loss: 1.8747 Acc: 0.2931\n",
      "val_ozon Loss: 1.7962 Acc: 0.3266\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.8608 Acc: 0.3010\n",
      "val_AffectPartly Loss: 1.8122 Acc: 0.3117\n",
      "val_ozon Loss: 1.7819 Acc: 0.3226\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.8621 Acc: 0.3020\n",
      "val_AffectPartly Loss: 1.8551 Acc: 0.2951\n",
      "val_ozon Loss: 1.7698 Acc: 0.3310\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.8521 Acc: 0.3053\n",
      "val_AffectPartly Loss: 1.9643 Acc: 0.2926\n",
      "val_ozon Loss: 1.8022 Acc: 0.3334\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.8429 Acc: 0.3090\n",
      "val_AffectPartly Loss: 1.8195 Acc: 0.3066\n",
      "val_ozon Loss: 1.7563 Acc: 0.3332\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.8546 Acc: 0.3037\n",
      "val_AffectPartly Loss: 1.9456 Acc: 0.3020\n",
      "val_ozon Loss: 1.8617 Acc: 0.3377\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.8399 Acc: 0.3089\n",
      "val_AffectPartly Loss: 1.8148 Acc: 0.3229\n",
      "val_ozon Loss: 1.7441 Acc: 0.3410\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.6900 Acc: 0.3508\n",
      "val_AffectPartly Loss: 1.6982 Acc: 0.3406\n",
      "val_ozon Loss: 1.6275 Acc: 0.3828\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.6709 Acc: 0.3551\n",
      "val_AffectPartly Loss: 1.7149 Acc: 0.3431\n",
      "val_ozon Loss: 1.6242 Acc: 0.3842\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.6694 Acc: 0.3568\n",
      "val_AffectPartly Loss: 1.6890 Acc: 0.3423\n",
      "val_ozon Loss: 1.6242 Acc: 0.3800\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.6720 Acc: 0.3549\n",
      "val_AffectPartly Loss: 1.7089 Acc: 0.3406\n",
      "val_ozon Loss: 1.6188 Acc: 0.3830\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.6695 Acc: 0.3549\n",
      "val_AffectPartly Loss: 1.7020 Acc: 0.3440\n",
      "val_ozon Loss: 1.6127 Acc: 0.3886\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.6679 Acc: 0.3565\n",
      "val_AffectPartly Loss: 1.7341 Acc: 0.3326\n",
      "val_ozon Loss: 1.6253 Acc: 0.3802\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.6659 Acc: 0.3558\n",
      "val_AffectPartly Loss: 1.6758 Acc: 0.3466\n",
      "val_ozon Loss: 1.6227 Acc: 0.3831\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.6566 Acc: 0.3612\n",
      "val_AffectPartly Loss: 1.6849 Acc: 0.3466\n",
      "val_ozon Loss: 1.6103 Acc: 0.3869\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.6554 Acc: 0.3613\n",
      "val_AffectPartly Loss: 1.6782 Acc: 0.3486\n",
      "val_ozon Loss: 1.6127 Acc: 0.3868\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.6533 Acc: 0.3629\n",
      "val_AffectPartly Loss: 1.6782 Acc: 0.3474\n",
      "val_ozon Loss: 1.6107 Acc: 0.3881\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.6533 Acc: 0.3629\n",
      "val_AffectPartly Loss: 1.6840 Acc: 0.3480\n",
      "val_ozon Loss: 1.6090 Acc: 0.3874\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.6514 Acc: 0.3641\n",
      "val_AffectPartly Loss: 1.6832 Acc: 0.3469\n",
      "val_ozon Loss: 1.6080 Acc: 0.3898\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.6509 Acc: 0.3641\n",
      "val_AffectPartly Loss: 1.6858 Acc: 0.3431\n",
      "val_ozon Loss: 1.6081 Acc: 0.3896\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.6544 Acc: 0.3620\n",
      "val_AffectPartly Loss: 1.6802 Acc: 0.3469\n",
      "val_ozon Loss: 1.6082 Acc: 0.3889\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.6530 Acc: 0.3628\n",
      "val_AffectPartly Loss: 1.6810 Acc: 0.3477\n",
      "val_ozon Loss: 1.6074 Acc: 0.3885\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.6492 Acc: 0.3645\n",
      "val_AffectPartly Loss: 1.6806 Acc: 0.3480\n",
      "val_ozon Loss: 1.6078 Acc: 0.3883\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.6506 Acc: 0.3651\n",
      "val_AffectPartly Loss: 1.6809 Acc: 0.3491\n",
      "val_ozon Loss: 1.6075 Acc: 0.3876\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.6522 Acc: 0.3657\n",
      "val_AffectPartly Loss: 1.6805 Acc: 0.3480\n",
      "val_ozon Loss: 1.6075 Acc: 0.3876\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.6503 Acc: 0.3645\n",
      "val_AffectPartly Loss: 1.6801 Acc: 0.3483\n",
      "val_ozon Loss: 1.6079 Acc: 0.3881\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.6522 Acc: 0.3634\n",
      "val_AffectPartly Loss: 1.6800 Acc: 0.3480\n",
      "val_ozon Loss: 1.6079 Acc: 0.3874\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.6498 Acc: 0.3655\n",
      "val_AffectPartly Loss: 1.6805 Acc: 0.3477\n",
      "val_ozon Loss: 1.6080 Acc: 0.3876\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.6511 Acc: 0.3645\n",
      "val_AffectPartly Loss: 1.6805 Acc: 0.3477\n",
      "val_ozon Loss: 1.6079 Acc: 0.3878\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.6515 Acc: 0.3648\n",
      "val_AffectPartly Loss: 1.6805 Acc: 0.3477\n",
      "val_ozon Loss: 1.6078 Acc: 0.3876\n",
      "\n",
      "Training complete in 163m 47s\n",
      "Best val Acc: 0.389837\n"
     ]
    }
   ],
   "source": [
    "\n",
    "proxyless_frozen_trained_only_expressions = train_model(proxyless_frozen_trained_only_expressions, criterion,optimizer_proxyless_frozen_trained_only_expressions, exp_lr_scheduler,dataloaders_AffectPartly_OZON,dataset_sizes_AffectPartly_OZON,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(proxyless_frozen_trained_only_expressions.state_dict(), '/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/proxyless_frozen_backbone_trained_only_expressions.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
