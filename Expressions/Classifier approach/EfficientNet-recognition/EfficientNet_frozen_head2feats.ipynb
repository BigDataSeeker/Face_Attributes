{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook aims to find out how accureate EfficientNet-b0 with frozen Face recognition weights can converge when trained on OZON-AffectNet composite dataset. Expressnion heah is mounted on extracted features (not logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import math\n",
    "import collections\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import copy\n",
    "from torch.utils import model_zoo\n",
    "from torch.nn import Sequential, BatchNorm1d, BatchNorm2d, Dropout, Module, Linear\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = argparse.ArgumentParser(description='traditional_training for face recognition.')\n",
    "\n",
    "conf.add_argument(\"--backbone_type\", type = str,default = 'EfficientNet',\n",
    "                      help = \"Mobilefacenets, Resnet.\")\n",
    "conf.add_argument(\"--backbone_conf_file\", type = str ,default ='/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/training_mode/backbone_conf.yaml', \n",
    "                      help = \"the path of backbone_conf.yaml.\")\n",
    "conf.add_argument(\"--head_type\", type = str ,default = 'AdaM-Softmax', \n",
    "                      help = \"mv-softmax, arcface, npc-face.\")\n",
    "conf.add_argument(\"--head_conf_file\", type = str ,default = '/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/training_mode/head_conf.yaml', \n",
    "                      help = \"the path of head_conf.yaml.\")\n",
    "    \n",
    "args = conf.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, model_name, weights_path=None, load_fc=True, advprop=False):\n",
    "    \"\"\"Loads pretrained weights from weights path or download using url.\n",
    "    Args:\n",
    "        model (Module): The whole model of efficientnet.\n",
    "        model_name (str): Model name of efficientnet.\n",
    "        weights_path (None or str):\n",
    "            str: path to pretrained weights file on the local disk.\n",
    "            None: use pretrained weights downloaded from the Internet.\n",
    "        load_fc (bool): Whether to load pretrained weights for fc layer at the end of the model.\n",
    "        advprop (bool): Whether to load pretrained weights\n",
    "                        trained with advprop (valid when weights_path is None).\n",
    "    \"\"\"\n",
    "    if isinstance(weights_path, str):\n",
    "        state_dict = torch.load(weights_path)['state_dict']\n",
    "        for key_name in list(state_dict.keys()):\n",
    "            new_key = key_name.replace('backbone.','')\n",
    "            state_dict[new_key] = state_dict.pop(key_name)\n",
    "    else:\n",
    "        # AutoAugment or Advprop (different preprocessing)\n",
    "        url_map_ = url_map_advprop if advprop else url_map\n",
    "        state_dict = model_zoo.load_url(url_map_[model_name])\n",
    "\n",
    "    if load_fc:\n",
    "        state_dict.pop('head.weight')\n",
    "        ret = model.load_state_dict(state_dict, strict=False)\n",
    "        assert not ret.missing_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)\n",
    "    else:\n",
    "        state_dict.pop('backbone._fc.weight')\n",
    "        state_dict.pop('backbone._fc.bias')\n",
    "        ret = model.load_state_dict(state_dict, strict=False)\n",
    "        assert set(ret.missing_keys) == set(\n",
    "            ['_fc.weight', '_fc.bias']), 'Missing keys when loading pretrained weights: {}'.format(ret.missing_keys)\n",
    "    assert not ret.unexpected_keys, 'Missing keys when loading pretrained weights: {}'.format(ret.unexpected_keys)\n",
    "\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/backbone/backbone_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  backbone_conf = yaml.load(f)\n",
      "/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo/head/head_def.py:32: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  head_conf = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone param:\n",
      "{'width': 1.0, 'depth': 1.0, 'image_size': 112, 'drop_ratio': 0.2, 'out_h': 7, 'out_w': 7, 'feat_dim': 512}\n",
      "head param:\n",
      "{'feat_dim': 512, 'num_class': 72778, 'scale': 32, 'lamda': 70.0}\n",
      "Loaded pretrained weights for EfficientNet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FaceModel(\n",
       "  (backbone): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "    (output_layer): Sequential(\n",
       "      (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Flatten()\n",
       "      (3): Linear(in_features=62720, out_features=512, bias=True)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Adam_Softmax()\n",
       "  (expression_head): Sequential(\n",
       "    (0): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=62720, out_features=1000, bias=True)\n",
       "    (3): Linear(in_features=1000, out_features=30, bias=True)\n",
       "    (4): Linear(in_features=30, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/FaceX-Zoo')\n",
    "from backbone.backbone_def import BackboneFactory\n",
    "from head.head_def import HeadFactory\n",
    "class FaceModel(torch.nn.Module):\n",
    "    \"\"\"Define a traditional face model which contains a backbone and a head.\n",
    "    \n",
    "    Attributes:\n",
    "        backbone(object): the backbone of face model.\n",
    "        head(object): the head of face model.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone_factory, head_factory):\n",
    "        \"\"\"Init face model by backbone factorcy and head factory.\n",
    "        \n",
    "        Args:\n",
    "            backbone_factory(object): produce a backbone according to config files.\n",
    "            head_factory(object): produce a head according to config files.\n",
    "        \"\"\"\n",
    "        super(FaceModel, self).__init__()\n",
    "        self.backbone = backbone_factory.get_backbone()\n",
    "        self.head = head_factory.get_head()\n",
    "        self.expression_head = Sequential(nn.BatchNorm2d(1280),nn.Flatten(),nn.Linear(in_features=62720, out_features=1000, bias=True),nn.Linear(in_features=1000, out_features=30, bias=True),nn.Linear(in_features=30, out_features=7, bias=True))\n",
    "\n",
    "    def forward(self, data):\n",
    "        logits = self.backbone.forward(data)\n",
    "        expression = self.expression_head(self.backbone.extract_features(data))\n",
    "        return logits,expression\n",
    "    \n",
    "backbone_factory = BackboneFactory(args.backbone_type, args.backbone_conf_file)   \n",
    "head_factory = HeadFactory(args.head_type, args.head_conf_file)\n",
    "efficientnet_b0_pretrained_frozen_expressionhead2feats = FaceModel(backbone_factory, head_factory)\n",
    "load_pretrained_weights(efficientnet_b0_pretrained_frozen_expressionhead2feats.backbone,args.backbone_type,weights_path ='/storage_labs/3030/BelyakovM/Face_attributes/Code/EfficientNet_B0_face_recognizer/efficientnet_facerecognition_weights.pt',load_fc=True )\n",
    "efficientnet_b0_pretrained_frozen_expressionhead2feats.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expression_head.0.weight\n",
      "expression_head.0.bias\n",
      "expression_head.2.weight\n",
      "expression_head.2.bias\n",
      "expression_head.3.weight\n",
      "expression_head.3.bias\n",
      "expression_head.4.weight\n",
      "expression_head.4.bias\n"
     ]
    }
   ],
   "source": [
    "# Backbone freezing\n",
    "for module in efficientnet_b0_pretrained_frozen_expressionhead2feats.backbone.modules():\n",
    "    if isinstance(module,nn.modules.BatchNorm1d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm2d):\n",
    "        module.eval()\n",
    "    if isinstance(module,nn.modules.BatchNorm3d):\n",
    "        module.eval()\n",
    "for i in efficientnet_b0_pretrained_frozen_expressionhead2feats.parameters():\n",
    "    i.requires_grad = False\n",
    "for param in efficientnet_b0_pretrained_frozen_expressionhead2feats.expression_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name,param in efficientnet_b0_pretrained_frozen_expressionhead2feats.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(112),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(120),\n",
    "        transforms.CenterCrop(112),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets.MyDataset_expression_AffectPartly import MyDataset_expression_AffectPartly\n",
    "\n",
    "annotations_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/annotation_'\n",
    "image_datasets_AffectPartly = {x: MyDataset_expression_AffectPartly(annotations_path,x,{'neutral':0, 'happiness':1, 'sadness':2, 'surprise':3, 'anger':4, 'disgust':5,'fear':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dataloaders_ozon = {x: torch.utils.data.DataLoader(image_datasets_ozon[x], batch_size=28,\\n                                             shuffle=True, num_workers=4)\\n              for x in ['train', 'val']}\\ndataset_sizes_ozon = {x: image_datasets_ozon[x].__len__() for x in ['train', 'val']}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Datasets.MyDataset_expression_OZON import MyDataset_expression_OZON\n",
    "    \n",
    "annotations_path_ozon = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train_7expressions_annotation.txt'\n",
    "image_datasets_ozon = {x: MyDataset_expression_OZON(annotations_path_ozon,x,{'neutral':0, 'happy':1, 'sad':2, 'surprise':3, 'anger':4, 'disgust':5,'fear':6},\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AffectNet-OZON composite dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets_AffectPartly_OZON = {'train': torch.utils.data.ConcatDataset([image_datasets_AffectPartly['train'],image_datasets_ozon['train']]),\n",
    "                                    'val_AffectPartly': image_datasets_AffectPartly['val'],'val_ozon':image_datasets_ozon['val']}\n",
    "dataloaders_AffectPartly_OZON = {x: torch.utils.data.DataLoader(image_datasets_AffectPartly_OZON[x], batch_size=63,\n",
    "                                             shuffle=True, num_workers=4) for x in ['train', 'val_AffectPartly','val_ozon']}\n",
    "\n",
    "dataset_sizes_AffectPartly_OZON = {x: image_datasets_AffectPartly_OZON[x].__len__() for x in ['train', 'val_AffectPartly','val_ozon']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler,dataloaders,dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val_AffectPartly','val_ozon']:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)[1]\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val_ozon' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_efficientnet_b0_pretrained_frozen_expressionhead2feats = optim.SGD(efficientnet_b0_pretrained_frozen_expressionhead2feats.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_efficientnet_b0_pretrained_frozen_expressionhead2feats, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.9359 Acc: 0.1699\n",
      "val_AffectPartly Loss: 1.9667 Acc: 0.1514\n",
      "val_ozon Loss: 1.9123 Acc: 0.1744\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.9269 Acc: 0.1789\n",
      "val_AffectPartly Loss: 1.9521 Acc: 0.1849\n",
      "val_ozon Loss: 1.9172 Acc: 0.1932\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.9228 Acc: 0.1859\n",
      "val_AffectPartly Loss: 1.9284 Acc: 0.1997\n",
      "val_ozon Loss: 1.9085 Acc: 0.2013\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.9191 Acc: 0.1912\n",
      "val_AffectPartly Loss: 1.9223 Acc: 0.1806\n",
      "val_ozon Loss: 1.9019 Acc: 0.2000\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 1.9152 Acc: 0.1927\n",
      "val_AffectPartly Loss: 1.9196 Acc: 0.2203\n",
      "val_ozon Loss: 1.8857 Acc: 0.2388\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 1.9122 Acc: 0.1993\n",
      "val_AffectPartly Loss: 1.9137 Acc: 0.2111\n",
      "val_ozon Loss: 1.8829 Acc: 0.2279\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 1.9112 Acc: 0.1988\n",
      "val_AffectPartly Loss: 1.9061 Acc: 0.2097\n",
      "val_ozon Loss: 1.8813 Acc: 0.2342\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 1.9014 Acc: 0.2121\n",
      "val_AffectPartly Loss: 1.9057 Acc: 0.2306\n",
      "val_ozon Loss: 1.8779 Acc: 0.2421\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 1.9014 Acc: 0.2138\n",
      "val_AffectPartly Loss: 1.9006 Acc: 0.2280\n",
      "val_ozon Loss: 1.8737 Acc: 0.2468\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 1.8999 Acc: 0.2141\n",
      "val_AffectPartly Loss: 1.9033 Acc: 0.2303\n",
      "val_ozon Loss: 1.8727 Acc: 0.2418\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 1.8990 Acc: 0.2162\n",
      "val_AffectPartly Loss: 1.8978 Acc: 0.2297\n",
      "val_ozon Loss: 1.8716 Acc: 0.2449\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 1.8988 Acc: 0.2158\n",
      "val_AffectPartly Loss: 1.9025 Acc: 0.2300\n",
      "val_ozon Loss: 1.8700 Acc: 0.2493\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 1.8973 Acc: 0.2158\n",
      "val_AffectPartly Loss: 1.8973 Acc: 0.2271\n",
      "val_ozon Loss: 1.8673 Acc: 0.2436\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 1.8976 Acc: 0.2163\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2354\n",
      "val_ozon Loss: 1.8664 Acc: 0.2509\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 1.8966 Acc: 0.2197\n",
      "val_AffectPartly Loss: 1.8964 Acc: 0.2369\n",
      "val_ozon Loss: 1.8659 Acc: 0.2496\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 1.8957 Acc: 0.2184\n",
      "val_AffectPartly Loss: 1.8955 Acc: 0.2349\n",
      "val_ozon Loss: 1.8655 Acc: 0.2503\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 1.8963 Acc: 0.2176\n",
      "val_AffectPartly Loss: 1.8946 Acc: 0.2351\n",
      "val_ozon Loss: 1.8660 Acc: 0.2520\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 1.8951 Acc: 0.2194\n",
      "val_AffectPartly Loss: 1.8946 Acc: 0.2329\n",
      "val_ozon Loss: 1.8655 Acc: 0.2505\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 1.8953 Acc: 0.2203\n",
      "val_AffectPartly Loss: 1.8949 Acc: 0.2326\n",
      "val_ozon Loss: 1.8649 Acc: 0.2534\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 1.8964 Acc: 0.2167\n",
      "val_AffectPartly Loss: 1.8944 Acc: 0.2340\n",
      "val_ozon Loss: 1.8655 Acc: 0.2512\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 1.8957 Acc: 0.2196\n",
      "val_AffectPartly Loss: 1.8952 Acc: 0.2363\n",
      "val_ozon Loss: 1.8649 Acc: 0.2547\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 1.8958 Acc: 0.2197\n",
      "val_AffectPartly Loss: 1.8947 Acc: 0.2383\n",
      "val_ozon Loss: 1.8649 Acc: 0.2530\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 1.8952 Acc: 0.2194\n",
      "val_AffectPartly Loss: 1.8945 Acc: 0.2351\n",
      "val_ozon Loss: 1.8649 Acc: 0.2509\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 1.8958 Acc: 0.2176\n",
      "val_AffectPartly Loss: 1.8944 Acc: 0.2331\n",
      "val_ozon Loss: 1.8649 Acc: 0.2516\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 1.8953 Acc: 0.2187\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2331\n",
      "val_ozon Loss: 1.8649 Acc: 0.2504\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 1.8947 Acc: 0.2179\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2331\n",
      "val_ozon Loss: 1.8649 Acc: 0.2515\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 1.8947 Acc: 0.2199\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2340\n",
      "val_ozon Loss: 1.8649 Acc: 0.2505\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 1.8949 Acc: 0.2180\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2340\n",
      "val_ozon Loss: 1.8649 Acc: 0.2509\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 1.8944 Acc: 0.2220\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2340\n",
      "val_ozon Loss: 1.8649 Acc: 0.2513\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 1.8955 Acc: 0.2173\n",
      "val_AffectPartly Loss: 1.8943 Acc: 0.2340\n",
      "val_ozon Loss: 1.8649 Acc: 0.2512\n",
      "\n",
      "Training complete in 167m 24s\n",
      "Best val Acc: 0.254692\n"
     ]
    }
   ],
   "source": [
    "efficientnet_b0_pretrained_frozen_expressionhead2feats = train_model(efficientnet_b0_pretrained_frozen_expressionhead2feats, criterion,optimizer_efficientnet_b0_pretrained_frozen_expressionhead2feats, exp_lr_scheduler,dataloaders_AffectPartly_OZON,dataset_sizes_AffectPartly_OZON,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_b0_pretrained_frozen_expressionhead2feats.state_dict(), '/storage_labs/3030/BelyakovM/Face_attributes/Saved_models/efficientnet_b0_pretrained_frozen_backbone_expressionhead2feats.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
