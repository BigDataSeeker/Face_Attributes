{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import PIL\n",
    "import pandas\n",
    "from os.path import join\n",
    "import copy\n",
    "import timm \n",
    "from collections import OrderedDict\n",
    "from numpy.linalg import norm as l2norm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/storage_labs/3030/BelyakovM/Face_attributes/insightface/recognition/arcface_torch')\n",
    "from backbones import get_model\n",
    "net = get_model('r18', fp16=False)\n",
    "net.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/insightface/recognition/arcface_torch/work_dirs/AffectnetOzon_r18_attempt4/backbone_38.pth'))\n",
    "@torch.no_grad()\n",
    "def inference(net, img):\n",
    "    if img is None:\n",
    "        img = np.random.randint(0, 255, size=(112, 112, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.resize(img, (112, 112))\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    " \n",
    "    net.eval()\n",
    "    feat = net(img).numpy()\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18096636\n"
     ]
    }
   ],
   "source": [
    "feat1 = inference(net,'/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/val/anger/image0000696.jpg') \n",
    "feat2 = inference(net,'/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/val/happiness/image0000295.jpg')\n",
    "feat1 = np.mean(feat1, axis=0)\n",
    "feat1 /= l2norm(feat1)\n",
    "feat2 = np.mean(feat2, axis=0)\n",
    "feat2 /= l2norm(feat2)\n",
    "print(np.dot(feat1,feat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = ['anger','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/test_kaggle/93.jpg',\n",
    "        'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/test_kaggle/109.jpg',\n",
    "         'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/test_kaggle/121.jpg']\n",
    "disgust = ['disgust','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/disgust/31.jpg',\n",
    "           'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/disgust/45.jpg',\n",
    "           'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/disgust/57.jpg']\n",
    "fear = ['fear','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/fear/22.jpg',\n",
    "        'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/fear/64.jpg',\n",
    "        'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/fear/74.jpg']\n",
    "happiness = ['happiness','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/happy/3326.jpg',\n",
    "             'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/happy/3335.jpg',\n",
    "             'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/happy/3418.jpg']\n",
    "neutral = ['neutral','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/neutral/168.jpg',\n",
    "          'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/neutral/169.jpg',\n",
    "          'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/neutral/193.jpg']\n",
    "sadness = ['sadness','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/sad/3808.jpg',\n",
    "          'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/sad/3840.jpg',\n",
    "          'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/sad/3961.jpg']\n",
    "surprise = ['surprise','Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/surprise/3195.jpg',\n",
    "           'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/surprise/3205.jpg',\n",
    "            'Face_attributes/ds/db_BuevichP/emochon/OZON_expressions_dataset/train/surprise/3242.jpg']\n",
    "reference = [anger,disgust,fear,happiness,neutral,sadness,surprise]\n",
    "reference.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger\n",
      "disgust\n",
      "fear\n",
      "happiness\n",
      "neutral\n",
      "sadness\n",
      "surprise\n"
     ]
    }
   ],
   "source": [
    "for expression_inx in range(len(reference)):\n",
    "    print(reference[expression_inx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.092), ('sadness', 0.706), ('fear', 0.828), ('happiness', 0.838), ('surprise', 0.67), ('disgust', 0.346), ('neutral', 0.588)]\n",
      "[('anger', 0.006), ('sadness', 0.676), ('fear', 0.854), ('happiness', 0.8), ('surprise', 0.7), ('disgust', 0.768), ('neutral', 0.618)]\n",
      "[('anger', 0.428), ('sadness', 0.646), ('fear', 0.858), ('happiness', 0.804), ('surprise', 0.692), ('disgust', 0.394), ('neutral', 0.58)]\n"
     ]
    }
   ],
   "source": [
    "#Computing r18 validation accuracy on AffectNet/val set with external references \n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/val'\n",
    "for i in range(1,4):\n",
    "    expression_reference_logits=[]\n",
    "    for expression_list in reference:\n",
    "        logits_reference = inference(net,'/storage_labs/3030/BelyakovM/'+expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "    folder_acc=[]\n",
    "    for folder in os.listdir(datadir):\n",
    "        folder_corrects = 0\n",
    "        imgs = os.listdir(os.path.join(datadir,folder))\n",
    "        num_folder_imgs = len(imgs)\n",
    "        for image in imgs:\n",
    "            try:\n",
    "                logits_val_img = inference(net,os.path.join(datadir,folder,image))\n",
    "                logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "                logits_val_img /= l2norm(logits_val_img)\n",
    "            except:\n",
    "                num_folder_imgs -= 1\n",
    "                continue\n",
    "            expression_reference_scores=[]\n",
    "   \n",
    "            for logits in expression_reference_logits:\n",
    "                score = np.dot(logits_val_img,logits[1])\n",
    "                expression_reference_scores.append(score)\n",
    "                \n",
    "            max_score = max(expression_reference_scores)\n",
    "            if folder == reference[expression_reference_scores.index(max_score)][0]:\n",
    "                folder_corrects += 1\n",
    "        folder_acc.append((folder,folder_corrects/num_folder_imgs))\n",
    "    print(folder_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.16666666666666666), ('sadness', 0.5), ('fear', 0.6666666666666666), ('happiness', 1.0), ('disgust', 0.08333333333333333), ('neutral', 0.25)]\n",
      "[('anger', 0.08333333333333333), ('sadness', 0.5), ('fear', 0.75), ('happiness', 1.0), ('disgust', 0.5833333333333334), ('neutral', 0.25)]\n",
      "[('anger', 0.25), ('sadness', 0.4166666666666667), ('fear', 0.6666666666666666), ('happiness', 1.0), ('disgust', 0.08333333333333333), ('neutral', 0.5833333333333334)]\n"
     ]
    }
   ],
   "source": [
    "#Computing r18 validation accuracy on FACESds with external references \n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds'\n",
    "annotation_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds/annotation.txt'\n",
    "reference_list = reference.copy()\n",
    "_ = reference_list.pop(6)\n",
    "file_to_read = open(annotation_path,'r')\n",
    "annotation_list = [line.split(';') for line in file_to_read.readlines()]\n",
    "for i in range(1,4):\n",
    "    expression_reference_logits=[]\n",
    "    \n",
    "    for expression_list in reference_list:\n",
    "        logits_reference = inference(net,'/storage_labs/3030/BelyakovM/'+expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "    folder_acc=[]\n",
    "    overall_corrects = {'anger':0,'sadness':0,'fear':0,'happiness':0,'disgust':0,'neutral':0}\n",
    "    for image in annotation_list:\n",
    "        \n",
    "        logits_val_img = inference(net,image[0])\n",
    "        logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "        logits_val_img /= l2norm(logits_val_img)\n",
    "        \n",
    "        \n",
    "        \n",
    "        expression_reference_scores=[]\n",
    "   \n",
    "        for logits in expression_reference_logits:\n",
    "            score = np.dot(logits_val_img,logits[1])\n",
    "            expression_reference_scores.append(score)\n",
    "                \n",
    "        max_score = max(expression_reference_scores)\n",
    "        label = image[1].replace('\\n','')\n",
    "        if label == reference[expression_reference_scores.index(max_score)][0]:\n",
    "            overall_corrects[label] += 1\n",
    "        else:\n",
    "            img = PIL.Image.open(image[0])\n",
    "            img = img.save('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_r18-confused-6clss/'+reference[expression_reference_scores.index(max_score)][0]+'/confused_when_refered_to_'+str(i)+'.jpg')\n",
    "        expression_acc = [(key,overall_corrects[key]/12) for key in overall_corrects.keys()]\n",
    "    print(expression_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.09090909090909091), ('sadness', 0.36363636363636365), ('fear', 0.5454545454545454), ('happiness', 1.0), ('disgust', 0.45454545454545453), ('neutral', 0.45454545454545453)]\n",
      "Confused number- 34\n"
     ]
    }
   ],
   "source": [
    "#Computing r18 validation presicion on FACESds with references from FACESds\n",
    "anger = ['anger','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/anger/066_y_m_a_a.jpg']\n",
    "\n",
    "disgust = ['disgust','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/disgust/140_y_f_d_a.jpg']\n",
    "\n",
    "fear = ['fear','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/fear/116_m_m_f_a.jpg']\n",
    "\n",
    "happiness = ['happiness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/happiness/079_o_f_h_a.jpg']\n",
    "\n",
    "neutral = ['neutral','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/neutral/116_m_m_n_a.jpg']\n",
    "\n",
    "sadness = ['sadness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/sadness/140_y_f_s_a.jpg']\n",
    "\n",
    "reference_from_ds = [anger,disgust,fear,happiness,neutral,sadness]\n",
    " \n",
    "\n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data'\n",
    "annotation_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/annotation_data.txt'\n",
    "reference_list = reference_from_ds.copy()\n",
    "\n",
    "file_to_read = open(annotation_path,'r')\n",
    "annotation_list = [line.split(';') for line in file_to_read.readlines()]\n",
    "for i in range(1,2):\n",
    "    expression_reference_logits=[]\n",
    "    \n",
    "    for expression_list in reference_list:\n",
    "        logits_reference = inference(net,expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "        \n",
    "    overall_corrects = {'anger':0,'sadness':0,'fear':0,'happiness':0,'disgust':0,'neutral':0}\n",
    "    overall_img_num = {'anger':11,'sadness':11,'fear':11,'happiness':11,'disgust':11,'neutral':11}\n",
    "    confused_num = 0\n",
    "    for image in annotation_list:\n",
    "        label = image[1].replace('\\n','')\n",
    "\n",
    "        logits_val_img = inference(net,image[0])\n",
    "        logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "        logits_val_img /= l2norm(logits_val_img)\n",
    "\n",
    "         \n",
    "        \n",
    "        expression_reference_scores=[]\n",
    "   \n",
    "        for logits in expression_reference_logits:\n",
    "            score = np.dot(logits_val_img,logits[1])\n",
    "            expression_reference_scores.append(score)\n",
    "                \n",
    "        max_score = max(expression_reference_scores)\n",
    "        \n",
    "        if label == reference_list[expression_reference_scores.index(max_score)][0]:\n",
    "            overall_corrects[label] += 1\n",
    "        else:\n",
    "            confused_num +=1\n",
    "            img = PIL.Image.open(image[0])\n",
    "            img = img.save('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/confused/'+reference[expression_reference_scores.index(max_score)][0]+'/confused'+str(confused_num)+'_when_refered_to_'+str(i)+'.jpg')\n",
    "        expression_acc = [(key,overall_corrects[key]/overall_img_num[key]) for key in overall_corrects.keys()]\n",
    "    print(expression_acc)\n",
    "    print('Confused images number-',confused_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_to_read = open(annotation_path,'r')\\nannotation_list = [line.split(';') for line in file_to_read.readlines()]\\n\\nexpression_reference_logits= {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\\n    \\nfor expression_list in reference_list:\\n    logits_reference = inference(net,expression_list[i])\\n    logits_reference = np.mean(logits_reference, axis=0)\\n    logits_reference /= l2norm(logits_reference)\\n    expression_reference_logits[expression_list[0]] = logits_reference\\n\\n\\nfor image in annotation_list:\\n\\n    label = image[1].replace('\\n','')\\n    logits_val_img = inference(net,image[0])\\n    logits_val_img = np.mean(logits_val_img, axis=0)\\n    logits_val_img /= l2norm(logits_val_img)\\n    expression_reference_scores = []\\n    for logits in expression_reference_logits.values():\\n        score = np.dot(logits_val_img,logits)\\n        expression_reference_scores.append(score)        \\n    max_score = max(expression_reference_scores)\\n    gt_score = np.dot(logits_val_img,expression_reference_logits[label])\\n    img = PIL.Image.open(image[0])\\n    save = img.save(path2save+label+'/'+label+'_gt-score:'+str(gt_score)+'_net-answer:'+reference_list[expression_reference_scores.index(max_score)][0]+'(score:'+str(max_score)+').jpg')\\n        \""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing r18 scores the image belongs to GT and saving the image with appropriate name(FACESds)\n",
    "anger = ['anger','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/anger/066_y_m_a_a.jpg']\n",
    "\n",
    "disgust = ['disgust','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/disgust/140_y_f_d_a.jpg']\n",
    "\n",
    "fear = ['fear','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/fear/116_m_m_f_a.jpg']\n",
    "\n",
    "happiness = ['happiness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/happiness/079_o_f_h_a.jpg']\n",
    "\n",
    "neutral = ['neutral','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/neutral/116_m_m_n_a.jpg']\n",
    "\n",
    "sadness = ['sadness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/references/sadness/140_y_f_s_a.jpg']\n",
    "\n",
    "reference_from_FACESds = [anger,disgust,fear,happiness,neutral,sadness]\n",
    " \n",
    "path2save = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/Scores image belongs to GT/'\n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data'\n",
    "annotation_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/annotation_data.txt'\n",
    "reference_list = reference_from_FACESds.copy()\n",
    "\n",
    "file_to_read = open(annotation_path,'r')\n",
    "annotation_list = [line.split(';') for line in file_to_read.readlines()]\n",
    "\n",
    "expression_reference_logits= {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "    \n",
    "for expression_list in reference_list:\n",
    "    logits_reference = inference(net,expression_list[i])\n",
    "    logits_reference = np.mean(logits_reference, axis=0)\n",
    "    logits_reference /= l2norm(logits_reference)\n",
    "    expression_reference_logits[expression_list[0]] = logits_reference\n",
    "\n",
    "\n",
    "for image in annotation_list:\n",
    "\n",
    "    label = image[1].replace('\\n','')\n",
    "    logits_val_img = inference(net,image[0])\n",
    "    logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "    logits_val_img /= l2norm(logits_val_img)\n",
    "    expression_reference_scores = []\n",
    "    for logits in expression_reference_logits.values():\n",
    "        score = np.dot(logits_val_img,logits)\n",
    "        expression_reference_scores.append(score)        \n",
    "    max_score = max(expression_reference_scores)\n",
    "    gt_score = np.dot(logits_val_img,expression_reference_logits[label])\n",
    "    img = PIL.Image.open(image[0])\n",
    "    save = img.save(path2save+label+'/'+label+'_gt-score:'+str(gt_score)+'_net-answer:'+reference_list[expression_reference_scores.index(max_score)][0]+'(score:'+str(max_score)+').jpg')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.19444444444444445), ('sadness', 0.3888888888888889), ('fear', 0.4722222222222222), ('happiness', 0.08333333333333333), ('disgust', 0.05555555555555555), ('neutral', 0.1388888888888889), ('surprise', 0.1111111111111111)]\n",
      "Confused images number- 200\n"
     ]
    }
   ],
   "source": [
    "#Computing r18 validation presicion on FACESds with references from facesdb\n",
    "anger = ['anger','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s032/bmp/s032-04_img.bmp']\n",
    "\n",
    "disgust = ['disgust','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s013/bmp/s013-05_img.bmp']\n",
    "\n",
    "fear = ['fear','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s032/bmp/s032-06_img.bmp']\n",
    "\n",
    "happiness = ['happiness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s019/bmp/s019-01_img.bmp']\n",
    "\n",
    "neutral = ['neutral','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s007/bmp/s007-00_img.bmp']\n",
    "\n",
    "sadness = ['sadness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s028/bmp/s028-02_img.bmp']\n",
    "\n",
    "surprise = ['surprise','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s029/bmp/s029-03_img.bmp']\n",
    "\n",
    "reference_from_facesdb = [anger,disgust,fear,happiness,neutral,sadness,surprise]\n",
    " \n",
    "\n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data'\n",
    "annotation_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/annotation.txt'\n",
    "reference_list = reference_from_facesdb.copy()\n",
    "\n",
    "file_to_read = open(annotation_path,'r')\n",
    "annotation_list = [line.split(';') for line in file_to_read.readlines()]\n",
    "for i in range(1,2):\n",
    "    expression_reference_logits=[]\n",
    "    \n",
    "    for expression_list in reference_list:\n",
    "        logits_reference = inference(net,expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "        \n",
    "    overall_corrects = {'anger':0,'sadness':0,'fear':0,'happiness':0,'disgust':0,'neutral':0,'surprise':0}\n",
    "    overall_img_num = {'anger':36,'sadness':36,'fear':36,'happiness':36,'disgust':36,'neutral':36,'surprise':36}\n",
    "    confused_num = 0\n",
    "    for image in annotation_list:\n",
    "        label = image[1]\n",
    "\n",
    "        logits_val_img = inference(net,image[0])\n",
    "        logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "        logits_val_img /= l2norm(logits_val_img)\n",
    "\n",
    "         \n",
    "        \n",
    "        expression_reference_scores=[]\n",
    "   \n",
    "        for logits in expression_reference_logits:\n",
    "            score = np.dot(logits_val_img,logits[1])\n",
    "            expression_reference_scores.append(score)\n",
    "                \n",
    "        max_score = max(expression_reference_scores)\n",
    "        \n",
    "        if label == reference_list[expression_reference_scores.index(max_score)][0]:\n",
    "            overall_corrects[label] += 1\n",
    "        else:\n",
    "            confused_num +=1\n",
    "            #img = PIL.Image.open(image[0])\n",
    "            #img = img.save('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/confused/'+reference[expression_reference_scores.index(max_score)][0]+'/confused'+str(confused_num)+'_when_refered_to_'+str(i)+'.jpg')\n",
    "        expression_acc = [(key,overall_corrects[key]/overall_img_num[key]) for key in overall_corrects.keys()]\n",
    "    print(expression_acc)\n",
    "    print('Confused images number-',confused_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing r18 scores the image belongs to GT and saving the image with appropriate name(facesdb)\n",
    "anger = ['anger','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s032/bmp/s032-04_img.bmp']\n",
    "\n",
    "disgust = ['disgust','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s013/bmp/s013-05_img.bmp']\n",
    "\n",
    "fear = ['fear','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s032/bmp/s032-06_img.bmp']\n",
    "\n",
    "happiness = ['happiness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s019/bmp/s019-01_img.bmp']\n",
    "\n",
    "neutral = ['neutral','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s007/bmp/s007-00_img.bmp']\n",
    "\n",
    "sadness = ['sadness','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s028/bmp/s028-02_img.bmp']\n",
    "\n",
    "surprise = ['surprise','/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/s029/bmp/s029-03_img.bmp']\n",
    "\n",
    "reference_from_ds = [anger,disgust,fear,happiness,neutral,sadness,surprise]\n",
    " \n",
    "path2save = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/Image GT scores/'\n",
    "\n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data'\n",
    "annotation_path = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data/annotation.txt'\n",
    "reference_list = reference_from_ds.copy()\n",
    "\n",
    "file_to_read = open(annotation_path,'r')\n",
    "annotation_list = [line.split(';') for line in file_to_read.readlines()]\n",
    "\n",
    "expression_reference_logits= {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None,'surprise':None}\n",
    "    \n",
    "for expression_list in reference_list:\n",
    "    logits_reference = inference(net,expression_list[1])\n",
    "    logits_reference = np.mean(logits_reference, axis=0)\n",
    "    logits_reference /= l2norm(logits_reference)\n",
    "    expression_reference_logits[expression_list[0]] = logits_reference\n",
    "\n",
    "\n",
    "for image in annotation_list:\n",
    "\n",
    "    label = image[1]\n",
    "    logits_val_img = inference(net,image[0])\n",
    "    logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "    logits_val_img /= l2norm(logits_val_img)\n",
    "    expression_reference_scores = []\n",
    "    for logits in expression_reference_logits.values():\n",
    "        score = np.dot(logits_val_img,logits)\n",
    "        expression_reference_scores.append(score)        \n",
    "    max_score = max(expression_reference_scores)\n",
    "    gt_score = np.dot(logits_val_img,expression_reference_logits[label])\n",
    "    img = PIL.Image.open(image[0])\n",
    "    save = img.save(path2save+label+'/'+label+'_gt-score:'+str(gt_score)+'_net-answer:'+reference_list[expression_reference_scores.index(max_score)][0]+'(score:'+str(max_score)+').jpg')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': -0.06331270580366254, 'sadness': 0.5369452998414636, 'fear': 0.6019274449823424, 'happiness': 0.7104119304791093, 'disgust': 0.6149329068101943, 'neutral': 0.4224602678231895, 'surprise': 0.4736080201137811}\n",
      "{'anger': -0.06331270580366254, 'sadness': 0.5369452998414636, 'fear': 0.6019274449823424, 'happiness': 0.7104119304791093, 'disgust': 0.6149329068101943, 'neutral': 0.4224602678231895, 'surprise': 0.4736080201137811}\n",
      "{'anger': -0.06331270580366254, 'sadness': 0.5369452998414636, 'fear': 0.6019274449823424, 'happiness': 0.7104119304791093, 'disgust': 0.6149329068101943, 'neutral': 0.4224602678231895, 'surprise': 0.4736080201137811}\n"
     ]
    }
   ],
   "source": [
    "#Treshhold computing\n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/val'\n",
    "file_to_write = open('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/Treshhold_val','w+')\n",
    "expression_reference_logits=[]\n",
    "express2indx = {'anger':0,'disgust':1,'fear':2,'happiness':3,'neutral':4,'sadness':5,'surprise':6}\n",
    "for i in range(1,4):\n",
    "    for expression_list in reference:\n",
    "        logits_reference = inference(net,'/storage_labs/3030/BelyakovM/'+expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "\n",
    "    expression_reference_mean_scores = {'anger':0,'sadness':0,'fear':0,'happiness':0,'disgust':0,'neutral':0,'surprise':0}\n",
    "    for expression in os.listdir(datadir):\n",
    "        imgs_list = os.listdir(os.path.join(datadir,expression))\n",
    "        num_folder_imgs = len(imgs_list)\n",
    "        for image in imgs_list:\n",
    "            try: \n",
    "                logits_val_img = inference(net,os.path.join(datadir,expression,image))\n",
    "                logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "                logits_val_img /= l2norm(logits_val_img)\n",
    "            except:\n",
    "                num_folder_imgs -= 1\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            score = np.dot(logits_val_img,expression_reference_logits[express2indx[expression]][1])\n",
    "            expression_reference_mean_scores[expression] += score\n",
    "        expression_reference_mean_scores[expression] /= num_folder_imgs\n",
    "    \n",
    "    print(expression_reference_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r18 Expression identifying within a person expressions(FACESds)\n",
    "dsdir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data/IDs/persons'\n",
    "reference2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "reference2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "\n",
    "for person in os.listdir(dsdir):\n",
    "\n",
    "    for mode in os.listdir(os.path.join(dsdir,person)):        \n",
    "        for expression in os.listdir(os.path.join(dsdir,person,mode)):\n",
    "            if mode == 'a':\n",
    "                reference2path_dict[expression] = os.path.join(dsdir,person,mode,expression,os.listdir(os.path.join(dsdir,person,mode,expression))[0])\n",
    "                try:\n",
    "                    reference2logits_dict[expression] = inference(net,reference2path_dict[expression])\n",
    "                    reference2logits_dict[expression] = np.mean(reference2logits_dict[expression], axis=0)\n",
    "                    reference2logits_dict[expression] /= l2norm(reference2logits_dict[expression])\n",
    "                except:\n",
    "                    print(reference2path_dict[expression])\n",
    "\n",
    "            if mode == 'b':\n",
    "                test2path_dict[expression] = os.path.join(dsdir,person,mode,expression,os.listdir(os.path.join(dsdir,person,mode,expression))[0])\n",
    "                test2logits_dict[expression] = inference(net,test2path_dict[expression])\n",
    "                test2logits_dict[expression] = np.mean(test2logits_dict[expression], axis=0)\n",
    "                test2logits_dict[expression] /= l2norm(test2logits_dict[expression])\n",
    "    for test_expression in test2path_dict.keys():\n",
    "        test_reference_score_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "        for reference_exoression in reference2path_dict.keys():\n",
    "            test_reference_score_dict[reference_exoression] = np.dot(reference2logits_dict[reference_exoression],test2logits_dict[test_expression])\n",
    "        net_answer = max(test_reference_score_dict,key = test_reference_score_dict.get)\n",
    "        gt_score = test_reference_score_dict[test_expression]\n",
    "        img = PIL.Image.open(test2path_dict[test_expression])\n",
    "        img = img.save(os.path.join('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data/IDs/image GT scores',person,test_expression+'_gt_score:'+str(gt_score)+'_net-answer:'+net_answer+'(score:'+str(test_reference_score_dict[net_answer])+').jpg'))\n",
    "    \n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r18 Expression identifying within a person expressions(facesdb)\n",
    "dsdir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/data'\n",
    "reference2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "reference2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "expression_dict = {'4':'anger','5':'disgust','6':'fear','1':'happiness','0':'neutral','2':'sadness','3':'surprise'}\n",
    "person_folder = os.listdir(dsdir)\n",
    "person_folder.remove('annotation.txt')\n",
    "person_folder.remove('fen.txt')\n",
    "person_folder.remove('.ipynb_checkpoints')\n",
    "for person in person_folder:\n",
    "      \n",
    "    for expression in os.listdir(os.path.join(dsdir,person,'bmp')):\n",
    "     \n",
    "        reference2path_dict[expression_dict[expression[6]]] = os.path.join(dsdir,person,'bmp',expression)\n",
    "        try:\n",
    "            reference2logits_dict[expression_dict[expression[6]]] = inference(net,reference2path_dict[expression_dict[expression[6]]])\n",
    "            reference2logits_dict[expression_dict[expression[6]]] = np.mean(reference2logits_dict[expression_dict[expression[6]]], axis=0)\n",
    "            reference2logits_dict[expression_dict[expression[6]]] /= l2norm(reference2logits_dict[expression_dict[expression[6]]])\n",
    "        except:\n",
    "            print(reference2path_dict[expression_dict[expression[6]]])\n",
    "\n",
    "     \n",
    "        test2path_dict[expression_dict[expression[6]]] = os.path.join(dsdir,person,'bmp',expression)\n",
    "        test2logits_dict[expression_dict[expression[6]]] = inference(net,test2path_dict[expression_dict[expression[6]]])\n",
    "        test2logits_dict[expression_dict[expression[6]]] = np.mean(test2logits_dict[expression_dict[expression[6]]], axis=0)\n",
    "        test2logits_dict[expression_dict[expression[6]]] /= l2norm(test2logits_dict[expression_dict[expression[6]]])\n",
    "    os.mkdir(os.path.join('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/ID reference-ID GT score',person))\n",
    "    for test_expression in test2path_dict.keys():\n",
    "        test_reference_score_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "        for reference_exoression in reference2path_dict.keys():\n",
    "            test_reference_score_dict[reference_exoression] = np.dot(reference2logits_dict[reference_exoression],test2logits_dict[test_expression])\n",
    "        net_answer = max(test_reference_score_dict,key = test_reference_score_dict.get)\n",
    "        gt_score = test_reference_score_dict[test_expression]\n",
    "        img = PIL.Image.open(test2path_dict[test_expression])\n",
    "        \n",
    "        img = img.save(os.path.join('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/facesdb/ID reference-ID GT score',person,test_expression+'_gt_score:'+str(gt_score)+'_net-answer:'+net_answer+'(score:'+str(test_reference_score_dict[net_answer])+').jpg'))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/storage_labs/3030/BelyakovM/Face_attributes/insightface/recognition/arcface_torch')\n",
    "from backbones import get_model\n",
    "net = get_model('r34', fp16=False)\n",
    "net.load_state_dict(torch.load('/storage_labs/3030/BelyakovM/Face_attributes/insightface/recognition/arcface_torch/work_dirs_r34/AffectnetOzon_r34/backbone_37.pth'))\n",
    "@torch.no_grad()\n",
    "def inference(net, img):\n",
    "    if img is None:\n",
    "        img = np.random.randint(0, 255, size=(112, 112, 3), dtype=np.uint8)\n",
    "    else:\n",
    "        img = cv2.imread(img)\n",
    "        img = cv2.resize(img, (112, 112))\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "    img.div_(255).sub_(0.5).div_(0.5)\n",
    " \n",
    "    net.eval()\n",
    "    feat = net(img).numpy()\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.47), ('sadness', 0.668), ('fear', 0.73), ('happiness', 0.772), ('surprise', 0.66), ('disgust', 0.556), ('neutral', 0.52)]\n",
      "[('anger', 0.11), ('sadness', 0.61), ('fear', 0.57), ('happiness', 0.78), ('surprise', 0.526), ('disgust', 0.746), ('neutral', 0.528)]\n",
      "[('anger', 0.604), ('sadness', 0.56), ('fear', 0.758), ('happiness', 0.752), ('surprise', 0.678), ('disgust', 0.688), ('neutral', 0.564)]\n"
     ]
    }
   ],
   "source": [
    "#Computing r34 validation accuracy on Affect/val set with external references \n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/AffecetNet_partly/original/val'\n",
    "for i in range(1,4):\n",
    "    expression_reference_logits=[]\n",
    "    for expression_list in reference:\n",
    "        logits_reference = inference(net,'/storage_labs/3030/BelyakovM/'+expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "    folder_acc=[]\n",
    "    for folder in os.listdir(datadir):\n",
    "        folder_corrects = 0\n",
    "        imgs = os.listdir(os.path.join(datadir,folder))\n",
    "        num_folder_imgs = len(imgs)\n",
    "        for image in imgs:\n",
    "            try:\n",
    "                logits_val_img = inference(net,os.path.join(datadir,folder,image))\n",
    "                logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "                logits_val_img /= l2norm(logits_val_img)\n",
    "            except:\n",
    "                num_folder_imgs -= 1\n",
    "                continue\n",
    "            expression_reference_scores=[]\n",
    "   \n",
    "            for logits in expression_reference_logits:\n",
    "                score = np.dot(logits_val_img,logits[1])\n",
    "                expression_reference_scores.append(score)\n",
    "                \n",
    "            max_score = max(expression_reference_scores)\n",
    "            if folder == reference[expression_reference_scores.index(max_score)][0]:\n",
    "                folder_corrects += 1\n",
    "        folder_acc.append((folder,folder_corrects/num_folder_imgs))\n",
    "    print(folder_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anger', 0.39501779359430605), ('disgust', 0.277337559429477), ('fear', 0.44400396432111), ('happiness', 0.7321578505457599), ('neutral', 0.46799116997792495), ('sadness', 0.5786350148367952), ('surprise', 0.5320158102766799)]\n",
      "[('anger', 0.08967971530249111), ('disgust', 0.4009508716323296), ('fear', 0.42021803766105054), ('happiness', 0.7405541561712846), ('neutral', 0.5320088300220751), ('sadness', 0.4903560830860534), ('surprise', 0.38814229249011856)]\n",
      "[('anger', 0.5330960854092527), ('disgust', 0.30427892234548337), ('fear', 0.5203171456888008), ('happiness', 0.7220822837951302), ('neutral', 0.5268579838116262), ('sadness', 0.43397626112759646), ('surprise', 0.5312252964426878)]\n"
     ]
    }
   ],
   "source": [
    "#Computing r34 validation accuracy on OZON/val set with external references \n",
    "datadir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/OZON_splited/val'\n",
    "for i in range(1,4):\n",
    "    expression_reference_logits=[]\n",
    "    for expression_list in reference:\n",
    "        logits_reference = inference(net,'/storage_labs/3030/BelyakovM/'+expression_list[i])\n",
    "        logits_reference = np.mean(logits_reference, axis=0)\n",
    "        logits_reference /= l2norm(logits_reference)\n",
    "        expression_reference_logits.append((expression_list[0],logits_reference))\n",
    "    folder_acc=[]\n",
    "    folders = os.listdir(datadir)\n",
    "    folders.sort()\n",
    "    for folder in folders:\n",
    "        if folder == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        folder_corrects = 0\n",
    "        imgs = os.listdir(os.path.join(datadir,folder))\n",
    "        num_folder_imgs = len(imgs)\n",
    "        for image in imgs:\n",
    "            try:\n",
    "                logits_val_img = inference(net,os.path.join(datadir,folder,image))\n",
    "                logits_val_img = np.mean(logits_val_img, axis=0)\n",
    "                logits_val_img /= l2norm(logits_val_img)\n",
    "            except:\n",
    "                num_folder_imgs -= 1\n",
    "                continue\n",
    "            expression_reference_scores=[]\n",
    "   \n",
    "            for logits in expression_reference_logits:\n",
    "                score = np.dot(logits_val_img,logits[1])\n",
    "                expression_reference_scores.append(score)\n",
    "                \n",
    "            max_score = max(expression_reference_scores)\n",
    "            if folder == reference[expression_reference_scores.index(max_score)][0]:\n",
    "                folder_corrects += 1\n",
    "        folder_acc.append((folder,folder_corrects/num_folder_imgs))\n",
    "    print(folder_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r34 Expression identifying within a person expressions(FACESds)\n",
    "dsdir = '/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data/IDs/persons'\n",
    "reference2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2path_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "reference2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "test2logits_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "\n",
    "for person in os.listdir(dsdir):\n",
    "\n",
    "    for mode in os.listdir(os.path.join(dsdir,person)):        \n",
    "        for expression in os.listdir(os.path.join(dsdir,person,mode)):\n",
    "            if mode == 'a':\n",
    "                reference2path_dict[expression] = os.path.join(dsdir,person,mode,expression,os.listdir(os.path.join(dsdir,person,mode,expression))[0])\n",
    "                try:\n",
    "                    reference2logits_dict[expression] = inference(net,reference2path_dict[expression])\n",
    "                    reference2logits_dict[expression] = np.mean(reference2logits_dict[expression], axis=0)\n",
    "                    reference2logits_dict[expression] /= l2norm(reference2logits_dict[expression])\n",
    "                except:\n",
    "                    print(reference2path_dict[expression])\n",
    "\n",
    "            if mode == 'b':\n",
    "                test2path_dict[expression] = os.path.join(dsdir,person,mode,expression,os.listdir(os.path.join(dsdir,person,mode,expression))[0])\n",
    "                test2logits_dict[expression] = inference(net,test2path_dict[expression])\n",
    "                test2logits_dict[expression] = np.mean(test2logits_dict[expression], axis=0)\n",
    "                test2logits_dict[expression] /= l2norm(test2logits_dict[expression])\n",
    "    for test_expression in test2path_dict.keys():\n",
    "        test_reference_score_dict = {'anger':None,'disgust':None,'fear':None,'happiness':None,'neutral':None,'sadness':None}\n",
    "        for reference_exoression in reference2path_dict.keys():\n",
    "            test_reference_score_dict[reference_exoression] = np.dot(reference2logits_dict[reference_exoression],test2logits_dict[test_expression])\n",
    "        net_answer = max(test_reference_score_dict,key = test_reference_score_dict.get)\n",
    "        gt_score = test_reference_score_dict[test_expression]\n",
    "        img = PIL.Image.open(test2path_dict[test_expression])\n",
    "        img = img.save(os.path.join('/storage_labs/3030/BelyakovM/Face_attributes/ds/db_BuevichP/emochon/FACESds_copy/data/IDs/image GT scores/r34',person,test_expression+'_gt_score:'+str(gt_score)+'_net-answer:'+net_answer+'(score:'+str(test_reference_score_dict[net_answer])+').jpg'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
